{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Gibbs Introduction Welcome to the documentation of the gibbs package. gibbs is a package that help you scale your ML workers (or any python code) across processes and machines, asynchronously. gibbs is : \u26a1\ufe0f Highly performant \ud83d\udd00 Asynchronous \ud83d\udc25 Easy-to-use Installation Latest version You can install the latest stable version of the package directly from PyPi with : pip install gibbs Bleeding-edge version To install the bleeding-edge version ( main , not released), you can do : pip install git+https://github.com/astariul/gibbs.git Local version For development purposes, you can clone the repository locally and install it manually : git clone https://github.com/astariul/gibbs.git cd gibbs pip install -e . Extra dependencies You can also install extras dependencies, for example : pip install gibbs [ docs ] Will install necessary dependencies for building the docs. List of extra dependencies : test : Dependencies for running unit-tests. hook : Dependencies for running pre-commit hooks. lint : Dependencies for running linters and formatters. docs : Dependencies for building the documentation. ex : Dependencies for running the examples. dev : test + hook + lint + docs . all : All extra dependencies. Contribute To contribute, install the package locally (see Installation ), create your own branch, add your code/tests/documentation, and open a PR ! Pre-commit hooks Pre-commit hooks are set to check the code added whenever you commit something. When you try to commit your code, hooks are run, and if anything fails ( linters, etc... ), your code will not be committed. You then have to fix your code and try to commit again ! Info If you never ran the hooks before, install it with : pre-commit install Documentation When you contribute, make sure to keep the documentation up-to-date. You can visualize the documentation locally by running : mkdocs serve","title":"Welcome"},{"location":"#gibbs","text":"","title":"Gibbs"},{"location":"#introduction","text":"Welcome to the documentation of the gibbs package. gibbs is a package that help you scale your ML workers (or any python code) across processes and machines, asynchronously. gibbs is : \u26a1\ufe0f Highly performant \ud83d\udd00 Asynchronous \ud83d\udc25 Easy-to-use","title":"Introduction"},{"location":"#installation","text":"","title":"Installation"},{"location":"#latest-version","text":"You can install the latest stable version of the package directly from PyPi with : pip install gibbs","title":"Latest version"},{"location":"#bleeding-edge-version","text":"To install the bleeding-edge version ( main , not released), you can do : pip install git+https://github.com/astariul/gibbs.git","title":"Bleeding-edge version"},{"location":"#local-version","text":"For development purposes, you can clone the repository locally and install it manually : git clone https://github.com/astariul/gibbs.git cd gibbs pip install -e .","title":"Local version"},{"location":"#extra-dependencies","text":"You can also install extras dependencies, for example : pip install gibbs [ docs ] Will install necessary dependencies for building the docs. List of extra dependencies : test : Dependencies for running unit-tests. hook : Dependencies for running pre-commit hooks. lint : Dependencies for running linters and formatters. docs : Dependencies for building the documentation. ex : Dependencies for running the examples. dev : test + hook + lint + docs . all : All extra dependencies.","title":"Extra dependencies"},{"location":"#contribute","text":"To contribute, install the package locally (see Installation ), create your own branch, add your code/tests/documentation, and open a PR !","title":"Contribute"},{"location":"#pre-commit-hooks","text":"Pre-commit hooks are set to check the code added whenever you commit something. When you try to commit your code, hooks are run, and if anything fails ( linters, etc... ), your code will not be committed. You then have to fix your code and try to commit again ! Info If you never ran the hooks before, install it with : pre-commit install","title":"Pre-commit hooks"},{"location":"#documentation","text":"When you contribute, make sure to keep the documentation up-to-date. You can visualize the documentation locally by running : mkdocs serve","title":"Documentation"},{"location":"advanced/","text":"Advanced Changing the port used by gibbs By default, gibbs uses the port 5019 for the sockets the communicate. You can change this port by using the argument gibbs_port in the Worker constructor, and the argument port in the Hub constructor : hub = Hub ( port = 6222 ) w = Worker ( MyModel , gibbs_port = 6222 ) Passing arguments to model's constructor If your model requires arguments for the constructor (like in the example given in the Usage section ) : class MyAwesomeModel : def __init__ ( self , wait_time = 0.25 ): super () . __init__ () self . w = wait_time You can just pass the arguments to the Worker (positional arguments or keyword arguments, both work) : # With positional argument w1 = Worker ( MyAwesomeModel , 0.3 ) # With keyword argument w2 = Worker ( MyAwesomeModel , wait_time = 0.3 ) Only a small list of keywords arguments are reserved for gibbs . Here is the exhaustive list : gibbs_host gibbs_port gibbs_heartbeat_interval gibbs_reset_after_n_miss Starting workers in another machine By default, gibbs workers try to connect to a Hub on the local machine ( localhost ). But you can change this behavior, to have workers running in another machine ! To do this, simply start your worker with the appropriate host using the gibbs_host argument : w = Worker ( MyModel , gibbs_host = \"192.178.0.3\" ) Retrials & timeouts By default, the request() method of the Hub will indefinitely waits for a response from the worker. If instead you want to have a timeout, you can specify the timeout (in seconds ) with the gibbs_timeout argument : h = Hub () await h . request ( x , gibbs_timeout = 0.4 ) If the Hub doesn't receive any response from the worker within the specified timeout, a asyncio.TimeoutError exception is raised. You can also specify a number of retries with the argument gibbs_retries : h = Hub () await h . request ( x , gibbs_timeout = 2 , gibbs_retries = 3 ) With this code, the Hub will try to send a request. If the Hub didn't receive an answer within 2 seconds, it will retry the request again, up to 3 times. Note You need to specify gibbs_timeout when using gibbs_retries , because there is no timeout by default ! You can also specify gibbs_retries=-1 for infinite retries ! Logging Inside gibbs , the library loguru is used for logging. By default, the logger is disabled ( so logging functions become no-op ). If you want to see what's going on inside gibbs (for contributing or debugging for example), you can activate it : from loguru import logger logger . enable ( \"gibbs\" ) # From here, logs will be displayed You can also change the level of logs you want, the format, etc... from loguru import logger import sys logger . enable ( \"gibbs\" ) logger . remove () logger . add ( sys . stderr , format = \" {time} {level} {message} \" , level = \"INFO\" ) Tip For more details, check out the loguru library ! Changing the heartbeat interval By default, the heartbeat interval is set to one second . You can change this value by using the argument gibbs_heartbeat_interval in the Worker constructor, and the argument heartbeat_interval in the Hub constructor : hub = Hub ( heartbeat_interval = 10 ) w = Worker ( MyModel , gibbs_heartbeat_interval = 10 ) Warning Make sure that both the Hub and the workers have the same value for the heartbeat interval, otherwise they might have synchronisation issues !","title":"Advanced"},{"location":"advanced/#advanced","text":"","title":"Advanced"},{"location":"advanced/#changing-the-port-used-by-gibbs","text":"By default, gibbs uses the port 5019 for the sockets the communicate. You can change this port by using the argument gibbs_port in the Worker constructor, and the argument port in the Hub constructor : hub = Hub ( port = 6222 ) w = Worker ( MyModel , gibbs_port = 6222 )","title":"Changing the port used by gibbs"},{"location":"advanced/#passing-arguments-to-models-constructor","text":"If your model requires arguments for the constructor (like in the example given in the Usage section ) : class MyAwesomeModel : def __init__ ( self , wait_time = 0.25 ): super () . __init__ () self . w = wait_time You can just pass the arguments to the Worker (positional arguments or keyword arguments, both work) : # With positional argument w1 = Worker ( MyAwesomeModel , 0.3 ) # With keyword argument w2 = Worker ( MyAwesomeModel , wait_time = 0.3 ) Only a small list of keywords arguments are reserved for gibbs . Here is the exhaustive list : gibbs_host gibbs_port gibbs_heartbeat_interval gibbs_reset_after_n_miss","title":"Passing arguments to model's constructor"},{"location":"advanced/#starting-workers-in-another-machine","text":"By default, gibbs workers try to connect to a Hub on the local machine ( localhost ). But you can change this behavior, to have workers running in another machine ! To do this, simply start your worker with the appropriate host using the gibbs_host argument : w = Worker ( MyModel , gibbs_host = \"192.178.0.3\" )","title":"Starting workers in another machine"},{"location":"advanced/#retrials-timeouts","text":"By default, the request() method of the Hub will indefinitely waits for a response from the worker. If instead you want to have a timeout, you can specify the timeout (in seconds ) with the gibbs_timeout argument : h = Hub () await h . request ( x , gibbs_timeout = 0.4 ) If the Hub doesn't receive any response from the worker within the specified timeout, a asyncio.TimeoutError exception is raised. You can also specify a number of retries with the argument gibbs_retries : h = Hub () await h . request ( x , gibbs_timeout = 2 , gibbs_retries = 3 ) With this code, the Hub will try to send a request. If the Hub didn't receive an answer within 2 seconds, it will retry the request again, up to 3 times. Note You need to specify gibbs_timeout when using gibbs_retries , because there is no timeout by default ! You can also specify gibbs_retries=-1 for infinite retries !","title":"Retrials &amp; timeouts"},{"location":"advanced/#logging","text":"Inside gibbs , the library loguru is used for logging. By default, the logger is disabled ( so logging functions become no-op ). If you want to see what's going on inside gibbs (for contributing or debugging for example), you can activate it : from loguru import logger logger . enable ( \"gibbs\" ) # From here, logs will be displayed You can also change the level of logs you want, the format, etc... from loguru import logger import sys logger . enable ( \"gibbs\" ) logger . remove () logger . add ( sys . stderr , format = \" {time} {level} {message} \" , level = \"INFO\" ) Tip For more details, check out the loguru library !","title":"Logging"},{"location":"advanced/#changing-the-heartbeat-interval","text":"By default, the heartbeat interval is set to one second . You can change this value by using the argument gibbs_heartbeat_interval in the Worker constructor, and the argument heartbeat_interval in the Hub constructor : hub = Hub ( heartbeat_interval = 10 ) w = Worker ( MyModel , gibbs_heartbeat_interval = 10 ) Warning Make sure that both the Hub and the workers have the same value for the heartbeat interval, otherwise they might have synchronisation issues !","title":"Changing the heartbeat interval"},{"location":"architecture/","text":"Architecture Warning This page contains advanced technical details about gibbs . You can probably skip it if you just want to use the library. Tooling gibbs relies on the zmq library for communication between the hub and the workers. zmq is a low-level networking library, providing us with TCP sockets. This gives us performances, and the ability to have workers on different machines. Pattern gibbs implement a modified version of the Paranoid Pirate Pattern . You can read more about the Paranoid Pirate Pattern in the zmq guide . But basically : It is a reliable pattern (it can handle failures) It relies on the REQUEST - REPLY sockets (and their asynchronous equivalent : ROUTER - DEALER ) It automatically balance requests across workers as they come Here is a schema for the Paranoid Pirate Pattern implemented in gibbs : Tip As you can see the the original Paranoid Pirate Pattern is slightly modified : the clients and the queue are merged into a single component, called \"Hub\". Let's see how these components interact with each other to deal with parallel requests : The Hub simply keeps a list of workers that are ready, and send incoming requests to one of the ready worker. Each worker deal with the request it receives. So with two workers, we can deal with two requests in parallel, as shown in the figure above. When receiving the response from the worker, the Hub marks it as ready again. Heartbeat In the zmq guide , the Paranoid Pirate Pattern implements a One-way heartbeat . In gibbs though, the heartbeat is implemented as a Ping-pong heartbeat . Question Heartbeat is necessary to have robustness , in case of workers or Hub crash. Here is how heartbeat works : The workers always initiate the heartbeat ( ping ), and the hub answer it ( pong ). If the worker keeps sending pings but does not receive pongs, we know the Hub is dead. In this case the worker will try to reconnect his socket. So when the Hub is restarted, the worker will automatically reconnect. If the Hub didn't receive a heartbeat from some time, we know this worker is dead. In this case the worker is removed from the list of workers ready, so no requests are sent to this worker. Warning There is a small time interval where a worker can die and the Hub still thinks it's alive. If a request is sent in this interval, the request will fail. To solve this, you can check the section about automatic retrials .","title":"Architecture"},{"location":"architecture/#architecture","text":"Warning This page contains advanced technical details about gibbs . You can probably skip it if you just want to use the library.","title":"Architecture"},{"location":"architecture/#tooling","text":"gibbs relies on the zmq library for communication between the hub and the workers. zmq is a low-level networking library, providing us with TCP sockets. This gives us performances, and the ability to have workers on different machines.","title":"Tooling"},{"location":"architecture/#pattern","text":"gibbs implement a modified version of the Paranoid Pirate Pattern . You can read more about the Paranoid Pirate Pattern in the zmq guide . But basically : It is a reliable pattern (it can handle failures) It relies on the REQUEST - REPLY sockets (and their asynchronous equivalent : ROUTER - DEALER ) It automatically balance requests across workers as they come Here is a schema for the Paranoid Pirate Pattern implemented in gibbs : Tip As you can see the the original Paranoid Pirate Pattern is slightly modified : the clients and the queue are merged into a single component, called \"Hub\". Let's see how these components interact with each other to deal with parallel requests : The Hub simply keeps a list of workers that are ready, and send incoming requests to one of the ready worker. Each worker deal with the request it receives. So with two workers, we can deal with two requests in parallel, as shown in the figure above. When receiving the response from the worker, the Hub marks it as ready again.","title":"Pattern"},{"location":"architecture/#heartbeat","text":"In the zmq guide , the Paranoid Pirate Pattern implements a One-way heartbeat . In gibbs though, the heartbeat is implemented as a Ping-pong heartbeat . Question Heartbeat is necessary to have robustness , in case of workers or Hub crash. Here is how heartbeat works : The workers always initiate the heartbeat ( ping ), and the hub answer it ( pong ). If the worker keeps sending pings but does not receive pongs, we know the Hub is dead. In this case the worker will try to reconnect his socket. So when the Hub is restarted, the worker will automatically reconnect. If the Hub didn't receive a heartbeat from some time, we know this worker is dead. In this case the worker is removed from the list of workers ready, so no requests are sent to this worker. Warning There is a small time interval where a worker can die and the Hub still thinks it's alive. If a request is sent in this interval, the request will fail. To solve this, you can check the section about automatic retrials .","title":"Heartbeat"},{"location":"code_ref/","text":"Code reference API Hub Class acting as a hub for all the requests to send. All requests sent through this class will be automatically dispatched to connected workers, will wait for the responses and return it. Parameters: Name Type Description Default port int Port number to use for the sockets. Defaults to DEFAULT_PORT. 5019 heartbeat_interval float Heartbeat interval used by the workers, in seconds. Defaults to DEFAULT_HEARTBEAT_INTERVAL. 1 resp_buffer_size int Maximum response buffer size. Defaults to RESPONSE_BUFFER_SIZE. 4096 Source code in gibbs/hub.py class Hub : \"\"\"Class acting as a hub for all the requests to send. All requests sent through this class will be automatically dispatched to connected workers, will wait for the responses and return it. Args: port (int): Port number to use for the sockets. Defaults to DEFAULT_PORT. heartbeat_interval (float): Heartbeat interval used by the workers, in seconds. Defaults to DEFAULT_HEARTBEAT_INTERVAL. resp_buffer_size (int): Maximum response buffer size. Defaults to RESPONSE_BUFFER_SIZE. \"\"\" def __init__ ( self , port : int = DEFAULT_PORT , heartbeat_interval : float = DEFAULT_HEARTBEAT_INTERVAL , resp_buffer_size : int = RESPONSE_BUFFER_SIZE , ): super () . __init__ () self . port = port self . heartbeat_t = heartbeat_interval self . socket = None self . w_manager = None self . req_manager = RequestManager ( resp_buffer_size = resp_buffer_size ) async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff logger . debug ( \"Receiving...\" ) address , * frames = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . w_manager . reckon ( address ) if len ( frames ) == 1 : # Answer the Ping logger . debug ( \"Answering the ping\" ) await self . socket . send_multipart ([ address , b \"\" , PONG ]) continue _ , resp = frames req_id , code , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) self . req_manager . store ( req_id , code , res ) def _start_if_not_started ( self ): \"\"\"Helper method to ensure everything is properly started (socket is initialized, receiving loop is started, etc...). \"\"\" if self . socket is None : # Create what we need here in this process/context context = zmq . asyncio . Context () self . socket = context . socket ( zmq . ROUTER ) self . socket . bind ( f \"tcp://*: { self . port } \" ) self . w_manager = WorkerManager ( heartbeat_interval = self . heartbeat_t ) # Fire and forget : infinite loop, taking care of receiving stuff from the socket logger . info ( \"Starting receiving loop...\" ) asyncio . create_task ( self . receive_loop ()) async def _request ( self , * args : Any , ** kwargs : Any ) -> Any : \"\"\"Raw method to send a request. This method will do the following : * Start the receiving loop if it was not started * Get the address of the next worker ready (blocking) * Send the request to the worker * Wait for the response (blocking) * Return the result Args: *args: Positional arguments for the request. **kwargs: Keywords arguments for the request. Raises: UserCodeException: Exception raised if an exception was raised inside user-defined code on the worker side. Returns: Any: The response for the request. \"\"\" # Before anything, if the receiving loop was not started, start it self . _start_if_not_started () # Assign a unique ID to the request req_id = uuid . uuid4 () . hex # Let the manager know that we are waiting for this request logger . debug ( f \"Pinning request # { req_id } \" ) self . req_manager . pin ( req_id ) # Send the request address = await self . w_manager . get_next_worker () logger . debug ( f \"Sending request # { req_id } to worker # { address } \" ) await self . socket . send_multipart ([ address , b \"\" , msgpack . packb ([ req_id , args , kwargs ])]) # Wait until we receive the response code , res = await self . req_manager . wait_for ( req_id ) logger . debug ( f \"Received result for request # { req_id } \" ) # Depending on what is the response, deal with it properly if code == CODE_FAILURE : raise UserCodeException ( res ) else : return res async def request ( self , * args : Any , gibbs_timeout : float = None , gibbs_retries : int = 0 , ** kwargs : Any ) -> Any : \"\"\"Main method, used to send a request to workers and get the result. This method is a wrapper around `_request`, providing additional functionalities : * Timeout * Automatic retries Args: *args: Positional arguments for the request. gibbs_timeout (float): Timeout for the request, in seconds. If `None` is given, block until the request is complete. Defaults to None. gibbs_retries (int): Number of retries. This argument is used only if `gibbs_timeout` is not `None`. If `-1` is given, indefinitely retry. Defaults to 0. **kwargs: Keywords arguments for the request. Raises: asyncio.TimeoutError: Error raised if no response is received within the given timeout. Returns: Any: The response for the request. \"\"\" try : return await asyncio . wait_for ( self . _request ( * args , ** kwargs ), timeout = gibbs_timeout ) except asyncio . TimeoutError : if gibbs_retries == 0 : logger . error ( f \"Request failed : no response received within { gibbs_timeout } s\" ) raise else : retries_left = max ( gibbs_retries - 1 , - 1 ) logger . warning ( f \"Request failed : no response received within { gibbs_timeout } s. Retrying { retries_left } times\" ) return await self . request ( * args , gibbs_timeout = gibbs_timeout , gibbs_retries = retries_left , ** kwargs ) def __del__ ( self ): if self . socket is not None : self . socket . close () receive_loop ( self ) async Infinite loop for receiving responses from the workers. Source code in gibbs/hub.py async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff logger . debug ( \"Receiving...\" ) address , * frames = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . w_manager . reckon ( address ) if len ( frames ) == 1 : # Answer the Ping logger . debug ( \"Answering the ping\" ) await self . socket . send_multipart ([ address , b \"\" , PONG ]) continue _ , resp = frames req_id , code , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) self . req_manager . store ( req_id , code , res ) request ( self , * args , * , gibbs_timeout = None , gibbs_retries = 0 , ** kwargs ) async Main method, used to send a request to workers and get the result. This method is a wrapper around _request , providing additional functionalities : * Timeout * Automatic retries Parameters: Name Type Description Default *args Any Positional arguments for the request. () gibbs_timeout float Timeout for the request, in seconds. If None is given, block until the request is complete. Defaults to None. None gibbs_retries int Number of retries. This argument is used only if gibbs_timeout is not None . If -1 is given, indefinitely retry. Defaults to 0. 0 **kwargs Any Keywords arguments for the request. {} Exceptions: Type Description asyncio.TimeoutError Error raised if no response is received within the given timeout. Returns: Type Description Any The response for the request. Source code in gibbs/hub.py async def request ( self , * args : Any , gibbs_timeout : float = None , gibbs_retries : int = 0 , ** kwargs : Any ) -> Any : \"\"\"Main method, used to send a request to workers and get the result. This method is a wrapper around `_request`, providing additional functionalities : * Timeout * Automatic retries Args: *args: Positional arguments for the request. gibbs_timeout (float): Timeout for the request, in seconds. If `None` is given, block until the request is complete. Defaults to None. gibbs_retries (int): Number of retries. This argument is used only if `gibbs_timeout` is not `None`. If `-1` is given, indefinitely retry. Defaults to 0. **kwargs: Keywords arguments for the request. Raises: asyncio.TimeoutError: Error raised if no response is received within the given timeout. Returns: Any: The response for the request. \"\"\" try : return await asyncio . wait_for ( self . _request ( * args , ** kwargs ), timeout = gibbs_timeout ) except asyncio . TimeoutError : if gibbs_retries == 0 : logger . error ( f \"Request failed : no response received within { gibbs_timeout } s\" ) raise else : retries_left = max ( gibbs_retries - 1 , - 1 ) logger . warning ( f \"Request failed : no response received within { gibbs_timeout } s. Retrying { retries_left } times\" ) return await self . request ( * args , gibbs_timeout = gibbs_timeout , gibbs_retries = retries_left , ** kwargs ) Worker ( Process ) Define a worker process. This worker process indefinitely waits for requests on a socket. Upon receiving a request, it processes it with the worker class provided, and return the response. After creating the Worker object, you have 2 different ways to run it : * worker.run() : It will run in the current process directly (blocking, infinite loop). * worker.start() : It will start a different process and start the code there (non-blocking). Parameters: Name Type Description Default worker_cls Callable Worker class containing the code that will be used to process requests. required gibbs_host str Host of the Hub. Defaults to \"localhost\". 'localhost' gibbs_port int Port of the Hub. Defaults to DEFAULT_PORT. 5019 gibbs_heartbeat_interval float Heartbeat interval between the worker and the Hub. Defaults to DEFAULT_HEARTBEAT_INTERVAL. 1 gibbs_reset_after_n_miss int Number of missed heartbeats allowed before hard-resetting the socket and retrying. Defaults to DEFAULT_RESET_AFTER_N_MISS. 2 Source code in gibbs/worker.py class Worker ( Process ): \"\"\"Define a worker process. This worker process indefinitely waits for requests on a socket. Upon receiving a request, it processes it with the worker class provided, and return the response. After creating the Worker object, you have 2 different ways to run it : * `worker.run()` : It will run in the current process directly (blocking, infinite loop). * `worker.start()` : It will start a different process and start the code there (non-blocking). Args: worker_cls (Callable): Worker class containing the code that will be used to process requests. gibbs_host (str): Host of the Hub. Defaults to \"localhost\". gibbs_port (int): Port of the Hub. Defaults to DEFAULT_PORT. gibbs_heartbeat_interval (float): Heartbeat interval between the worker and the Hub. Defaults to DEFAULT_HEARTBEAT_INTERVAL. gibbs_reset_after_n_miss (int): Number of missed heartbeats allowed before hard-resetting the socket and retrying. Defaults to DEFAULT_RESET_AFTER_N_MISS. \"\"\" def __init__ ( self , worker_cls : Callable , * args : Any , gibbs_host : str = \"localhost\" , gibbs_port : int = DEFAULT_PORT , gibbs_heartbeat_interval : float = DEFAULT_HEARTBEAT_INTERVAL , gibbs_reset_after_n_miss : int = DEFAULT_RESET_AFTER_N_MISS , ** kwargs : Any , ): super () . __init__ () self . worker_cls = worker_cls self . worker_args = args self . worker_kwargs = kwargs self . identity = uuid . uuid4 () . hex self . host = gibbs_host self . port = gibbs_port self . heartbeat_t = gibbs_heartbeat_interval self . reset_n_miss = gibbs_reset_after_n_miss self . waiting_pong = 0 def create_socket ( self , context : zmq . Context ) -> zmq . Socket : \"\"\"Helper method to create a socket, setting its identity and connecting to the Hub. Args: context (zmq.Context): ZMQ context to use. Returns: zmq.Socket: Initialized and connected socket, ready to use. \"\"\" # Create the socket, set its identity socket = context . socket ( zmq . DEALER ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) return socket def ping ( self , socket : zmq . Socket ): \"\"\"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Args: socket (zmq.Socket): Socket to use to send the heartbeat. \"\"\" logger . debug ( \"Sending ping...\" ) socket . send ( PING ) self . waiting_pong += 1 def run ( self ): \"\"\"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. \"\"\" # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the socket context = zmq . Context () socket = self . create_socket ( context ) logger . info ( \"Worker ready to roll\" ) # Tell the Hub we are ready self . ping ( socket ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) if socket . poll ( self . heartbeat_t * MS , zmq . POLLIN ): _ , workload = socket . recv_multipart ( zmq . NOBLOCK ) logger . debug ( \"Received something !\" ) self . waiting_pong = 0 else : logger . debug ( f \"Didn't receive anything for { self . heartbeat_t } s ( { self . waiting_pong } )\" ) if self . waiting_pong >= self . reset_n_miss : logger . warning ( f \"The Hub is not answering, even after { self . waiting_pong } missed pings... \" f \"Resetting the socket\" ) socket . close ( linger = 0 ) socket = self . create_socket ( context ) self . waiting_pong = 0 # We didn't receive anything for some time, try to ping again self . ping ( socket ) continue if workload == PONG : # Just a Pong, ignore it logger . debug ( \"It was just a pong...\" ) continue # From here the Hub sent us an actual request req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments try : res = worker ( * req_args , ** req_kwargs ) except Exception as e : logger . warning ( f \"Exception in user-defined __call__ method : { e . __class__ . __name__ } ( { str ( e ) } )\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_FAILURE , traceback . format_exc ()])]) else : logger . debug ( \"Sending back the response\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_SUCCESS , res ])]) create_socket ( self , context ) Helper method to create a socket, setting its identity and connecting to the Hub. Parameters: Name Type Description Default context zmq.Context ZMQ context to use. required Returns: Type Description zmq.Socket Initialized and connected socket, ready to use. Source code in gibbs/worker.py def create_socket ( self , context : zmq . Context ) -> zmq . Socket : \"\"\"Helper method to create a socket, setting its identity and connecting to the Hub. Args: context (zmq.Context): ZMQ context to use. Returns: zmq.Socket: Initialized and connected socket, ready to use. \"\"\" # Create the socket, set its identity socket = context . socket ( zmq . DEALER ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) return socket ping ( self , socket ) Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Parameters: Name Type Description Default socket zmq.Socket Socket to use to send the heartbeat. required Source code in gibbs/worker.py def ping ( self , socket : zmq . Socket ): \"\"\"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Args: socket (zmq.Socket): Socket to use to send the heartbeat. \"\"\" logger . debug ( \"Sending ping...\" ) socket . send ( PING ) self . waiting_pong += 1 run ( self ) Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. Source code in gibbs/worker.py def run ( self ): \"\"\"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. \"\"\" # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the socket context = zmq . Context () socket = self . create_socket ( context ) logger . info ( \"Worker ready to roll\" ) # Tell the Hub we are ready self . ping ( socket ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) if socket . poll ( self . heartbeat_t * MS , zmq . POLLIN ): _ , workload = socket . recv_multipart ( zmq . NOBLOCK ) logger . debug ( \"Received something !\" ) self . waiting_pong = 0 else : logger . debug ( f \"Didn't receive anything for { self . heartbeat_t } s ( { self . waiting_pong } )\" ) if self . waiting_pong >= self . reset_n_miss : logger . warning ( f \"The Hub is not answering, even after { self . waiting_pong } missed pings... \" f \"Resetting the socket\" ) socket . close ( linger = 0 ) socket = self . create_socket ( context ) self . waiting_pong = 0 # We didn't receive anything for some time, try to ping again self . ping ( socket ) continue if workload == PONG : # Just a Pong, ignore it logger . debug ( \"It was just a pong...\" ) continue # From here the Hub sent us an actual request req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments try : res = worker ( * req_args , ** req_kwargs ) except Exception as e : logger . warning ( f \"Exception in user-defined __call__ method : { e . __class__ . __name__ } ( { str ( e ) } )\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_FAILURE , traceback . format_exc ()])]) else : logger . debug ( \"Sending back the response\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_SUCCESS , res ])]) Internal UserCodeException ( Exception ) Custom Exception for user-defined catched errors. Parameters: Name Type Description Default t str Traceback returned by the worker. required Source code in gibbs/hub.py class UserCodeException ( Exception ): \"\"\"Custom Exception for user-defined catched errors. Args: t (str): Traceback returned by the worker. \"\"\" def __init__ ( self , t : str ): super () . __init__ ( f \"Exception raised in user-defined code. Traceback : \\n { t } \" ) WorkerManager A helper class that takes care of managing workers. Workers' address can be registered as available, and this class will make sure to return address of workers that are available and alive. A worker is considered as dead if we didn't receive any heartbeat within a given interval. Parameters: Name Type Description Default heartbeat_interval float Interval of time (in seconds) after which we consider a worker to be dead. required Source code in gibbs/hub.py class WorkerManager : \"\"\"A helper class that takes care of managing workers. Workers' address can be registered as available, and this class will make sure to return address of workers that are available and alive. A worker is considered as dead if we didn't receive any heartbeat within a given interval. Args: heartbeat_interval (float): Interval of time (in seconds) after which we consider a worker to be dead. \"\"\" def __init__ ( self , heartbeat_interval : float ): super () . __init__ () self . heartbeat_t = heartbeat_interval self . w_ts = {} self . w_access = asyncio . Condition () async def reckon ( self , address : str ): \"\"\"Register the given address as available. Args: address (str): Address of the worker to register as available. \"\"\" async with self . w_access : self . w_ts [ address ] = time . time () self . w_access . notify () async def get_next_worker ( self ) -> str : \"\"\"Retrieve the next available and alive worker's address. Returns: str: Address of the available and alive worker. \"\"\" async with self . w_access : # Iterate workers until we find one that was alive recently w_alive = False while not w_alive : # If no workers are available, wait... if not self . w_ts : await self . w_access . wait () address , ts = self . w_ts . popitem () w_alive = time . time () - ts < self . heartbeat_t return address reckon ( self , address ) async Register the given address as available. Parameters: Name Type Description Default address str Address of the worker to register as available. required Source code in gibbs/hub.py async def reckon ( self , address : str ): \"\"\"Register the given address as available. Args: address (str): Address of the worker to register as available. \"\"\" async with self . w_access : self . w_ts [ address ] = time . time () self . w_access . notify () get_next_worker ( self ) async Retrieve the next available and alive worker's address. Returns: Type Description str Address of the available and alive worker. Source code in gibbs/hub.py async def get_next_worker ( self ) -> str : \"\"\"Retrieve the next available and alive worker's address. Returns: str: Address of the available and alive worker. \"\"\" async with self . w_access : # Iterate workers until we find one that was alive recently w_alive = False while not w_alive : # If no workers are available, wait... if not self . w_ts : await self . w_access . wait () address , ts = self . w_ts . popitem () w_alive = time . time () - ts < self . heartbeat_t return address RequestManager A helper class that takes care of storing responses and waiting for the right response. Parameters: Name Type Description Default resp_buffer_size int Maximum size of the response buffer. required Source code in gibbs/hub.py class RequestManager : \"\"\"A helper class that takes care of storing responses and waiting for the right response. Args: resp_buffer_size (int): Maximum size of the response buffer. \"\"\" def __init__ ( self , resp_buffer_size : int ): super () . __init__ () self . resp_buffer_size = resp_buffer_size self . responses = {} self . req_states = {} def pin ( self , req_id : str ): \"\"\"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each `req_id` before calling `wait_for`. Args: req_id (str): Request unique identifier. \"\"\" self . req_states [ req_id ] = asyncio . Event () # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None ) async def wait_for ( self , req_id : str ) -> Tuple [ int , Any ]: \"\"\"Async method that waits until we received the response corresponding to the given request ID. The method `pin` should be called before waiting with this method. Args: req_id (str): Request unique identifier. Raises: KeyError: Exception raised if the request wasn't registered previously. Returns: Tuple[int, Any]: Code and content of the received response. \"\"\" if req_id not in self . req_states : raise KeyError ( f \"Request # { req_id } was not pinned, or was removed because of buffer overflow\" ) # Wait for the receiving loop to receive the response await self . req_states [ req_id ] . wait () # Once we get it, access the result r = self . responses . pop ( req_id ) # Don't forget to remove the event self . req_states . pop ( req_id ) return r . code , r . content def store ( self , req_id : str , code : int , response : Any ): \"\"\"Store a response, to be consumed later. Args: req_id (str): Request unique identifier. code (int): Code of the response. response (Any): Content of the response. \"\"\" # Store the response if the req_id is recognized if req_id in self . req_states : self . responses [ req_id ] = Response ( code , response ) # Notify that we received the response self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" ) pin ( self , req_id ) Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each req_id before calling wait_for . Parameters: Name Type Description Default req_id str Request unique identifier. required Source code in gibbs/hub.py def pin ( self , req_id : str ): \"\"\"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each `req_id` before calling `wait_for`. Args: req_id (str): Request unique identifier. \"\"\" self . req_states [ req_id ] = asyncio . Event () # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None ) wait_for ( self , req_id ) async Async method that waits until we received the response corresponding to the given request ID. The method pin should be called before waiting with this method. Parameters: Name Type Description Default req_id str Request unique identifier. required Exceptions: Type Description KeyError Exception raised if the request wasn't registered previously. Returns: Type Description Tuple[int, Any] Code and content of the received response. Source code in gibbs/hub.py async def wait_for ( self , req_id : str ) -> Tuple [ int , Any ]: \"\"\"Async method that waits until we received the response corresponding to the given request ID. The method `pin` should be called before waiting with this method. Args: req_id (str): Request unique identifier. Raises: KeyError: Exception raised if the request wasn't registered previously. Returns: Tuple[int, Any]: Code and content of the received response. \"\"\" if req_id not in self . req_states : raise KeyError ( f \"Request # { req_id } was not pinned, or was removed because of buffer overflow\" ) # Wait for the receiving loop to receive the response await self . req_states [ req_id ] . wait () # Once we get it, access the result r = self . responses . pop ( req_id ) # Don't forget to remove the event self . req_states . pop ( req_id ) return r . code , r . content store ( self , req_id , code , response ) Store a response, to be consumed later. Parameters: Name Type Description Default req_id str Request unique identifier. required code int Code of the response. required response Any Content of the response. required Source code in gibbs/hub.py def store ( self , req_id : str , code : int , response : Any ): \"\"\"Store a response, to be consumed later. Args: req_id (str): Request unique identifier. code (int): Code of the response. response (Any): Content of the response. \"\"\" # Store the response if the req_id is recognized if req_id in self . req_states : self . responses [ req_id ] = Response ( code , response ) # Notify that we received the response self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" ) Constants RESPONSE_BUFFER_SIZE : int CODE_FAILURE : int CODE_SUCCESS : int DEFAULT_HEARTBEAT_INTERVAL : float DEFAULT_PORT : int DEFAULT_RESET_AFTER_N_MISS : int MS : int PING : bytes PONG : bytes","title":"Code reference"},{"location":"code_ref/#code-reference","text":"","title":"Code reference"},{"location":"code_ref/#api","text":"","title":"API"},{"location":"code_ref/#gibbs.hub.Hub","text":"Class acting as a hub for all the requests to send. All requests sent through this class will be automatically dispatched to connected workers, will wait for the responses and return it. Parameters: Name Type Description Default port int Port number to use for the sockets. Defaults to DEFAULT_PORT. 5019 heartbeat_interval float Heartbeat interval used by the workers, in seconds. Defaults to DEFAULT_HEARTBEAT_INTERVAL. 1 resp_buffer_size int Maximum response buffer size. Defaults to RESPONSE_BUFFER_SIZE. 4096 Source code in gibbs/hub.py class Hub : \"\"\"Class acting as a hub for all the requests to send. All requests sent through this class will be automatically dispatched to connected workers, will wait for the responses and return it. Args: port (int): Port number to use for the sockets. Defaults to DEFAULT_PORT. heartbeat_interval (float): Heartbeat interval used by the workers, in seconds. Defaults to DEFAULT_HEARTBEAT_INTERVAL. resp_buffer_size (int): Maximum response buffer size. Defaults to RESPONSE_BUFFER_SIZE. \"\"\" def __init__ ( self , port : int = DEFAULT_PORT , heartbeat_interval : float = DEFAULT_HEARTBEAT_INTERVAL , resp_buffer_size : int = RESPONSE_BUFFER_SIZE , ): super () . __init__ () self . port = port self . heartbeat_t = heartbeat_interval self . socket = None self . w_manager = None self . req_manager = RequestManager ( resp_buffer_size = resp_buffer_size ) async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff logger . debug ( \"Receiving...\" ) address , * frames = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . w_manager . reckon ( address ) if len ( frames ) == 1 : # Answer the Ping logger . debug ( \"Answering the ping\" ) await self . socket . send_multipart ([ address , b \"\" , PONG ]) continue _ , resp = frames req_id , code , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) self . req_manager . store ( req_id , code , res ) def _start_if_not_started ( self ): \"\"\"Helper method to ensure everything is properly started (socket is initialized, receiving loop is started, etc...). \"\"\" if self . socket is None : # Create what we need here in this process/context context = zmq . asyncio . Context () self . socket = context . socket ( zmq . ROUTER ) self . socket . bind ( f \"tcp://*: { self . port } \" ) self . w_manager = WorkerManager ( heartbeat_interval = self . heartbeat_t ) # Fire and forget : infinite loop, taking care of receiving stuff from the socket logger . info ( \"Starting receiving loop...\" ) asyncio . create_task ( self . receive_loop ()) async def _request ( self , * args : Any , ** kwargs : Any ) -> Any : \"\"\"Raw method to send a request. This method will do the following : * Start the receiving loop if it was not started * Get the address of the next worker ready (blocking) * Send the request to the worker * Wait for the response (blocking) * Return the result Args: *args: Positional arguments for the request. **kwargs: Keywords arguments for the request. Raises: UserCodeException: Exception raised if an exception was raised inside user-defined code on the worker side. Returns: Any: The response for the request. \"\"\" # Before anything, if the receiving loop was not started, start it self . _start_if_not_started () # Assign a unique ID to the request req_id = uuid . uuid4 () . hex # Let the manager know that we are waiting for this request logger . debug ( f \"Pinning request # { req_id } \" ) self . req_manager . pin ( req_id ) # Send the request address = await self . w_manager . get_next_worker () logger . debug ( f \"Sending request # { req_id } to worker # { address } \" ) await self . socket . send_multipart ([ address , b \"\" , msgpack . packb ([ req_id , args , kwargs ])]) # Wait until we receive the response code , res = await self . req_manager . wait_for ( req_id ) logger . debug ( f \"Received result for request # { req_id } \" ) # Depending on what is the response, deal with it properly if code == CODE_FAILURE : raise UserCodeException ( res ) else : return res async def request ( self , * args : Any , gibbs_timeout : float = None , gibbs_retries : int = 0 , ** kwargs : Any ) -> Any : \"\"\"Main method, used to send a request to workers and get the result. This method is a wrapper around `_request`, providing additional functionalities : * Timeout * Automatic retries Args: *args: Positional arguments for the request. gibbs_timeout (float): Timeout for the request, in seconds. If `None` is given, block until the request is complete. Defaults to None. gibbs_retries (int): Number of retries. This argument is used only if `gibbs_timeout` is not `None`. If `-1` is given, indefinitely retry. Defaults to 0. **kwargs: Keywords arguments for the request. Raises: asyncio.TimeoutError: Error raised if no response is received within the given timeout. Returns: Any: The response for the request. \"\"\" try : return await asyncio . wait_for ( self . _request ( * args , ** kwargs ), timeout = gibbs_timeout ) except asyncio . TimeoutError : if gibbs_retries == 0 : logger . error ( f \"Request failed : no response received within { gibbs_timeout } s\" ) raise else : retries_left = max ( gibbs_retries - 1 , - 1 ) logger . warning ( f \"Request failed : no response received within { gibbs_timeout } s. Retrying { retries_left } times\" ) return await self . request ( * args , gibbs_timeout = gibbs_timeout , gibbs_retries = retries_left , ** kwargs ) def __del__ ( self ): if self . socket is not None : self . socket . close ()","title":"Hub"},{"location":"code_ref/#gibbs.hub.Hub.receive_loop","text":"Infinite loop for receiving responses from the workers. Source code in gibbs/hub.py async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff logger . debug ( \"Receiving...\" ) address , * frames = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . w_manager . reckon ( address ) if len ( frames ) == 1 : # Answer the Ping logger . debug ( \"Answering the ping\" ) await self . socket . send_multipart ([ address , b \"\" , PONG ]) continue _ , resp = frames req_id , code , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) self . req_manager . store ( req_id , code , res )","title":"receive_loop()"},{"location":"code_ref/#gibbs.hub.Hub.request","text":"Main method, used to send a request to workers and get the result. This method is a wrapper around _request , providing additional functionalities : * Timeout * Automatic retries Parameters: Name Type Description Default *args Any Positional arguments for the request. () gibbs_timeout float Timeout for the request, in seconds. If None is given, block until the request is complete. Defaults to None. None gibbs_retries int Number of retries. This argument is used only if gibbs_timeout is not None . If -1 is given, indefinitely retry. Defaults to 0. 0 **kwargs Any Keywords arguments for the request. {} Exceptions: Type Description asyncio.TimeoutError Error raised if no response is received within the given timeout. Returns: Type Description Any The response for the request. Source code in gibbs/hub.py async def request ( self , * args : Any , gibbs_timeout : float = None , gibbs_retries : int = 0 , ** kwargs : Any ) -> Any : \"\"\"Main method, used to send a request to workers and get the result. This method is a wrapper around `_request`, providing additional functionalities : * Timeout * Automatic retries Args: *args: Positional arguments for the request. gibbs_timeout (float): Timeout for the request, in seconds. If `None` is given, block until the request is complete. Defaults to None. gibbs_retries (int): Number of retries. This argument is used only if `gibbs_timeout` is not `None`. If `-1` is given, indefinitely retry. Defaults to 0. **kwargs: Keywords arguments for the request. Raises: asyncio.TimeoutError: Error raised if no response is received within the given timeout. Returns: Any: The response for the request. \"\"\" try : return await asyncio . wait_for ( self . _request ( * args , ** kwargs ), timeout = gibbs_timeout ) except asyncio . TimeoutError : if gibbs_retries == 0 : logger . error ( f \"Request failed : no response received within { gibbs_timeout } s\" ) raise else : retries_left = max ( gibbs_retries - 1 , - 1 ) logger . warning ( f \"Request failed : no response received within { gibbs_timeout } s. Retrying { retries_left } times\" ) return await self . request ( * args , gibbs_timeout = gibbs_timeout , gibbs_retries = retries_left , ** kwargs )","title":"request()"},{"location":"code_ref/#gibbs.worker.Worker","text":"Define a worker process. This worker process indefinitely waits for requests on a socket. Upon receiving a request, it processes it with the worker class provided, and return the response. After creating the Worker object, you have 2 different ways to run it : * worker.run() : It will run in the current process directly (blocking, infinite loop). * worker.start() : It will start a different process and start the code there (non-blocking). Parameters: Name Type Description Default worker_cls Callable Worker class containing the code that will be used to process requests. required gibbs_host str Host of the Hub. Defaults to \"localhost\". 'localhost' gibbs_port int Port of the Hub. Defaults to DEFAULT_PORT. 5019 gibbs_heartbeat_interval float Heartbeat interval between the worker and the Hub. Defaults to DEFAULT_HEARTBEAT_INTERVAL. 1 gibbs_reset_after_n_miss int Number of missed heartbeats allowed before hard-resetting the socket and retrying. Defaults to DEFAULT_RESET_AFTER_N_MISS. 2 Source code in gibbs/worker.py class Worker ( Process ): \"\"\"Define a worker process. This worker process indefinitely waits for requests on a socket. Upon receiving a request, it processes it with the worker class provided, and return the response. After creating the Worker object, you have 2 different ways to run it : * `worker.run()` : It will run in the current process directly (blocking, infinite loop). * `worker.start()` : It will start a different process and start the code there (non-blocking). Args: worker_cls (Callable): Worker class containing the code that will be used to process requests. gibbs_host (str): Host of the Hub. Defaults to \"localhost\". gibbs_port (int): Port of the Hub. Defaults to DEFAULT_PORT. gibbs_heartbeat_interval (float): Heartbeat interval between the worker and the Hub. Defaults to DEFAULT_HEARTBEAT_INTERVAL. gibbs_reset_after_n_miss (int): Number of missed heartbeats allowed before hard-resetting the socket and retrying. Defaults to DEFAULT_RESET_AFTER_N_MISS. \"\"\" def __init__ ( self , worker_cls : Callable , * args : Any , gibbs_host : str = \"localhost\" , gibbs_port : int = DEFAULT_PORT , gibbs_heartbeat_interval : float = DEFAULT_HEARTBEAT_INTERVAL , gibbs_reset_after_n_miss : int = DEFAULT_RESET_AFTER_N_MISS , ** kwargs : Any , ): super () . __init__ () self . worker_cls = worker_cls self . worker_args = args self . worker_kwargs = kwargs self . identity = uuid . uuid4 () . hex self . host = gibbs_host self . port = gibbs_port self . heartbeat_t = gibbs_heartbeat_interval self . reset_n_miss = gibbs_reset_after_n_miss self . waiting_pong = 0 def create_socket ( self , context : zmq . Context ) -> zmq . Socket : \"\"\"Helper method to create a socket, setting its identity and connecting to the Hub. Args: context (zmq.Context): ZMQ context to use. Returns: zmq.Socket: Initialized and connected socket, ready to use. \"\"\" # Create the socket, set its identity socket = context . socket ( zmq . DEALER ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) return socket def ping ( self , socket : zmq . Socket ): \"\"\"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Args: socket (zmq.Socket): Socket to use to send the heartbeat. \"\"\" logger . debug ( \"Sending ping...\" ) socket . send ( PING ) self . waiting_pong += 1 def run ( self ): \"\"\"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. \"\"\" # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the socket context = zmq . Context () socket = self . create_socket ( context ) logger . info ( \"Worker ready to roll\" ) # Tell the Hub we are ready self . ping ( socket ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) if socket . poll ( self . heartbeat_t * MS , zmq . POLLIN ): _ , workload = socket . recv_multipart ( zmq . NOBLOCK ) logger . debug ( \"Received something !\" ) self . waiting_pong = 0 else : logger . debug ( f \"Didn't receive anything for { self . heartbeat_t } s ( { self . waiting_pong } )\" ) if self . waiting_pong >= self . reset_n_miss : logger . warning ( f \"The Hub is not answering, even after { self . waiting_pong } missed pings... \" f \"Resetting the socket\" ) socket . close ( linger = 0 ) socket = self . create_socket ( context ) self . waiting_pong = 0 # We didn't receive anything for some time, try to ping again self . ping ( socket ) continue if workload == PONG : # Just a Pong, ignore it logger . debug ( \"It was just a pong...\" ) continue # From here the Hub sent us an actual request req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments try : res = worker ( * req_args , ** req_kwargs ) except Exception as e : logger . warning ( f \"Exception in user-defined __call__ method : { e . __class__ . __name__ } ( { str ( e ) } )\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_FAILURE , traceback . format_exc ()])]) else : logger . debug ( \"Sending back the response\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_SUCCESS , res ])])","title":"Worker"},{"location":"code_ref/#gibbs.worker.Worker.create_socket","text":"Helper method to create a socket, setting its identity and connecting to the Hub. Parameters: Name Type Description Default context zmq.Context ZMQ context to use. required Returns: Type Description zmq.Socket Initialized and connected socket, ready to use. Source code in gibbs/worker.py def create_socket ( self , context : zmq . Context ) -> zmq . Socket : \"\"\"Helper method to create a socket, setting its identity and connecting to the Hub. Args: context (zmq.Context): ZMQ context to use. Returns: zmq.Socket: Initialized and connected socket, ready to use. \"\"\" # Create the socket, set its identity socket = context . socket ( zmq . DEALER ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) return socket","title":"create_socket()"},{"location":"code_ref/#gibbs.worker.Worker.ping","text":"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Parameters: Name Type Description Default socket zmq.Socket Socket to use to send the heartbeat. required Source code in gibbs/worker.py def ping ( self , socket : zmq . Socket ): \"\"\"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Args: socket (zmq.Socket): Socket to use to send the heartbeat. \"\"\" logger . debug ( \"Sending ping...\" ) socket . send ( PING ) self . waiting_pong += 1","title":"ping()"},{"location":"code_ref/#gibbs.worker.Worker.run","text":"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. Source code in gibbs/worker.py def run ( self ): \"\"\"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. \"\"\" # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the socket context = zmq . Context () socket = self . create_socket ( context ) logger . info ( \"Worker ready to roll\" ) # Tell the Hub we are ready self . ping ( socket ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) if socket . poll ( self . heartbeat_t * MS , zmq . POLLIN ): _ , workload = socket . recv_multipart ( zmq . NOBLOCK ) logger . debug ( \"Received something !\" ) self . waiting_pong = 0 else : logger . debug ( f \"Didn't receive anything for { self . heartbeat_t } s ( { self . waiting_pong } )\" ) if self . waiting_pong >= self . reset_n_miss : logger . warning ( f \"The Hub is not answering, even after { self . waiting_pong } missed pings... \" f \"Resetting the socket\" ) socket . close ( linger = 0 ) socket = self . create_socket ( context ) self . waiting_pong = 0 # We didn't receive anything for some time, try to ping again self . ping ( socket ) continue if workload == PONG : # Just a Pong, ignore it logger . debug ( \"It was just a pong...\" ) continue # From here the Hub sent us an actual request req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments try : res = worker ( * req_args , ** req_kwargs ) except Exception as e : logger . warning ( f \"Exception in user-defined __call__ method : { e . __class__ . __name__ } ( { str ( e ) } )\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_FAILURE , traceback . format_exc ()])]) else : logger . debug ( \"Sending back the response\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_SUCCESS , res ])])","title":"run()"},{"location":"code_ref/#internal","text":"","title":"Internal"},{"location":"code_ref/#gibbs.hub.UserCodeException","text":"Custom Exception for user-defined catched errors. Parameters: Name Type Description Default t str Traceback returned by the worker. required Source code in gibbs/hub.py class UserCodeException ( Exception ): \"\"\"Custom Exception for user-defined catched errors. Args: t (str): Traceback returned by the worker. \"\"\" def __init__ ( self , t : str ): super () . __init__ ( f \"Exception raised in user-defined code. Traceback : \\n { t } \" )","title":"UserCodeException"},{"location":"code_ref/#gibbs.hub.WorkerManager","text":"A helper class that takes care of managing workers. Workers' address can be registered as available, and this class will make sure to return address of workers that are available and alive. A worker is considered as dead if we didn't receive any heartbeat within a given interval. Parameters: Name Type Description Default heartbeat_interval float Interval of time (in seconds) after which we consider a worker to be dead. required Source code in gibbs/hub.py class WorkerManager : \"\"\"A helper class that takes care of managing workers. Workers' address can be registered as available, and this class will make sure to return address of workers that are available and alive. A worker is considered as dead if we didn't receive any heartbeat within a given interval. Args: heartbeat_interval (float): Interval of time (in seconds) after which we consider a worker to be dead. \"\"\" def __init__ ( self , heartbeat_interval : float ): super () . __init__ () self . heartbeat_t = heartbeat_interval self . w_ts = {} self . w_access = asyncio . Condition () async def reckon ( self , address : str ): \"\"\"Register the given address as available. Args: address (str): Address of the worker to register as available. \"\"\" async with self . w_access : self . w_ts [ address ] = time . time () self . w_access . notify () async def get_next_worker ( self ) -> str : \"\"\"Retrieve the next available and alive worker's address. Returns: str: Address of the available and alive worker. \"\"\" async with self . w_access : # Iterate workers until we find one that was alive recently w_alive = False while not w_alive : # If no workers are available, wait... if not self . w_ts : await self . w_access . wait () address , ts = self . w_ts . popitem () w_alive = time . time () - ts < self . heartbeat_t return address","title":"WorkerManager"},{"location":"code_ref/#gibbs.hub.WorkerManager.reckon","text":"Register the given address as available. Parameters: Name Type Description Default address str Address of the worker to register as available. required Source code in gibbs/hub.py async def reckon ( self , address : str ): \"\"\"Register the given address as available. Args: address (str): Address of the worker to register as available. \"\"\" async with self . w_access : self . w_ts [ address ] = time . time () self . w_access . notify ()","title":"reckon()"},{"location":"code_ref/#gibbs.hub.WorkerManager.get_next_worker","text":"Retrieve the next available and alive worker's address. Returns: Type Description str Address of the available and alive worker. Source code in gibbs/hub.py async def get_next_worker ( self ) -> str : \"\"\"Retrieve the next available and alive worker's address. Returns: str: Address of the available and alive worker. \"\"\" async with self . w_access : # Iterate workers until we find one that was alive recently w_alive = False while not w_alive : # If no workers are available, wait... if not self . w_ts : await self . w_access . wait () address , ts = self . w_ts . popitem () w_alive = time . time () - ts < self . heartbeat_t return address","title":"get_next_worker()"},{"location":"code_ref/#gibbs.hub.RequestManager","text":"A helper class that takes care of storing responses and waiting for the right response. Parameters: Name Type Description Default resp_buffer_size int Maximum size of the response buffer. required Source code in gibbs/hub.py class RequestManager : \"\"\"A helper class that takes care of storing responses and waiting for the right response. Args: resp_buffer_size (int): Maximum size of the response buffer. \"\"\" def __init__ ( self , resp_buffer_size : int ): super () . __init__ () self . resp_buffer_size = resp_buffer_size self . responses = {} self . req_states = {} def pin ( self , req_id : str ): \"\"\"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each `req_id` before calling `wait_for`. Args: req_id (str): Request unique identifier. \"\"\" self . req_states [ req_id ] = asyncio . Event () # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None ) async def wait_for ( self , req_id : str ) -> Tuple [ int , Any ]: \"\"\"Async method that waits until we received the response corresponding to the given request ID. The method `pin` should be called before waiting with this method. Args: req_id (str): Request unique identifier. Raises: KeyError: Exception raised if the request wasn't registered previously. Returns: Tuple[int, Any]: Code and content of the received response. \"\"\" if req_id not in self . req_states : raise KeyError ( f \"Request # { req_id } was not pinned, or was removed because of buffer overflow\" ) # Wait for the receiving loop to receive the response await self . req_states [ req_id ] . wait () # Once we get it, access the result r = self . responses . pop ( req_id ) # Don't forget to remove the event self . req_states . pop ( req_id ) return r . code , r . content def store ( self , req_id : str , code : int , response : Any ): \"\"\"Store a response, to be consumed later. Args: req_id (str): Request unique identifier. code (int): Code of the response. response (Any): Content of the response. \"\"\" # Store the response if the req_id is recognized if req_id in self . req_states : self . responses [ req_id ] = Response ( code , response ) # Notify that we received the response self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" )","title":"RequestManager"},{"location":"code_ref/#gibbs.hub.RequestManager.pin","text":"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each req_id before calling wait_for . Parameters: Name Type Description Default req_id str Request unique identifier. required Source code in gibbs/hub.py def pin ( self , req_id : str ): \"\"\"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each `req_id` before calling `wait_for`. Args: req_id (str): Request unique identifier. \"\"\" self . req_states [ req_id ] = asyncio . Event () # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None )","title":"pin()"},{"location":"code_ref/#gibbs.hub.RequestManager.wait_for","text":"Async method that waits until we received the response corresponding to the given request ID. The method pin should be called before waiting with this method. Parameters: Name Type Description Default req_id str Request unique identifier. required Exceptions: Type Description KeyError Exception raised if the request wasn't registered previously. Returns: Type Description Tuple[int, Any] Code and content of the received response. Source code in gibbs/hub.py async def wait_for ( self , req_id : str ) -> Tuple [ int , Any ]: \"\"\"Async method that waits until we received the response corresponding to the given request ID. The method `pin` should be called before waiting with this method. Args: req_id (str): Request unique identifier. Raises: KeyError: Exception raised if the request wasn't registered previously. Returns: Tuple[int, Any]: Code and content of the received response. \"\"\" if req_id not in self . req_states : raise KeyError ( f \"Request # { req_id } was not pinned, or was removed because of buffer overflow\" ) # Wait for the receiving loop to receive the response await self . req_states [ req_id ] . wait () # Once we get it, access the result r = self . responses . pop ( req_id ) # Don't forget to remove the event self . req_states . pop ( req_id ) return r . code , r . content","title":"wait_for()"},{"location":"code_ref/#gibbs.hub.RequestManager.store","text":"Store a response, to be consumed later. Parameters: Name Type Description Default req_id str Request unique identifier. required code int Code of the response. required response Any Content of the response. required Source code in gibbs/hub.py def store ( self , req_id : str , code : int , response : Any ): \"\"\"Store a response, to be consumed later. Args: req_id (str): Request unique identifier. code (int): Code of the response. response (Any): Content of the response. \"\"\" # Store the response if the req_id is recognized if req_id in self . req_states : self . responses [ req_id ] = Response ( code , response ) # Notify that we received the response self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" )","title":"store()"},{"location":"code_ref/#constants","text":"","title":"Constants"},{"location":"code_ref/#gibbs.hub.RESPONSE_BUFFER_SIZE","text":"","title":"RESPONSE_BUFFER_SIZE"},{"location":"code_ref/#gibbs.worker.CODE_FAILURE","text":"","title":"CODE_FAILURE"},{"location":"code_ref/#gibbs.worker.CODE_SUCCESS","text":"","title":"CODE_SUCCESS"},{"location":"code_ref/#gibbs.worker.DEFAULT_HEARTBEAT_INTERVAL","text":"","title":"DEFAULT_HEARTBEAT_INTERVAL"},{"location":"code_ref/#gibbs.worker.DEFAULT_PORT","text":"","title":"DEFAULT_PORT"},{"location":"code_ref/#gibbs.worker.DEFAULT_RESET_AFTER_N_MISS","text":"","title":"DEFAULT_RESET_AFTER_N_MISS"},{"location":"code_ref/#gibbs.worker.MS","text":"","title":"MS"},{"location":"code_ref/#gibbs.worker.PING","text":"","title":"PING"},{"location":"code_ref/#gibbs.worker.PONG","text":"","title":"PONG"},{"location":"examples/","text":"Examples All examples are located in the examples/ folder. All examples can be run directly without any arguments. You can experiment new settings by changing the constants inside the scripts. Important Some examples require additional dependencies. You can install these dependencies with pip install gibbs[ex] (see Installation ) vanilla_fastapi.py python examples/vanilla_fastapi.py This example simply creates a FastAPI application with a dummy model. The dummy model simulate some computations time. The script will measure the time needed to send and receive 10 requests. gibbs_fastapi.py python examples/gibbs_fastapi.py This example is the same as vanilla_fastapi.py , but it uses gibbs to scale up the dummy model (with 2 workers). The script will also measure the time needed to send and receive 10 requests, so you can compare the results with the vanilla approach. transformer.py python examples/transformer.py A more \"real-life\" application, where we use a BART model (from transformers library) along with gibbs for scaling up text-summarization.","title":"Examples"},{"location":"examples/#examples","text":"All examples are located in the examples/ folder. All examples can be run directly without any arguments. You can experiment new settings by changing the constants inside the scripts. Important Some examples require additional dependencies. You can install these dependencies with pip install gibbs[ex] (see Installation )","title":"Examples"},{"location":"examples/#vanilla_fastapipy","text":"python examples/vanilla_fastapi.py This example simply creates a FastAPI application with a dummy model. The dummy model simulate some computations time. The script will measure the time needed to send and receive 10 requests.","title":"vanilla_fastapi.py"},{"location":"examples/#gibbs_fastapipy","text":"python examples/gibbs_fastapi.py This example is the same as vanilla_fastapi.py , but it uses gibbs to scale up the dummy model (with 2 workers). The script will also measure the time needed to send and receive 10 requests, so you can compare the results with the vanilla approach.","title":"gibbs_fastapi.py"},{"location":"examples/#transformerpy","text":"python examples/transformer.py A more \"real-life\" application, where we use a BART model (from transformers library) along with gibbs for scaling up text-summarization.","title":"transformer.py"},{"location":"usage/","text":"Usage Let's walk-through an example of how to scale a FastAPI application together ! Note Here we use FastAPI to show how easy it is to integrate gibbs in an asynchronous framework, but gibbs can be used like any asynchronous python code ! Initial application Let's take a simple example to see how we can scale with gibbs . Say we have developed a great ML model. For the simplicity of this example, here is the code of a dummy model : import time class MyAwesomeModel : def __init__ ( self , wait_time = 0.25 ): super () . __init__ () self . w = wait_time def __call__ ( self , x ): time . sleep ( self . w ) return x ** 2 This model simply return the squared input, after simulating a certain processing time. Now, having a model is great, but we want to make it available to our users. To do that, we create an API using FastAPI, serving that model. Here is the code : import time import uvicorn from fastapi import FastAPI class MyAwesomeModel : def __init__ ( self , wait_time = 0.25 ): super () . __init__ () self . w = wait_time def __call__ ( self , x ): time . sleep ( self . w ) return x ** 2 # Instanciate FastAPI app and instanciate our model app = FastAPI () model = MyAwesomeModel () # Define a route that will call our model and return the result @app . get ( \"/request\" ) async def simple_request ( x : int ): return { \"result\" : model ( x )} if __name__ == \"__main__\" : # Run the app uvicorn . run ( app , host = \"0.0.0.0\" , port = 8000 ) You can run this python script and access http://localhost:8000/docs to try the route by yourself. Great ! We are serving our awesome model ! The scaling issue This code is great, but it does not scale. Because our model takes 250ms to deal with every request, you can imagine what happen when 10 clients send one request at the same time... One of the client will have to wait 2.5s before receiving a response ! You can try this out by starting our simple app, and in another terminal, run the following script : import multiprocessing as mp import time import requests def req_process ( i ): r = requests . get ( f \"http://localhost:8000/request?x= { i } \" ) assert r . status_code == 200 return r . json () def time_parallel_requests ( n ): with mp . Pool ( n ) as p : t0 = time . time () p . map ( req_process , range ( n )) t1 = time . time () return t1 - t0 if __name__ == \"__main__\" : t = time_parallel_requests ( 10 ) print ( f \"It tooks { t : .3f } s to process 10 requests\" ) This script simply run 10 requests in parallel and print the time necessary to complete all of them. And as expected : It tooks 2.532s to process 10 requests How gibbs works What we want is simply to have pool of several models, and when one model is busy dealing with a request, instead of waiting for it to finish, we want to call another (idle) model. So we can deal with several requests in parallel, and therefore serve several clients with a low latency ! To achieve this, gibbs introduces 2 classes : Hub Worker The Worker class is just a process, dealing with requests sequentially by calling the awesome model you created. The Hub is the class that orchestrate the requests, sending each request to the right worker (currently idle). Hint You can see a more detailed description of how this work in Architecture Use gibbs to scale up Let's see how to modify our simple app to scale up. We simply have to create a Hub and use it to send requests, and start a few workers with our awesome model ! import time import uvicorn from fastapi import FastAPI from gibbs import Hub , Worker class MyAwesomeModel : def __init__ ( self , wait_time = 0.25 ): super () . __init__ () self . w = wait_time def __call__ ( self , x ): time . sleep ( self . w ) return x ** 2 # Instanciate FastAPI app and instanciate the Hub app = FastAPI () hub = Hub () # Define a route that will call our model and return the result @app . get ( \"/request\" ) async def simple_request ( x : int ): return { \"result\" : await hub . request ( x )} if __name__ == \"__main__\" : # Start the workers (in another process) workers = [ Worker ( MyAwesomeModel ) for _ in range ( 4 )] for w in workers : w . start () # Run the app uvicorn . run ( app , host = \"0.0.0.0\" , port = 8000 ) Quite simple, right ? Now, if we use the same script as before to run 10 requests in parallel in another terminal : It tooks 0.855s to process 10 requests The time needed to deal with 10 requests is greatly reduced, by sharing the work between the 4 workers !","title":"Usage"},{"location":"usage/#usage","text":"Let's walk-through an example of how to scale a FastAPI application together ! Note Here we use FastAPI to show how easy it is to integrate gibbs in an asynchronous framework, but gibbs can be used like any asynchronous python code !","title":"Usage"},{"location":"usage/#initial-application","text":"Let's take a simple example to see how we can scale with gibbs . Say we have developed a great ML model. For the simplicity of this example, here is the code of a dummy model : import time class MyAwesomeModel : def __init__ ( self , wait_time = 0.25 ): super () . __init__ () self . w = wait_time def __call__ ( self , x ): time . sleep ( self . w ) return x ** 2 This model simply return the squared input, after simulating a certain processing time. Now, having a model is great, but we want to make it available to our users. To do that, we create an API using FastAPI, serving that model. Here is the code : import time import uvicorn from fastapi import FastAPI class MyAwesomeModel : def __init__ ( self , wait_time = 0.25 ): super () . __init__ () self . w = wait_time def __call__ ( self , x ): time . sleep ( self . w ) return x ** 2 # Instanciate FastAPI app and instanciate our model app = FastAPI () model = MyAwesomeModel () # Define a route that will call our model and return the result @app . get ( \"/request\" ) async def simple_request ( x : int ): return { \"result\" : model ( x )} if __name__ == \"__main__\" : # Run the app uvicorn . run ( app , host = \"0.0.0.0\" , port = 8000 ) You can run this python script and access http://localhost:8000/docs to try the route by yourself. Great ! We are serving our awesome model !","title":"Initial application"},{"location":"usage/#the-scaling-issue","text":"This code is great, but it does not scale. Because our model takes 250ms to deal with every request, you can imagine what happen when 10 clients send one request at the same time... One of the client will have to wait 2.5s before receiving a response ! You can try this out by starting our simple app, and in another terminal, run the following script : import multiprocessing as mp import time import requests def req_process ( i ): r = requests . get ( f \"http://localhost:8000/request?x= { i } \" ) assert r . status_code == 200 return r . json () def time_parallel_requests ( n ): with mp . Pool ( n ) as p : t0 = time . time () p . map ( req_process , range ( n )) t1 = time . time () return t1 - t0 if __name__ == \"__main__\" : t = time_parallel_requests ( 10 ) print ( f \"It tooks { t : .3f } s to process 10 requests\" ) This script simply run 10 requests in parallel and print the time necessary to complete all of them. And as expected : It tooks 2.532s to process 10 requests","title":"The scaling issue"},{"location":"usage/#how-gibbs-works","text":"What we want is simply to have pool of several models, and when one model is busy dealing with a request, instead of waiting for it to finish, we want to call another (idle) model. So we can deal with several requests in parallel, and therefore serve several clients with a low latency ! To achieve this, gibbs introduces 2 classes : Hub Worker The Worker class is just a process, dealing with requests sequentially by calling the awesome model you created. The Hub is the class that orchestrate the requests, sending each request to the right worker (currently idle). Hint You can see a more detailed description of how this work in Architecture","title":"How gibbs works"},{"location":"usage/#use-gibbs-to-scale-up","text":"Let's see how to modify our simple app to scale up. We simply have to create a Hub and use it to send requests, and start a few workers with our awesome model ! import time import uvicorn from fastapi import FastAPI from gibbs import Hub , Worker class MyAwesomeModel : def __init__ ( self , wait_time = 0.25 ): super () . __init__ () self . w = wait_time def __call__ ( self , x ): time . sleep ( self . w ) return x ** 2 # Instanciate FastAPI app and instanciate the Hub app = FastAPI () hub = Hub () # Define a route that will call our model and return the result @app . get ( \"/request\" ) async def simple_request ( x : int ): return { \"result\" : await hub . request ( x )} if __name__ == \"__main__\" : # Start the workers (in another process) workers = [ Worker ( MyAwesomeModel ) for _ in range ( 4 )] for w in workers : w . start () # Run the app uvicorn . run ( app , host = \"0.0.0.0\" , port = 8000 ) Quite simple, right ? Now, if we use the same script as before to run 10 requests in parallel in another terminal : It tooks 0.855s to process 10 requests The time needed to deal with 10 requests is greatly reduced, by sharing the work between the 4 workers !","title":"Use gibbs to scale up"}]}