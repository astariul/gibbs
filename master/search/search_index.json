{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Pytere Introduction Welcome to the documentation of the pytere package. pytere ( Py thon te mplate re pository) is simply a template repository for python packages. This full-fledged template provides you with everything you need ( documentation, unit-tests, code linting & formatting, pre-commit hooks, etc... ) so you can just focus on writing the code. If you want to use this template, follow the instructions at the Usage page. Installation Latest version You can install the latest version of the package directly from PyPi with : pip install pytere Hint If you want to install directly from Github, run : pip install git+https://github.com/astariul/pytere.git Specific version You can install a specific version of the package ( 0.1.0 in ths example) from PyPi with : pip install pytere == 0 .1.0 Hint If you want to install directly from Github, run : pip install git+https://github.com/astariul/pytere.git@v0.1.0 Local You can also clone the repository locally and install it manually : git clone https://github.com/astariul/pytere.git cd pytere pip install -e . Extra dependencies You can also install extras dependencies, for example : pip install -e . [ docs ] Will install necessary dependencies for building the docs. Hint If you installed the package directly from github, run : pip install \"pytere[docs] @ git+https://github.com/astariul/pytere.git\" List of extra dependencies : test : Dependencies for running unit-tests. hook : Dependencies for running pre-commit hooks. lint : Dependencies for running linters and formatters. docs : Dependencies for building the documentation. dev : test + hook + lint + docs . all : All extra dependencies. Contribute To contribute, install the package locally (see Installation ), create your own branch, add your code/tests/documentation, and open a PR ! Pre-commit hooks Pre-commit hooks are set to check the code added whenever you commit something. When you try to commit your code, hooks are run, and if anything fails ( linters, tests, etc... ), your code will not be committed. You then have to fix your code and try to commit again ! Info If you never ran the hooks before, install it with : pre-commit install Documentation When you contribute, make sure to keep the documentation up-to-date. You can visualize the documentation locally by running : mkdocs serve","title":"Welcome"},{"location":"#pytere","text":"","title":"Pytere"},{"location":"#introduction","text":"Welcome to the documentation of the pytere package. pytere ( Py thon te mplate re pository) is simply a template repository for python packages. This full-fledged template provides you with everything you need ( documentation, unit-tests, code linting & formatting, pre-commit hooks, etc... ) so you can just focus on writing the code. If you want to use this template, follow the instructions at the Usage page.","title":"Introduction"},{"location":"#installation","text":"","title":"Installation"},{"location":"#latest-version","text":"You can install the latest version of the package directly from PyPi with : pip install pytere Hint If you want to install directly from Github, run : pip install git+https://github.com/astariul/pytere.git","title":"Latest version"},{"location":"#specific-version","text":"You can install a specific version of the package ( 0.1.0 in ths example) from PyPi with : pip install pytere == 0 .1.0 Hint If you want to install directly from Github, run : pip install git+https://github.com/astariul/pytere.git@v0.1.0","title":"Specific version"},{"location":"#local","text":"You can also clone the repository locally and install it manually : git clone https://github.com/astariul/pytere.git cd pytere pip install -e .","title":"Local"},{"location":"#extra-dependencies","text":"You can also install extras dependencies, for example : pip install -e . [ docs ] Will install necessary dependencies for building the docs. Hint If you installed the package directly from github, run : pip install \"pytere[docs] @ git+https://github.com/astariul/pytere.git\" List of extra dependencies : test : Dependencies for running unit-tests. hook : Dependencies for running pre-commit hooks. lint : Dependencies for running linters and formatters. docs : Dependencies for building the documentation. dev : test + hook + lint + docs . all : All extra dependencies.","title":"Extra dependencies"},{"location":"#contribute","text":"To contribute, install the package locally (see Installation ), create your own branch, add your code/tests/documentation, and open a PR !","title":"Contribute"},{"location":"#pre-commit-hooks","text":"Pre-commit hooks are set to check the code added whenever you commit something. When you try to commit your code, hooks are run, and if anything fails ( linters, tests, etc... ), your code will not be committed. You then have to fix your code and try to commit again ! Info If you never ran the hooks before, install it with : pre-commit install","title":"Pre-commit hooks"},{"location":"#documentation","text":"When you contribute, make sure to keep the documentation up-to-date. You can visualize the documentation locally by running : mkdocs serve","title":"Documentation"},{"location":"code_ref/","text":"gibbs hub Response ( tuple ) Response(code, content) code : None property readonly Alias for field number 0 content : None property readonly Alias for field number 1 __new__ ( _cls , code , content ) special staticmethod Create new instance of Response(code, content) __repr__ ( self ) special Return a nicely formatted representation string Source code in gibbs/hub.py def __repr__ ( self ): 'Return a nicely formatted representation string' return self . __class__ . __name__ + repr_fmt % self __getnewargs__ ( self ) special Return self as a plain tuple. Used by copy and pickle. Source code in gibbs/hub.py def __getnewargs__ ( self ): 'Return self as a plain tuple. Used by copy and pickle.' return tuple ( self ) UserCodeException ( Exception ) Custom Exception for user-defined catched errors. Parameters: Name Type Description Default t str Traceback returned by the worker. required Source code in gibbs/hub.py class UserCodeException ( Exception ): \"\"\"Custom Exception for user-defined catched errors. Args: t (str): Traceback returned by the worker. \"\"\" def __init__ ( self , t : str ): super () . __init__ ( f \"Exception raised in user-defined code. Traceback : \\n { t } \" ) WorkerManager A helper class that takes care of managing workers. Workers' address can be registered as available, and this class will make sure to return address of workers that are available and alive. A worker is considered as dead if we didn't receive any heartbeat within a given interval. Parameters: Name Type Description Default heartbeat_interval float Interval of time (in seconds) after which we consider a worker to be dead. required Source code in gibbs/hub.py class WorkerManager : \"\"\"A helper class that takes care of managing workers. Workers' address can be registered as available, and this class will make sure to return address of workers that are available and alive. A worker is considered as dead if we didn't receive any heartbeat within a given interval. Args: heartbeat_interval (float): Interval of time (in seconds) after which we consider a worker to be dead. \"\"\" def __init__ ( self , heartbeat_interval : float ): super () . __init__ () self . heartbeat_t = heartbeat_interval self . w_ts = {} self . w_access = asyncio . Condition () async def reckon ( self , address : str ): \"\"\"Register the given address as available. Args: address (str): Address of the worker to register as available. \"\"\" async with self . w_access : self . w_ts [ address ] = time . time () self . w_access . notify () async def get_next_worker ( self ) -> str : \"\"\"Retrieve the next available and alive worker's address. Returns: str: Address of the available and alive worker. \"\"\" async with self . w_access : # Iterate workers until we find one that was alive recently w_alive = False while not w_alive : # If no workers are available, wait... if not self . w_ts : await self . w_access . wait () address , ts = self . w_ts . popitem () w_alive = time . time () - ts < self . heartbeat_t return address reckon ( self , address ) async Register the given address as available. Parameters: Name Type Description Default address str Address of the worker to register as available. required Source code in gibbs/hub.py async def reckon ( self , address : str ): \"\"\"Register the given address as available. Args: address (str): Address of the worker to register as available. \"\"\" async with self . w_access : self . w_ts [ address ] = time . time () self . w_access . notify () get_next_worker ( self ) async Retrieve the next available and alive worker's address. Returns: Type Description str Address of the available and alive worker. Source code in gibbs/hub.py async def get_next_worker ( self ) -> str : \"\"\"Retrieve the next available and alive worker's address. Returns: str: Address of the available and alive worker. \"\"\" async with self . w_access : # Iterate workers until we find one that was alive recently w_alive = False while not w_alive : # If no workers are available, wait... if not self . w_ts : await self . w_access . wait () address , ts = self . w_ts . popitem () w_alive = time . time () - ts < self . heartbeat_t return address RequestManager A helper class that takes care of storing responses and waiting for the right response. Parameters: Name Type Description Default resp_buffer_size int Maximum size of the response buffer. required Source code in gibbs/hub.py class RequestManager : \"\"\"A helper class that takes care of storing responses and waiting for the right response. Args: resp_buffer_size (int): Maximum size of the response buffer. \"\"\" def __init__ ( self , resp_buffer_size : int ): super () . __init__ () self . resp_buffer_size = resp_buffer_size self . responses = {} self . req_states = {} def pin ( self , req_id : str ): \"\"\"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each `req_id` before calling `wait_for`. Args: req_id (str): Request unique identifier. \"\"\" self . req_states [ req_id ] = asyncio . Event () # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None ) async def wait_for ( self , req_id : str ) -> Tuple [ int , Any ]: \"\"\"Async method that waits until we received the response corresponding to the given request ID. The method `pin` should be called before waiting with this method. Args: req_id (str): Request unique identifier. Raises: KeyError: Exception raised if the request wasn't registered previously. Returns: Tuple[int, Any]: Code and content of the received response. \"\"\" if req_id not in self . req_states : raise KeyError ( f \"Request # { req_id } was not pinned, or was removed because of buffer overflow\" ) # Wait for the receiving loop to receive the response await self . req_states [ req_id ] . wait () # Once we get it, access the result r = self . responses . pop ( req_id ) # Don't forget to remove the event self . req_states . pop ( req_id ) return r . code , r . content def store ( self , req_id : str , code : int , response : Any ): \"\"\"Store a response, to be consumed later. Args: req_id (str): Request unique identifier. code (int): Code of the response. response (Any): Content of the response. \"\"\" # Store the response if the req_id is recognized if req_id in self . req_states : self . responses [ req_id ] = Response ( code , response ) # Notify that we received the response self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" ) pin ( self , req_id ) Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each req_id before calling wait_for . Parameters: Name Type Description Default req_id str Request unique identifier. required Source code in gibbs/hub.py def pin ( self , req_id : str ): \"\"\"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each `req_id` before calling `wait_for`. Args: req_id (str): Request unique identifier. \"\"\" self . req_states [ req_id ] = asyncio . Event () # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None ) wait_for ( self , req_id ) async Async method that waits until we received the response corresponding to the given request ID. The method pin should be called before waiting with this method. Parameters: Name Type Description Default req_id str Request unique identifier. required Exceptions: Type Description KeyError Exception raised if the request wasn't registered previously. Returns: Type Description Tuple[int, Any] Code and content of the received response. Source code in gibbs/hub.py async def wait_for ( self , req_id : str ) -> Tuple [ int , Any ]: \"\"\"Async method that waits until we received the response corresponding to the given request ID. The method `pin` should be called before waiting with this method. Args: req_id (str): Request unique identifier. Raises: KeyError: Exception raised if the request wasn't registered previously. Returns: Tuple[int, Any]: Code and content of the received response. \"\"\" if req_id not in self . req_states : raise KeyError ( f \"Request # { req_id } was not pinned, or was removed because of buffer overflow\" ) # Wait for the receiving loop to receive the response await self . req_states [ req_id ] . wait () # Once we get it, access the result r = self . responses . pop ( req_id ) # Don't forget to remove the event self . req_states . pop ( req_id ) return r . code , r . content store ( self , req_id , code , response ) Store a response, to be consumed later. Parameters: Name Type Description Default req_id str Request unique identifier. required code int Code of the response. required response Any Content of the response. required Source code in gibbs/hub.py def store ( self , req_id : str , code : int , response : Any ): \"\"\"Store a response, to be consumed later. Args: req_id (str): Request unique identifier. code (int): Code of the response. response (Any): Content of the response. \"\"\" # Store the response if the req_id is recognized if req_id in self . req_states : self . responses [ req_id ] = Response ( code , response ) # Notify that we received the response self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" ) Hub Class acting as a hub for all the requests to send. All requests sent through this class will be automatically dispatched to connected workers, will wait for the responses and return it. Parameters: Name Type Description Default port int Port number to use for the sockets. Defaults to DEFAULT_PORT. 5019 heartbeat_interval float Heartbeat interval used by the workers, in seconds. Defaults to DEFAULT_HEARTBEAT_INTERVAL. 1 resp_buffer_size int Maximum response buffer size. Defaults to RESPONSE_BUFFER_SIZE. 4096 Source code in gibbs/hub.py class Hub : \"\"\"Class acting as a hub for all the requests to send. All requests sent through this class will be automatically dispatched to connected workers, will wait for the responses and return it. Args: port (int): Port number to use for the sockets. Defaults to DEFAULT_PORT. heartbeat_interval (float): Heartbeat interval used by the workers, in seconds. Defaults to DEFAULT_HEARTBEAT_INTERVAL. resp_buffer_size (int): Maximum response buffer size. Defaults to RESPONSE_BUFFER_SIZE. \"\"\" def __init__ ( self , port : int = DEFAULT_PORT , heartbeat_interval : float = DEFAULT_HEARTBEAT_INTERVAL , resp_buffer_size : int = RESPONSE_BUFFER_SIZE , ): super () . __init__ () self . port = port self . heartbeat_t = heartbeat_interval self . socket = None self . w_manager = None self . req_manager = RequestManager ( resp_buffer_size = resp_buffer_size ) async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff logger . debug ( \"Receiving...\" ) address , * frames = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . w_manager . reckon ( address ) if len ( frames ) == 1 : # Answer the Ping logger . debug ( \"Answering the ping\" ) await self . socket . send_multipart ([ address , b \"\" , PONG ]) continue _ , resp = frames req_id , code , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) self . req_manager . store ( req_id , code , res ) def _start_if_not_started ( self ): \"\"\"Helper method to ensure everything is properly started (socket is initialized, receiving loop is started, etc...). \"\"\" if self . socket is None : # Create what we need here in this process/context context = zmq . asyncio . Context () self . socket = context . socket ( zmq . ROUTER ) self . socket . bind ( f \"tcp://*: { self . port } \" ) self . w_manager = WorkerManager ( heartbeat_interval = self . heartbeat_t ) # Fire and forget : infinite loop, taking care of receiving stuff from the socket logger . info ( \"Starting receiving loop...\" ) asyncio . create_task ( self . receive_loop ()) async def _request ( self , * args : Any , ** kwargs : Any ) -> Any : \"\"\"Raw method to send a request. This method will do the following : * Start the receiving loop if it was not started * Get the address of the next worker ready (blocking) * Send the request to the worker * Wait for the response (blocking) * Return the result Args: *args: Positional arguments for the request. **kwargs: Keywords arguments for the request. Raises: UserCodeException: Exception raised if an exception was raised inside user-defined code on the worker side. Returns: Any: The response for the request. \"\"\" # Before anything, if the receiving loop was not started, start it self . _start_if_not_started () # Assign a unique ID to the request req_id = uuid . uuid4 () . hex # Let the manager know that we are waiting for this request logger . debug ( f \"Pinning request # { req_id } \" ) self . req_manager . pin ( req_id ) # Send the request address = await self . w_manager . get_next_worker () logger . debug ( f \"Sending request # { req_id } to worker # { address } \" ) await self . socket . send_multipart ([ address , b \"\" , msgpack . packb ([ req_id , args , kwargs ])]) # Wait until we receive the response code , res = await self . req_manager . wait_for ( req_id ) logger . debug ( f \"Received result for request # { req_id } \" ) # Depending on what is the response, deal with it properly if code == CODE_FAILURE : raise UserCodeException ( res ) else : return res async def request ( self , * args : Any , gibbs_timeout : float = None , gibbs_retries : int = 0 , ** kwargs : Any ) -> Any : \"\"\"Main method, used to send a request to workers and get the result. This method is a wrapper around `_request`, providing additional functionalities : * Timeout * Automatic retries Args: *args: Positional arguments for the request. gibbs_timeout (float): Timeout for the request, in seconds. If `None` is given, block until the request is complete. Defaults to None. gibbs_retries (int): Number of retries. This argument is used only if `gibbs_timeout` is not `None`. If `-1` is given, indefinitely retry. Defaults to 0. **kwargs: Keywords arguments for the request. Raises: asyncio.TimeoutError: Error raised if no response is received within the given timeout. Returns: Any: The response for the request. \"\"\" try : return await asyncio . wait_for ( self . _request ( * args , ** kwargs ), timeout = gibbs_timeout ) except asyncio . TimeoutError : if gibbs_retries == 0 : logger . error ( f \"Request failed : no response received within { gibbs_timeout } s\" ) raise else : retries_left = max ( gibbs_retries - 1 , - 1 ) logger . warning ( f \"Request failed : no response received within { gibbs_timeout } s. Retrying { retries_left } times\" ) return await self . request ( * args , gibbs_timeout = gibbs_timeout , gibbs_retries = retries_left , ** kwargs ) def __del__ ( self ): if self . socket is not None : self . socket . close () receive_loop ( self ) async Infinite loop for receiving responses from the workers. Source code in gibbs/hub.py async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff logger . debug ( \"Receiving...\" ) address , * frames = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . w_manager . reckon ( address ) if len ( frames ) == 1 : # Answer the Ping logger . debug ( \"Answering the ping\" ) await self . socket . send_multipart ([ address , b \"\" , PONG ]) continue _ , resp = frames req_id , code , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) self . req_manager . store ( req_id , code , res ) request ( self , * args , * , gibbs_timeout = None , gibbs_retries = 0 , ** kwargs ) async Main method, used to send a request to workers and get the result. This method is a wrapper around _request , providing additional functionalities : * Timeout * Automatic retries Parameters: Name Type Description Default *args Any Positional arguments for the request. () gibbs_timeout float Timeout for the request, in seconds. If None is given, block until the request is complete. Defaults to None. None gibbs_retries int Number of retries. This argument is used only if gibbs_timeout is not None . If -1 is given, indefinitely retry. Defaults to 0. 0 **kwargs Any Keywords arguments for the request. {} Exceptions: Type Description asyncio.TimeoutError Error raised if no response is received within the given timeout. Returns: Type Description Any The response for the request. Source code in gibbs/hub.py async def request ( self , * args : Any , gibbs_timeout : float = None , gibbs_retries : int = 0 , ** kwargs : Any ) -> Any : \"\"\"Main method, used to send a request to workers and get the result. This method is a wrapper around `_request`, providing additional functionalities : * Timeout * Automatic retries Args: *args: Positional arguments for the request. gibbs_timeout (float): Timeout for the request, in seconds. If `None` is given, block until the request is complete. Defaults to None. gibbs_retries (int): Number of retries. This argument is used only if `gibbs_timeout` is not `None`. If `-1` is given, indefinitely retry. Defaults to 0. **kwargs: Keywords arguments for the request. Raises: asyncio.TimeoutError: Error raised if no response is received within the given timeout. Returns: Any: The response for the request. \"\"\" try : return await asyncio . wait_for ( self . _request ( * args , ** kwargs ), timeout = gibbs_timeout ) except asyncio . TimeoutError : if gibbs_retries == 0 : logger . error ( f \"Request failed : no response received within { gibbs_timeout } s\" ) raise else : retries_left = max ( gibbs_retries - 1 , - 1 ) logger . warning ( f \"Request failed : no response received within { gibbs_timeout } s. Retrying { retries_left } times\" ) return await self . request ( * args , gibbs_timeout = gibbs_timeout , gibbs_retries = retries_left , ** kwargs ) worker Worker ( Process ) Define a worker process. This worker process indefinitely waits for requests on a socket. Upon receiving a request, it processes it with the worker class provided, and return the response. After creating the Worker object, you have 2 different ways to run it : * worker.run() : It will run in the current process directly (blocking, infinite loop). * worker.start() : It will start a different process and start the code there (non-blocking). Parameters: Name Type Description Default worker_cls Callable Worker class containing the code that will be used to process requests. required gibbs_host str Host of the Hub. Defaults to \"localhost\". 'localhost' gibbs_port int Port of the Hub. Defaults to DEFAULT_PORT. 5019 gibbs_heartbeat_interval float Heartbeat interval between the worker and the Hub. Defaults to DEFAULT_HEARTBEAT_INTERVAL. 1 gibbs_reset_after_n_miss int Number of missed heartbeats allowed before hard-resetting the socket and retrying. Defaults to DEFAULT_RESET_AFTER_N_MISS. 2 Source code in gibbs/worker.py class Worker ( Process ): \"\"\"Define a worker process. This worker process indefinitely waits for requests on a socket. Upon receiving a request, it processes it with the worker class provided, and return the response. After creating the Worker object, you have 2 different ways to run it : * `worker.run()` : It will run in the current process directly (blocking, infinite loop). * `worker.start()` : It will start a different process and start the code there (non-blocking). Args: worker_cls (Callable): Worker class containing the code that will be used to process requests. gibbs_host (str): Host of the Hub. Defaults to \"localhost\". gibbs_port (int): Port of the Hub. Defaults to DEFAULT_PORT. gibbs_heartbeat_interval (float): Heartbeat interval between the worker and the Hub. Defaults to DEFAULT_HEARTBEAT_INTERVAL. gibbs_reset_after_n_miss (int): Number of missed heartbeats allowed before hard-resetting the socket and retrying. Defaults to DEFAULT_RESET_AFTER_N_MISS. \"\"\" def __init__ ( self , worker_cls : Callable , * args : Any , gibbs_host : str = \"localhost\" , gibbs_port : int = DEFAULT_PORT , gibbs_heartbeat_interval : float = DEFAULT_HEARTBEAT_INTERVAL , gibbs_reset_after_n_miss : int = DEFAULT_RESET_AFTER_N_MISS , ** kwargs : Any , ): super () . __init__ () self . worker_cls = worker_cls self . worker_args = args self . worker_kwargs = kwargs self . identity = uuid . uuid4 () . hex self . host = gibbs_host self . port = gibbs_port self . heartbeat_t = gibbs_heartbeat_interval self . reset_n_miss = gibbs_reset_after_n_miss self . waiting_pong = 0 def create_socket ( self , context : zmq . Context ) -> zmq . Socket : \"\"\"Helper method to create a socket, setting its identity and connecting to the Hub. Args: context (zmq.Context): ZMQ context to use. Returns: zmq.Socket: Initialized and connected socket, ready to use. \"\"\" # Create the socket, set its identity socket = context . socket ( zmq . DEALER ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) return socket def ping ( self , socket : zmq . Socket ): \"\"\"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Args: socket (zmq.Socket): Socket to use to send the heartbeat. \"\"\" logger . debug ( \"Sending ping...\" ) socket . send ( PING ) self . waiting_pong += 1 def run ( self ): \"\"\"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. \"\"\" # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the socket context = zmq . Context () socket = self . create_socket ( context ) logger . info ( \"Worker ready to roll\" ) # Tell the Hub we are ready self . ping ( socket ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) if socket . poll ( self . heartbeat_t * MS , zmq . POLLIN ): _ , workload = socket . recv_multipart ( zmq . NOBLOCK ) logger . debug ( \"Received something !\" ) self . waiting_pong = 0 else : logger . debug ( f \"Didn't receive anything for { self . heartbeat_t } s ( { self . waiting_pong } )\" ) if self . waiting_pong >= self . reset_n_miss : logger . warning ( f \"The Hub is not answering, even after { self . waiting_pong } missed pings... \" f \"Resetting the socket\" ) socket . close ( linger = 0 ) socket = self . create_socket ( context ) self . waiting_pong = 0 # We didn't receive anything for some time, try to ping again self . ping ( socket ) continue if workload == PONG : # Just a Pong, ignore it logger . debug ( \"It was just a pong...\" ) continue # From here the Hub sent us an actual request req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments try : res = worker ( * req_args , ** req_kwargs ) except Exception as e : logger . warning ( f \"Exception in user-defined __call__ method : { e . __class__ . __name__ } ( { str ( e ) } )\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_FAILURE , traceback . format_exc ()])]) else : logger . debug ( \"Sending back the response\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_SUCCESS , res ])]) create_socket ( self , context ) Helper method to create a socket, setting its identity and connecting to the Hub. Parameters: Name Type Description Default context zmq.Context ZMQ context to use. required Returns: Type Description zmq.Socket Initialized and connected socket, ready to use. Source code in gibbs/worker.py def create_socket ( self , context : zmq . Context ) -> zmq . Socket : \"\"\"Helper method to create a socket, setting its identity and connecting to the Hub. Args: context (zmq.Context): ZMQ context to use. Returns: zmq.Socket: Initialized and connected socket, ready to use. \"\"\" # Create the socket, set its identity socket = context . socket ( zmq . DEALER ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) return socket ping ( self , socket ) Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Parameters: Name Type Description Default socket zmq.Socket Socket to use to send the heartbeat. required Source code in gibbs/worker.py def ping ( self , socket : zmq . Socket ): \"\"\"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Args: socket (zmq.Socket): Socket to use to send the heartbeat. \"\"\" logger . debug ( \"Sending ping...\" ) socket . send ( PING ) self . waiting_pong += 1 run ( self ) Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. Source code in gibbs/worker.py def run ( self ): \"\"\"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. \"\"\" # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the socket context = zmq . Context () socket = self . create_socket ( context ) logger . info ( \"Worker ready to roll\" ) # Tell the Hub we are ready self . ping ( socket ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) if socket . poll ( self . heartbeat_t * MS , zmq . POLLIN ): _ , workload = socket . recv_multipart ( zmq . NOBLOCK ) logger . debug ( \"Received something !\" ) self . waiting_pong = 0 else : logger . debug ( f \"Didn't receive anything for { self . heartbeat_t } s ( { self . waiting_pong } )\" ) if self . waiting_pong >= self . reset_n_miss : logger . warning ( f \"The Hub is not answering, even after { self . waiting_pong } missed pings... \" f \"Resetting the socket\" ) socket . close ( linger = 0 ) socket = self . create_socket ( context ) self . waiting_pong = 0 # We didn't receive anything for some time, try to ping again self . ping ( socket ) continue if workload == PONG : # Just a Pong, ignore it logger . debug ( \"It was just a pong...\" ) continue # From here the Hub sent us an actual request req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments try : res = worker ( * req_args , ** req_kwargs ) except Exception as e : logger . warning ( f \"Exception in user-defined __call__ method : { e . __class__ . __name__ } ( { str ( e ) } )\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_FAILURE , traceback . format_exc ()])]) else : logger . debug ( \"Sending back the response\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_SUCCESS , res ])])","title":"gibbs"},{"location":"code_ref/#gibbs","text":"","title":"gibbs"},{"location":"code_ref/#gibbs.hub","text":"","title":"hub"},{"location":"code_ref/#gibbs.hub.Response","text":"Response(code, content)","title":"Response"},{"location":"code_ref/#gibbs.hub.Response.code","text":"Alias for field number 0","title":"code"},{"location":"code_ref/#gibbs.hub.Response.content","text":"Alias for field number 1","title":"content"},{"location":"code_ref/#gibbs.hub.Response.__new__","text":"Create new instance of Response(code, content)","title":"__new__()"},{"location":"code_ref/#gibbs.hub.Response.__repr__","text":"Return a nicely formatted representation string Source code in gibbs/hub.py def __repr__ ( self ): 'Return a nicely formatted representation string' return self . __class__ . __name__ + repr_fmt % self","title":"__repr__()"},{"location":"code_ref/#gibbs.hub.Response.__getnewargs__","text":"Return self as a plain tuple. Used by copy and pickle. Source code in gibbs/hub.py def __getnewargs__ ( self ): 'Return self as a plain tuple. Used by copy and pickle.' return tuple ( self )","title":"__getnewargs__()"},{"location":"code_ref/#gibbs.hub.UserCodeException","text":"Custom Exception for user-defined catched errors. Parameters: Name Type Description Default t str Traceback returned by the worker. required Source code in gibbs/hub.py class UserCodeException ( Exception ): \"\"\"Custom Exception for user-defined catched errors. Args: t (str): Traceback returned by the worker. \"\"\" def __init__ ( self , t : str ): super () . __init__ ( f \"Exception raised in user-defined code. Traceback : \\n { t } \" )","title":"UserCodeException"},{"location":"code_ref/#gibbs.hub.WorkerManager","text":"A helper class that takes care of managing workers. Workers' address can be registered as available, and this class will make sure to return address of workers that are available and alive. A worker is considered as dead if we didn't receive any heartbeat within a given interval. Parameters: Name Type Description Default heartbeat_interval float Interval of time (in seconds) after which we consider a worker to be dead. required Source code in gibbs/hub.py class WorkerManager : \"\"\"A helper class that takes care of managing workers. Workers' address can be registered as available, and this class will make sure to return address of workers that are available and alive. A worker is considered as dead if we didn't receive any heartbeat within a given interval. Args: heartbeat_interval (float): Interval of time (in seconds) after which we consider a worker to be dead. \"\"\" def __init__ ( self , heartbeat_interval : float ): super () . __init__ () self . heartbeat_t = heartbeat_interval self . w_ts = {} self . w_access = asyncio . Condition () async def reckon ( self , address : str ): \"\"\"Register the given address as available. Args: address (str): Address of the worker to register as available. \"\"\" async with self . w_access : self . w_ts [ address ] = time . time () self . w_access . notify () async def get_next_worker ( self ) -> str : \"\"\"Retrieve the next available and alive worker's address. Returns: str: Address of the available and alive worker. \"\"\" async with self . w_access : # Iterate workers until we find one that was alive recently w_alive = False while not w_alive : # If no workers are available, wait... if not self . w_ts : await self . w_access . wait () address , ts = self . w_ts . popitem () w_alive = time . time () - ts < self . heartbeat_t return address","title":"WorkerManager"},{"location":"code_ref/#gibbs.hub.WorkerManager.reckon","text":"Register the given address as available. Parameters: Name Type Description Default address str Address of the worker to register as available. required Source code in gibbs/hub.py async def reckon ( self , address : str ): \"\"\"Register the given address as available. Args: address (str): Address of the worker to register as available. \"\"\" async with self . w_access : self . w_ts [ address ] = time . time () self . w_access . notify ()","title":"reckon()"},{"location":"code_ref/#gibbs.hub.WorkerManager.get_next_worker","text":"Retrieve the next available and alive worker's address. Returns: Type Description str Address of the available and alive worker. Source code in gibbs/hub.py async def get_next_worker ( self ) -> str : \"\"\"Retrieve the next available and alive worker's address. Returns: str: Address of the available and alive worker. \"\"\" async with self . w_access : # Iterate workers until we find one that was alive recently w_alive = False while not w_alive : # If no workers are available, wait... if not self . w_ts : await self . w_access . wait () address , ts = self . w_ts . popitem () w_alive = time . time () - ts < self . heartbeat_t return address","title":"get_next_worker()"},{"location":"code_ref/#gibbs.hub.RequestManager","text":"A helper class that takes care of storing responses and waiting for the right response. Parameters: Name Type Description Default resp_buffer_size int Maximum size of the response buffer. required Source code in gibbs/hub.py class RequestManager : \"\"\"A helper class that takes care of storing responses and waiting for the right response. Args: resp_buffer_size (int): Maximum size of the response buffer. \"\"\" def __init__ ( self , resp_buffer_size : int ): super () . __init__ () self . resp_buffer_size = resp_buffer_size self . responses = {} self . req_states = {} def pin ( self , req_id : str ): \"\"\"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each `req_id` before calling `wait_for`. Args: req_id (str): Request unique identifier. \"\"\" self . req_states [ req_id ] = asyncio . Event () # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None ) async def wait_for ( self , req_id : str ) -> Tuple [ int , Any ]: \"\"\"Async method that waits until we received the response corresponding to the given request ID. The method `pin` should be called before waiting with this method. Args: req_id (str): Request unique identifier. Raises: KeyError: Exception raised if the request wasn't registered previously. Returns: Tuple[int, Any]: Code and content of the received response. \"\"\" if req_id not in self . req_states : raise KeyError ( f \"Request # { req_id } was not pinned, or was removed because of buffer overflow\" ) # Wait for the receiving loop to receive the response await self . req_states [ req_id ] . wait () # Once we get it, access the result r = self . responses . pop ( req_id ) # Don't forget to remove the event self . req_states . pop ( req_id ) return r . code , r . content def store ( self , req_id : str , code : int , response : Any ): \"\"\"Store a response, to be consumed later. Args: req_id (str): Request unique identifier. code (int): Code of the response. response (Any): Content of the response. \"\"\" # Store the response if the req_id is recognized if req_id in self . req_states : self . responses [ req_id ] = Response ( code , response ) # Notify that we received the response self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" )","title":"RequestManager"},{"location":"code_ref/#gibbs.hub.RequestManager.pin","text":"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each req_id before calling wait_for . Parameters: Name Type Description Default req_id str Request unique identifier. required Source code in gibbs/hub.py def pin ( self , req_id : str ): \"\"\"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each `req_id` before calling `wait_for`. Args: req_id (str): Request unique identifier. \"\"\" self . req_states [ req_id ] = asyncio . Event () # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None )","title":"pin()"},{"location":"code_ref/#gibbs.hub.RequestManager.wait_for","text":"Async method that waits until we received the response corresponding to the given request ID. The method pin should be called before waiting with this method. Parameters: Name Type Description Default req_id str Request unique identifier. required Exceptions: Type Description KeyError Exception raised if the request wasn't registered previously. Returns: Type Description Tuple[int, Any] Code and content of the received response. Source code in gibbs/hub.py async def wait_for ( self , req_id : str ) -> Tuple [ int , Any ]: \"\"\"Async method that waits until we received the response corresponding to the given request ID. The method `pin` should be called before waiting with this method. Args: req_id (str): Request unique identifier. Raises: KeyError: Exception raised if the request wasn't registered previously. Returns: Tuple[int, Any]: Code and content of the received response. \"\"\" if req_id not in self . req_states : raise KeyError ( f \"Request # { req_id } was not pinned, or was removed because of buffer overflow\" ) # Wait for the receiving loop to receive the response await self . req_states [ req_id ] . wait () # Once we get it, access the result r = self . responses . pop ( req_id ) # Don't forget to remove the event self . req_states . pop ( req_id ) return r . code , r . content","title":"wait_for()"},{"location":"code_ref/#gibbs.hub.RequestManager.store","text":"Store a response, to be consumed later. Parameters: Name Type Description Default req_id str Request unique identifier. required code int Code of the response. required response Any Content of the response. required Source code in gibbs/hub.py def store ( self , req_id : str , code : int , response : Any ): \"\"\"Store a response, to be consumed later. Args: req_id (str): Request unique identifier. code (int): Code of the response. response (Any): Content of the response. \"\"\" # Store the response if the req_id is recognized if req_id in self . req_states : self . responses [ req_id ] = Response ( code , response ) # Notify that we received the response self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" )","title":"store()"},{"location":"code_ref/#gibbs.hub.Hub","text":"Class acting as a hub for all the requests to send. All requests sent through this class will be automatically dispatched to connected workers, will wait for the responses and return it. Parameters: Name Type Description Default port int Port number to use for the sockets. Defaults to DEFAULT_PORT. 5019 heartbeat_interval float Heartbeat interval used by the workers, in seconds. Defaults to DEFAULT_HEARTBEAT_INTERVAL. 1 resp_buffer_size int Maximum response buffer size. Defaults to RESPONSE_BUFFER_SIZE. 4096 Source code in gibbs/hub.py class Hub : \"\"\"Class acting as a hub for all the requests to send. All requests sent through this class will be automatically dispatched to connected workers, will wait for the responses and return it. Args: port (int): Port number to use for the sockets. Defaults to DEFAULT_PORT. heartbeat_interval (float): Heartbeat interval used by the workers, in seconds. Defaults to DEFAULT_HEARTBEAT_INTERVAL. resp_buffer_size (int): Maximum response buffer size. Defaults to RESPONSE_BUFFER_SIZE. \"\"\" def __init__ ( self , port : int = DEFAULT_PORT , heartbeat_interval : float = DEFAULT_HEARTBEAT_INTERVAL , resp_buffer_size : int = RESPONSE_BUFFER_SIZE , ): super () . __init__ () self . port = port self . heartbeat_t = heartbeat_interval self . socket = None self . w_manager = None self . req_manager = RequestManager ( resp_buffer_size = resp_buffer_size ) async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff logger . debug ( \"Receiving...\" ) address , * frames = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . w_manager . reckon ( address ) if len ( frames ) == 1 : # Answer the Ping logger . debug ( \"Answering the ping\" ) await self . socket . send_multipart ([ address , b \"\" , PONG ]) continue _ , resp = frames req_id , code , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) self . req_manager . store ( req_id , code , res ) def _start_if_not_started ( self ): \"\"\"Helper method to ensure everything is properly started (socket is initialized, receiving loop is started, etc...). \"\"\" if self . socket is None : # Create what we need here in this process/context context = zmq . asyncio . Context () self . socket = context . socket ( zmq . ROUTER ) self . socket . bind ( f \"tcp://*: { self . port } \" ) self . w_manager = WorkerManager ( heartbeat_interval = self . heartbeat_t ) # Fire and forget : infinite loop, taking care of receiving stuff from the socket logger . info ( \"Starting receiving loop...\" ) asyncio . create_task ( self . receive_loop ()) async def _request ( self , * args : Any , ** kwargs : Any ) -> Any : \"\"\"Raw method to send a request. This method will do the following : * Start the receiving loop if it was not started * Get the address of the next worker ready (blocking) * Send the request to the worker * Wait for the response (blocking) * Return the result Args: *args: Positional arguments for the request. **kwargs: Keywords arguments for the request. Raises: UserCodeException: Exception raised if an exception was raised inside user-defined code on the worker side. Returns: Any: The response for the request. \"\"\" # Before anything, if the receiving loop was not started, start it self . _start_if_not_started () # Assign a unique ID to the request req_id = uuid . uuid4 () . hex # Let the manager know that we are waiting for this request logger . debug ( f \"Pinning request # { req_id } \" ) self . req_manager . pin ( req_id ) # Send the request address = await self . w_manager . get_next_worker () logger . debug ( f \"Sending request # { req_id } to worker # { address } \" ) await self . socket . send_multipart ([ address , b \"\" , msgpack . packb ([ req_id , args , kwargs ])]) # Wait until we receive the response code , res = await self . req_manager . wait_for ( req_id ) logger . debug ( f \"Received result for request # { req_id } \" ) # Depending on what is the response, deal with it properly if code == CODE_FAILURE : raise UserCodeException ( res ) else : return res async def request ( self , * args : Any , gibbs_timeout : float = None , gibbs_retries : int = 0 , ** kwargs : Any ) -> Any : \"\"\"Main method, used to send a request to workers and get the result. This method is a wrapper around `_request`, providing additional functionalities : * Timeout * Automatic retries Args: *args: Positional arguments for the request. gibbs_timeout (float): Timeout for the request, in seconds. If `None` is given, block until the request is complete. Defaults to None. gibbs_retries (int): Number of retries. This argument is used only if `gibbs_timeout` is not `None`. If `-1` is given, indefinitely retry. Defaults to 0. **kwargs: Keywords arguments for the request. Raises: asyncio.TimeoutError: Error raised if no response is received within the given timeout. Returns: Any: The response for the request. \"\"\" try : return await asyncio . wait_for ( self . _request ( * args , ** kwargs ), timeout = gibbs_timeout ) except asyncio . TimeoutError : if gibbs_retries == 0 : logger . error ( f \"Request failed : no response received within { gibbs_timeout } s\" ) raise else : retries_left = max ( gibbs_retries - 1 , - 1 ) logger . warning ( f \"Request failed : no response received within { gibbs_timeout } s. Retrying { retries_left } times\" ) return await self . request ( * args , gibbs_timeout = gibbs_timeout , gibbs_retries = retries_left , ** kwargs ) def __del__ ( self ): if self . socket is not None : self . socket . close ()","title":"Hub"},{"location":"code_ref/#gibbs.hub.Hub.receive_loop","text":"Infinite loop for receiving responses from the workers. Source code in gibbs/hub.py async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff logger . debug ( \"Receiving...\" ) address , * frames = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . w_manager . reckon ( address ) if len ( frames ) == 1 : # Answer the Ping logger . debug ( \"Answering the ping\" ) await self . socket . send_multipart ([ address , b \"\" , PONG ]) continue _ , resp = frames req_id , code , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) self . req_manager . store ( req_id , code , res )","title":"receive_loop()"},{"location":"code_ref/#gibbs.hub.Hub.request","text":"Main method, used to send a request to workers and get the result. This method is a wrapper around _request , providing additional functionalities : * Timeout * Automatic retries Parameters: Name Type Description Default *args Any Positional arguments for the request. () gibbs_timeout float Timeout for the request, in seconds. If None is given, block until the request is complete. Defaults to None. None gibbs_retries int Number of retries. This argument is used only if gibbs_timeout is not None . If -1 is given, indefinitely retry. Defaults to 0. 0 **kwargs Any Keywords arguments for the request. {} Exceptions: Type Description asyncio.TimeoutError Error raised if no response is received within the given timeout. Returns: Type Description Any The response for the request. Source code in gibbs/hub.py async def request ( self , * args : Any , gibbs_timeout : float = None , gibbs_retries : int = 0 , ** kwargs : Any ) -> Any : \"\"\"Main method, used to send a request to workers and get the result. This method is a wrapper around `_request`, providing additional functionalities : * Timeout * Automatic retries Args: *args: Positional arguments for the request. gibbs_timeout (float): Timeout for the request, in seconds. If `None` is given, block until the request is complete. Defaults to None. gibbs_retries (int): Number of retries. This argument is used only if `gibbs_timeout` is not `None`. If `-1` is given, indefinitely retry. Defaults to 0. **kwargs: Keywords arguments for the request. Raises: asyncio.TimeoutError: Error raised if no response is received within the given timeout. Returns: Any: The response for the request. \"\"\" try : return await asyncio . wait_for ( self . _request ( * args , ** kwargs ), timeout = gibbs_timeout ) except asyncio . TimeoutError : if gibbs_retries == 0 : logger . error ( f \"Request failed : no response received within { gibbs_timeout } s\" ) raise else : retries_left = max ( gibbs_retries - 1 , - 1 ) logger . warning ( f \"Request failed : no response received within { gibbs_timeout } s. Retrying { retries_left } times\" ) return await self . request ( * args , gibbs_timeout = gibbs_timeout , gibbs_retries = retries_left , ** kwargs )","title":"request()"},{"location":"code_ref/#gibbs.worker","text":"","title":"worker"},{"location":"code_ref/#gibbs.worker.Worker","text":"Define a worker process. This worker process indefinitely waits for requests on a socket. Upon receiving a request, it processes it with the worker class provided, and return the response. After creating the Worker object, you have 2 different ways to run it : * worker.run() : It will run in the current process directly (blocking, infinite loop). * worker.start() : It will start a different process and start the code there (non-blocking). Parameters: Name Type Description Default worker_cls Callable Worker class containing the code that will be used to process requests. required gibbs_host str Host of the Hub. Defaults to \"localhost\". 'localhost' gibbs_port int Port of the Hub. Defaults to DEFAULT_PORT. 5019 gibbs_heartbeat_interval float Heartbeat interval between the worker and the Hub. Defaults to DEFAULT_HEARTBEAT_INTERVAL. 1 gibbs_reset_after_n_miss int Number of missed heartbeats allowed before hard-resetting the socket and retrying. Defaults to DEFAULT_RESET_AFTER_N_MISS. 2 Source code in gibbs/worker.py class Worker ( Process ): \"\"\"Define a worker process. This worker process indefinitely waits for requests on a socket. Upon receiving a request, it processes it with the worker class provided, and return the response. After creating the Worker object, you have 2 different ways to run it : * `worker.run()` : It will run in the current process directly (blocking, infinite loop). * `worker.start()` : It will start a different process and start the code there (non-blocking). Args: worker_cls (Callable): Worker class containing the code that will be used to process requests. gibbs_host (str): Host of the Hub. Defaults to \"localhost\". gibbs_port (int): Port of the Hub. Defaults to DEFAULT_PORT. gibbs_heartbeat_interval (float): Heartbeat interval between the worker and the Hub. Defaults to DEFAULT_HEARTBEAT_INTERVAL. gibbs_reset_after_n_miss (int): Number of missed heartbeats allowed before hard-resetting the socket and retrying. Defaults to DEFAULT_RESET_AFTER_N_MISS. \"\"\" def __init__ ( self , worker_cls : Callable , * args : Any , gibbs_host : str = \"localhost\" , gibbs_port : int = DEFAULT_PORT , gibbs_heartbeat_interval : float = DEFAULT_HEARTBEAT_INTERVAL , gibbs_reset_after_n_miss : int = DEFAULT_RESET_AFTER_N_MISS , ** kwargs : Any , ): super () . __init__ () self . worker_cls = worker_cls self . worker_args = args self . worker_kwargs = kwargs self . identity = uuid . uuid4 () . hex self . host = gibbs_host self . port = gibbs_port self . heartbeat_t = gibbs_heartbeat_interval self . reset_n_miss = gibbs_reset_after_n_miss self . waiting_pong = 0 def create_socket ( self , context : zmq . Context ) -> zmq . Socket : \"\"\"Helper method to create a socket, setting its identity and connecting to the Hub. Args: context (zmq.Context): ZMQ context to use. Returns: zmq.Socket: Initialized and connected socket, ready to use. \"\"\" # Create the socket, set its identity socket = context . socket ( zmq . DEALER ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) return socket def ping ( self , socket : zmq . Socket ): \"\"\"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Args: socket (zmq.Socket): Socket to use to send the heartbeat. \"\"\" logger . debug ( \"Sending ping...\" ) socket . send ( PING ) self . waiting_pong += 1 def run ( self ): \"\"\"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. \"\"\" # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the socket context = zmq . Context () socket = self . create_socket ( context ) logger . info ( \"Worker ready to roll\" ) # Tell the Hub we are ready self . ping ( socket ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) if socket . poll ( self . heartbeat_t * MS , zmq . POLLIN ): _ , workload = socket . recv_multipart ( zmq . NOBLOCK ) logger . debug ( \"Received something !\" ) self . waiting_pong = 0 else : logger . debug ( f \"Didn't receive anything for { self . heartbeat_t } s ( { self . waiting_pong } )\" ) if self . waiting_pong >= self . reset_n_miss : logger . warning ( f \"The Hub is not answering, even after { self . waiting_pong } missed pings... \" f \"Resetting the socket\" ) socket . close ( linger = 0 ) socket = self . create_socket ( context ) self . waiting_pong = 0 # We didn't receive anything for some time, try to ping again self . ping ( socket ) continue if workload == PONG : # Just a Pong, ignore it logger . debug ( \"It was just a pong...\" ) continue # From here the Hub sent us an actual request req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments try : res = worker ( * req_args , ** req_kwargs ) except Exception as e : logger . warning ( f \"Exception in user-defined __call__ method : { e . __class__ . __name__ } ( { str ( e ) } )\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_FAILURE , traceback . format_exc ()])]) else : logger . debug ( \"Sending back the response\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_SUCCESS , res ])])","title":"Worker"},{"location":"code_ref/#gibbs.worker.Worker.create_socket","text":"Helper method to create a socket, setting its identity and connecting to the Hub. Parameters: Name Type Description Default context zmq.Context ZMQ context to use. required Returns: Type Description zmq.Socket Initialized and connected socket, ready to use. Source code in gibbs/worker.py def create_socket ( self , context : zmq . Context ) -> zmq . Socket : \"\"\"Helper method to create a socket, setting its identity and connecting to the Hub. Args: context (zmq.Context): ZMQ context to use. Returns: zmq.Socket: Initialized and connected socket, ready to use. \"\"\" # Create the socket, set its identity socket = context . socket ( zmq . DEALER ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) return socket","title":"create_socket()"},{"location":"code_ref/#gibbs.worker.Worker.ping","text":"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Parameters: Name Type Description Default socket zmq.Socket Socket to use to send the heartbeat. required Source code in gibbs/worker.py def ping ( self , socket : zmq . Socket ): \"\"\"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Args: socket (zmq.Socket): Socket to use to send the heartbeat. \"\"\" logger . debug ( \"Sending ping...\" ) socket . send ( PING ) self . waiting_pong += 1","title":"ping()"},{"location":"code_ref/#gibbs.worker.Worker.run","text":"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. Source code in gibbs/worker.py def run ( self ): \"\"\"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. \"\"\" # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the socket context = zmq . Context () socket = self . create_socket ( context ) logger . info ( \"Worker ready to roll\" ) # Tell the Hub we are ready self . ping ( socket ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) if socket . poll ( self . heartbeat_t * MS , zmq . POLLIN ): _ , workload = socket . recv_multipart ( zmq . NOBLOCK ) logger . debug ( \"Received something !\" ) self . waiting_pong = 0 else : logger . debug ( f \"Didn't receive anything for { self . heartbeat_t } s ( { self . waiting_pong } )\" ) if self . waiting_pong >= self . reset_n_miss : logger . warning ( f \"The Hub is not answering, even after { self . waiting_pong } missed pings... \" f \"Resetting the socket\" ) socket . close ( linger = 0 ) socket = self . create_socket ( context ) self . waiting_pong = 0 # We didn't receive anything for some time, try to ping again self . ping ( socket ) continue if workload == PONG : # Just a Pong, ignore it logger . debug ( \"It was just a pong...\" ) continue # From here the Hub sent us an actual request req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments try : res = worker ( * req_args , ** req_kwargs ) except Exception as e : logger . warning ( f \"Exception in user-defined __call__ method : { e . __class__ . __name__ } ( { str ( e ) } )\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_FAILURE , traceback . format_exc ()])]) else : logger . debug ( \"Sending back the response\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_SUCCESS , res ])])","title":"run()"},{"location":"features/","text":"Features This page introduces the different features included in this template repository, as well as where to find them and modify them if necessary. Documentation This documentation is generated using Mkdocs , using Material for Mkdocs theme. Check out Material for Mkdocs documentation , their documentation is complete and easy to follow. Where to modify it ? If you want to modify the documentation, modify the appropriate markdown files in docs/ . If you want to modify the configuration, take a look at mkdocs.yml . If you want to modify the theme (advanced), go to mkdocs/ . The documentation is versioned and published as a Github page with mike . Check mike's documentation for more details on how to use it. For a very short summary : mike deploy --push --update-aliases X.Y to push the current documentation version as X.Y version. mike deploy --push --update-aliases X.Y name to push the current documentation version as X.Y version, and add an alias name . mike retitle --push X.Y \"title\" to set the title of X.Y as title . For example, title can be the full version X.Y.Z . mike set-default --push name to set the alias name as default. mike delete --all --push to remove everything (careful with that !). mike serve to serve the documentation locally (for debugging). Code formatting & linters To lint and check the format of the code, this template uses several libraries : isort , black , flake8 , and darglint . Where to modify it ? If you wish to not use one of these tools, you need to remove it from the pre-commit hooks and from the Github actions . isort isort is a library that sorts import statements in your python code. You can run isort manually by running : isort . Where to modify it ? You can modify the configuration of isort in pyproject.toml , under the section [tool.isort] . black black is a well-known code formatter for python. You can run black manually by running : black . Where to modify it ? You can modify the configuration of black in pyproject.toml , under the section [tool.black] . flake518 flake8 is another code formatter, with additional checks, such as code complexity. flake518 is just a small wrapper around flake8 , that allows to manage its configuration from a pyproject configuration file (so we have a single configuration file for all tools). You can run flake518 manually by running : flake518 . Where to modify it ? You can modify the configuration of flake518 in pyproject.toml , under the section [tool.flake8] . darglint darglint is a docstring linter, ensuring the docstrings written match the source code. You can run darglint manually by running : darglint . Unit-testing Unit-tests are implemented with pytest . You can run the unit-tests manually by running : python -m pytest Where to modify it ? You can add/remove tests in the python files in tests/ . If you wish to not run unit-tests, you need to remove it from the pre-commit hooks and from the Github actions . Pre-commit hooks Several pre-commit hooks are used in this template repository : Remove trailing whitespaces Ensure files have an empty line at the end Check the syntax of yaml files Ensure no large files are added Lint code with isort Lint code with black Lint code with flake518 Lint code with darglint Ensure unit-tests pass Ensure the coverage badge is up-to-date Where to modify it ? You can modify the configuration for pre-commit hooks in the file .pre-commit-config.yaml . Github actions Continuous Integration Continuous Integration ( CI ) is here to make sure that an open PR is \"safe to merge\", that is : make sure the code is well formatted, the unit-tests are passing, etc... Two Github actions are used for CI : one for the code format, and one for the unit-tests. These actions are ran whenever a PR is opened. Where to modify it ? You can modify the Github action for code format in .github/workflows/lint.yaml . You can modify the Github action for unit-tests in .github/workflows/pytest.yaml . Continuous Deployment Continuous Deployment ( CD ) is here to automatically deploying whatever needs to be deployed. It avoids manual labor. Three Github actions are used for CD : Deploying the latest documentation ( ran whenever a commit is pushed in the main branch ) Deploying the documentation of stable versions ( ran whenever a release is published ) Publishing the package to PyPi ( ran whenever a release is published ) Where to modify it ? You can modify the Github action for latest documentation deployment in .github/workflows/mike_dev.yaml . You can modify the Github action for stable documentation deployment in .github/workflows/mike_stable.yaml . You can modify the Github action for package publishing to PyPi in .github/workflows/auto_pypi.yaml . Others There is one more Github action, which takes care of labeling and closing any stale issue or PR. Where to modify it ? You can modify the Github action for stale issue/PR and its configuration in .github/workflows/stale.yaml . Issues & PR Templates This template repository uses a PR template . PR templates are useful to guide the format of new PR, making it easier to read and understand new PR. Where to modify it ? You can modify the PR template in the file .github/pull_request_template.md . The repository also defines several issue templates ( for bugs, documentation issues, and features requests ). These templates guide users in formatting their issue, and automatically label new issues. It's also useful to redirect users to the proper place to ask general questions (in the Discussion tab). Where to modify it ? You can modify each issue template in their appropriate file : .github/ISSUE_TEMPLATE/bug.yaml for bugs .github/ISSUE_TEMPLATE/doc.yaml for documentation issues .github/ISSUE_TEMPLATE/feature.yaml for feature requests You can also modify redirections in the configuration file .github/ISSUE_TEMPLATE/config.yml . Dependabot Dependabot is enabled in this template repository. It keeps your dependencies up-to-date. Where to modify it ? You can enable/disable it in the Settings tab of your Github repository ( Security & analysis section). You can modify the configuration in the file .github/dependabot.yml .","title":"Features"},{"location":"features/#features","text":"This page introduces the different features included in this template repository, as well as where to find them and modify them if necessary.","title":"Features"},{"location":"features/#documentation","text":"This documentation is generated using Mkdocs , using Material for Mkdocs theme. Check out Material for Mkdocs documentation , their documentation is complete and easy to follow. Where to modify it ? If you want to modify the documentation, modify the appropriate markdown files in docs/ . If you want to modify the configuration, take a look at mkdocs.yml . If you want to modify the theme (advanced), go to mkdocs/ . The documentation is versioned and published as a Github page with mike . Check mike's documentation for more details on how to use it. For a very short summary : mike deploy --push --update-aliases X.Y to push the current documentation version as X.Y version. mike deploy --push --update-aliases X.Y name to push the current documentation version as X.Y version, and add an alias name . mike retitle --push X.Y \"title\" to set the title of X.Y as title . For example, title can be the full version X.Y.Z . mike set-default --push name to set the alias name as default. mike delete --all --push to remove everything (careful with that !). mike serve to serve the documentation locally (for debugging).","title":"Documentation"},{"location":"features/#code-formatting-linters","text":"To lint and check the format of the code, this template uses several libraries : isort , black , flake8 , and darglint . Where to modify it ? If you wish to not use one of these tools, you need to remove it from the pre-commit hooks and from the Github actions .","title":"Code formatting &amp; linters"},{"location":"features/#isort","text":"isort is a library that sorts import statements in your python code. You can run isort manually by running : isort . Where to modify it ? You can modify the configuration of isort in pyproject.toml , under the section [tool.isort] .","title":"isort"},{"location":"features/#black","text":"black is a well-known code formatter for python. You can run black manually by running : black . Where to modify it ? You can modify the configuration of black in pyproject.toml , under the section [tool.black] .","title":"black"},{"location":"features/#flake518","text":"flake8 is another code formatter, with additional checks, such as code complexity. flake518 is just a small wrapper around flake8 , that allows to manage its configuration from a pyproject configuration file (so we have a single configuration file for all tools). You can run flake518 manually by running : flake518 . Where to modify it ? You can modify the configuration of flake518 in pyproject.toml , under the section [tool.flake8] .","title":"flake518"},{"location":"features/#darglint","text":"darglint is a docstring linter, ensuring the docstrings written match the source code. You can run darglint manually by running : darglint .","title":"darglint"},{"location":"features/#unit-testing","text":"Unit-tests are implemented with pytest . You can run the unit-tests manually by running : python -m pytest Where to modify it ? You can add/remove tests in the python files in tests/ . If you wish to not run unit-tests, you need to remove it from the pre-commit hooks and from the Github actions .","title":"Unit-testing"},{"location":"features/#pre-commit-hooks","text":"Several pre-commit hooks are used in this template repository : Remove trailing whitespaces Ensure files have an empty line at the end Check the syntax of yaml files Ensure no large files are added Lint code with isort Lint code with black Lint code with flake518 Lint code with darglint Ensure unit-tests pass Ensure the coverage badge is up-to-date Where to modify it ? You can modify the configuration for pre-commit hooks in the file .pre-commit-config.yaml .","title":"Pre-commit hooks"},{"location":"features/#github-actions","text":"","title":"Github actions"},{"location":"features/#continuous-integration","text":"Continuous Integration ( CI ) is here to make sure that an open PR is \"safe to merge\", that is : make sure the code is well formatted, the unit-tests are passing, etc... Two Github actions are used for CI : one for the code format, and one for the unit-tests. These actions are ran whenever a PR is opened. Where to modify it ? You can modify the Github action for code format in .github/workflows/lint.yaml . You can modify the Github action for unit-tests in .github/workflows/pytest.yaml .","title":"Continuous Integration"},{"location":"features/#continuous-deployment","text":"Continuous Deployment ( CD ) is here to automatically deploying whatever needs to be deployed. It avoids manual labor. Three Github actions are used for CD : Deploying the latest documentation ( ran whenever a commit is pushed in the main branch ) Deploying the documentation of stable versions ( ran whenever a release is published ) Publishing the package to PyPi ( ran whenever a release is published ) Where to modify it ? You can modify the Github action for latest documentation deployment in .github/workflows/mike_dev.yaml . You can modify the Github action for stable documentation deployment in .github/workflows/mike_stable.yaml . You can modify the Github action for package publishing to PyPi in .github/workflows/auto_pypi.yaml .","title":"Continuous Deployment"},{"location":"features/#others","text":"There is one more Github action, which takes care of labeling and closing any stale issue or PR. Where to modify it ? You can modify the Github action for stale issue/PR and its configuration in .github/workflows/stale.yaml .","title":"Others"},{"location":"features/#issues-pr-templates","text":"This template repository uses a PR template . PR templates are useful to guide the format of new PR, making it easier to read and understand new PR. Where to modify it ? You can modify the PR template in the file .github/pull_request_template.md . The repository also defines several issue templates ( for bugs, documentation issues, and features requests ). These templates guide users in formatting their issue, and automatically label new issues. It's also useful to redirect users to the proper place to ask general questions (in the Discussion tab). Where to modify it ? You can modify each issue template in their appropriate file : .github/ISSUE_TEMPLATE/bug.yaml for bugs .github/ISSUE_TEMPLATE/doc.yaml for documentation issues .github/ISSUE_TEMPLATE/feature.yaml for feature requests You can also modify redirections in the configuration file .github/ISSUE_TEMPLATE/config.yml .","title":"Issues &amp; PR Templates"},{"location":"features/#dependabot","text":"Dependabot is enabled in this template repository. It keeps your dependencies up-to-date. Where to modify it ? You can enable/disable it in the Settings tab of your Github repository ( Security & analysis section). You can modify the configuration in the file .github/dependabot.yml .","title":"Dependabot"},{"location":"usage/","text":"Usage Create your repository The very first step is to create your own repository from this template repository. To do this, just click the button \"Use this template\" : It will prompt you to create a new Github repository. Add your content Once your repository is created, you can just clone it and replace the dummy content with your content. To be sure you don't forget to replace anything, here is an exhaustive list of steps to follow : Change setup.py In setup.py , replace the name of the package, the version , the author and the author_email , the package description , and the package url . Replace README.md You can keep the same README outline, but you must update the core content. Make sure to search for any occurence of the string astariul/pytere and replace it with your own <user>/<repo> . Make sure to search for any occurence of the string astariul and replace it with your own username. Make sure to search for any occurence of the string pytere and replace it with the name of your package. Important Don't forget to carefully read your README and edit each section with a content that fit your package ! Update the documentation In the file mkdocs.yml , replace the site_name , repo_url , repo_name . Of course you also need to update the content of the documentation. You can do this by updating the md files in the docs/ folder. For the code reference (in docs/code_ref.md ), make sure to change the name from pytere to the name of your package. Info The documentation will be published in Github page after you create a Github release. Change the package name Make sure to replace the name of the folder pytere/ , which contains the source code of the package, to the name of your package. Also don't forget to remove the dummy code in pytere/__init__.py ! Update the configuration file In the configuration file pyproject.toml , you should replace the name pytere with the name of your package. Replace the tests Rename the test file tests/test_pytere.py and replace its content with actual tests ! Update names and links in .github/ folder A few links to update in .github/ folder : In .github/ISSUE_TEMPLATE/bug.yaml , replace pytere by the name of your package. In .github/ISSUE_TEMPLATE/config.yml , replace astariul/pytere by your <user>/<repo> . In .github/workflows/mike_dev.yaml , replace pytere by your package name. In .github/workflows/mike_stable.yaml , replace pytere by your package name. Optionally Optionally, if there is some features you don't want (like the Github action that automatically release your code to PyPi), you can remove it ! Head over to the Features page to see which file to remove. Enable Dependabot From the Github website, on your repository page, you can enable Dependabot by going to the Settings tab of your repository, then in the Security & analysis section you can enable Dependabot alerts and Dependabot security updates . Add your PyPi API token The Github action that automatically publish your package to PyPi (see Features ) requires your PyPi API token . You can store the API token in a Github secret . To do this, go to the Settings tab of your Github repository, then go to the Secrets section, and click the button New repository secret . Then set the name of the secret as PYPI_API_TOKEN , and put your API token in the value field.","title":"Usage"},{"location":"usage/#usage","text":"","title":"Usage"},{"location":"usage/#create-your-repository","text":"The very first step is to create your own repository from this template repository. To do this, just click the button \"Use this template\" : It will prompt you to create a new Github repository.","title":"Create your repository"},{"location":"usage/#add-your-content","text":"Once your repository is created, you can just clone it and replace the dummy content with your content. To be sure you don't forget to replace anything, here is an exhaustive list of steps to follow :","title":"Add your content"},{"location":"usage/#change-setuppy","text":"In setup.py , replace the name of the package, the version , the author and the author_email , the package description , and the package url .","title":"Change setup.py"},{"location":"usage/#replace-readmemd","text":"You can keep the same README outline, but you must update the core content. Make sure to search for any occurence of the string astariul/pytere and replace it with your own <user>/<repo> . Make sure to search for any occurence of the string astariul and replace it with your own username. Make sure to search for any occurence of the string pytere and replace it with the name of your package. Important Don't forget to carefully read your README and edit each section with a content that fit your package !","title":"Replace README.md"},{"location":"usage/#update-the-documentation","text":"In the file mkdocs.yml , replace the site_name , repo_url , repo_name . Of course you also need to update the content of the documentation. You can do this by updating the md files in the docs/ folder. For the code reference (in docs/code_ref.md ), make sure to change the name from pytere to the name of your package. Info The documentation will be published in Github page after you create a Github release.","title":"Update the documentation"},{"location":"usage/#change-the-package-name","text":"Make sure to replace the name of the folder pytere/ , which contains the source code of the package, to the name of your package. Also don't forget to remove the dummy code in pytere/__init__.py !","title":"Change the package name"},{"location":"usage/#update-the-configuration-file","text":"In the configuration file pyproject.toml , you should replace the name pytere with the name of your package.","title":"Update the configuration file"},{"location":"usage/#replace-the-tests","text":"Rename the test file tests/test_pytere.py and replace its content with actual tests !","title":"Replace the tests"},{"location":"usage/#update-names-and-links-in-github-folder","text":"A few links to update in .github/ folder : In .github/ISSUE_TEMPLATE/bug.yaml , replace pytere by the name of your package. In .github/ISSUE_TEMPLATE/config.yml , replace astariul/pytere by your <user>/<repo> . In .github/workflows/mike_dev.yaml , replace pytere by your package name. In .github/workflows/mike_stable.yaml , replace pytere by your package name.","title":"Update names and links in .github/ folder"},{"location":"usage/#optionally","text":"Optionally, if there is some features you don't want (like the Github action that automatically release your code to PyPi), you can remove it ! Head over to the Features page to see which file to remove.","title":"Optionally"},{"location":"usage/#enable-dependabot","text":"From the Github website, on your repository page, you can enable Dependabot by going to the Settings tab of your repository, then in the Security & analysis section you can enable Dependabot alerts and Dependabot security updates .","title":"Enable Dependabot"},{"location":"usage/#add-your-pypi-api-token","text":"The Github action that automatically publish your package to PyPi (see Features ) requires your PyPi API token . You can store the API token in a Github secret . To do this, go to the Settings tab of your Github repository, then go to the Secrets section, and click the button New repository secret . Then set the name of the secret as PYPI_API_TOKEN , and put your API token in the value field.","title":"Add your PyPi API token"}]}