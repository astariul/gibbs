{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Pytere Introduction Welcome to the documentation of the pytere package. pytere ( Py thon te mplate re pository) is simply a template repository for python packages. This full-fledged template provides you with everything you need ( documentation, unit-tests, code linting & formatting, pre-commit hooks, etc... ) so you can just focus on writing the code. If you want to use this template, follow the instructions at the Usage page. Installation Latest version You can install the latest version of the package directly from PyPi with : pip install pytere Hint If you want to install directly from Github, run : pip install git+https://github.com/astariul/pytere.git Specific version You can install a specific version of the package ( 0.1.0 in ths example) from PyPi with : pip install pytere == 0 .1.0 Hint If you want to install directly from Github, run : pip install git+https://github.com/astariul/pytere.git@v0.1.0 Local You can also clone the repository locally and install it manually : git clone https://github.com/astariul/pytere.git cd pytere pip install -e . Extra dependencies You can also install extras dependencies, for example : pip install -e . [ docs ] Will install necessary dependencies for building the docs. Hint If you installed the package directly from github, run : pip install \"pytere[docs] @ git+https://github.com/astariul/pytere.git\" List of extra dependencies : test : Dependencies for running unit-tests. hook : Dependencies for running pre-commit hooks. lint : Dependencies for running linters and formatters. docs : Dependencies for building the documentation. dev : test + hook + lint + docs . all : All extra dependencies. Contribute To contribute, install the package locally (see Installation ), create your own branch, add your code/tests/documentation, and open a PR ! Pre-commit hooks Pre-commit hooks are set to check the code added whenever you commit something. When you try to commit your code, hooks are run, and if anything fails ( linters, tests, etc... ), your code will not be committed. You then have to fix your code and try to commit again ! Info If you never ran the hooks before, install it with : pre-commit install Documentation When you contribute, make sure to keep the documentation up-to-date. You can visualize the documentation locally by running : mkdocs serve","title":"Welcome"},{"location":"#pytere","text":"","title":"Pytere"},{"location":"#introduction","text":"Welcome to the documentation of the pytere package. pytere ( Py thon te mplate re pository) is simply a template repository for python packages. This full-fledged template provides you with everything you need ( documentation, unit-tests, code linting & formatting, pre-commit hooks, etc... ) so you can just focus on writing the code. If you want to use this template, follow the instructions at the Usage page.","title":"Introduction"},{"location":"#installation","text":"","title":"Installation"},{"location":"#latest-version","text":"You can install the latest version of the package directly from PyPi with : pip install pytere Hint If you want to install directly from Github, run : pip install git+https://github.com/astariul/pytere.git","title":"Latest version"},{"location":"#specific-version","text":"You can install a specific version of the package ( 0.1.0 in ths example) from PyPi with : pip install pytere == 0 .1.0 Hint If you want to install directly from Github, run : pip install git+https://github.com/astariul/pytere.git@v0.1.0","title":"Specific version"},{"location":"#local","text":"You can also clone the repository locally and install it manually : git clone https://github.com/astariul/pytere.git cd pytere pip install -e .","title":"Local"},{"location":"#extra-dependencies","text":"You can also install extras dependencies, for example : pip install -e . [ docs ] Will install necessary dependencies for building the docs. Hint If you installed the package directly from github, run : pip install \"pytere[docs] @ git+https://github.com/astariul/pytere.git\" List of extra dependencies : test : Dependencies for running unit-tests. hook : Dependencies for running pre-commit hooks. lint : Dependencies for running linters and formatters. docs : Dependencies for building the documentation. dev : test + hook + lint + docs . all : All extra dependencies.","title":"Extra dependencies"},{"location":"#contribute","text":"To contribute, install the package locally (see Installation ), create your own branch, add your code/tests/documentation, and open a PR !","title":"Contribute"},{"location":"#pre-commit-hooks","text":"Pre-commit hooks are set to check the code added whenever you commit something. When you try to commit your code, hooks are run, and if anything fails ( linters, tests, etc... ), your code will not be committed. You then have to fix your code and try to commit again ! Info If you never ran the hooks before, install it with : pre-commit install","title":"Pre-commit hooks"},{"location":"#documentation","text":"When you contribute, make sure to keep the documentation up-to-date. You can visualize the documentation locally by running : mkdocs serve","title":"Documentation"},{"location":"code_ref/","text":"gibbs hub Hub Source code in gibbs/hub.py class Hub : def __init__ ( self , port = DEFAULT_PORT , resp_buffer_size = RESPONSE_BUFFER_SIZE ): super () . __init__ () self . port = port self . resp_buffer_size = resp_buffer_size self . socket = None self . ready_workers = None self . responses = {} self . req_states = {} async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff address , _ , resp = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . ready_workers . put ( address ) # Check if the response is a prediction or just a ready message if resp != b \"\" : req_id , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None ) # Store the response and set the Event if req_id in self . req_states : self . responses [ req_id ] = res self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" ) async def request ( self , * args , ** kwargs ): # Before anything, if the receiving loop was not started, start it if self . socket is None : # Create what we need here in this process/context context = zmq . asyncio . Context () self . socket = context . socket ( zmq . ROUTER ) self . socket . bind ( f \"tcp://*: { self . port } \" ) self . ready_workers = asyncio . Queue () # Fire and forget : infinite loop, taking care of receiving stuff from the socket logger . info ( \"Starting receiving loop...\" ) asyncio . create_task ( self . receive_loop ()) # Assign a unique ID to the request, so we know which one to wait for req_id = uuid . uuid4 () . hex # Create an event for this request, so we know when we receive an answer self . req_states [ req_id ] = asyncio . Event () # Send the request address = await self . ready_workers . get () logger . debug ( f \"Sending request # { req_id } to worker # { address } \" ) await self . socket . send_multipart ([ address , b \"\" , msgpack . packb ([ req_id , args , kwargs ])]) # Wait for the receiving loop to receive the response await self . req_states [ req_id ] . wait () logger . debug ( f \"Accessing result for request # { req_id } \" ) # Once we get it, access the result and return it res = self . responses . pop ( req_id ) # Don't forget to remove the event self . req_states . pop ( req_id ) return res def __del__ ( self ): if self . socket is not None : self . socket . close () receive_loop ( self ) async Infinite loop for receiving responses from the workers. Source code in gibbs/hub.py async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff address , _ , resp = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . ready_workers . put ( address ) # Check if the response is a prediction or just a ready message if resp != b \"\" : req_id , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None ) # Store the response and set the Event if req_id in self . req_states : self . responses [ req_id ] = res self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" ) worker Worker ( Process ) Source code in gibbs/worker.py class Worker ( Process ): def __init__ ( self , worker_cls , * args , gibbs_host = \"localhost\" , gibbs_port = DEFAULT_PORT , ** kwargs ): super () . __init__ () self . worker_cls = worker_cls self . worker_args = args self . worker_kwargs = kwargs self . identity = uuid . uuid4 () . hex self . host = gibbs_host self . port = gibbs_port def run ( self ): # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the context for the socket context = zmq . Context () socket = context . socket ( zmq . REQ ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) # Tell the Hub we are ready socket . send ( b \"\" ) logger . info ( \"Worker ready to roll\" ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) workload = socket . recv () req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments res = worker ( * req_args , ** req_kwargs ) logger . debug ( \"Sending back the response\" ) socket . send ( msgpack . packb ([ req_id , res ])) run ( self ) Method to be run in sub-process; can be overridden in sub-class Source code in gibbs/worker.py def run ( self ): # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the context for the socket context = zmq . Context () socket = context . socket ( zmq . REQ ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) # Tell the Hub we are ready socket . send ( b \"\" ) logger . info ( \"Worker ready to roll\" ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) workload = socket . recv () req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments res = worker ( * req_args , ** req_kwargs ) logger . debug ( \"Sending back the response\" ) socket . send ( msgpack . packb ([ req_id , res ]))","title":"gibbs"},{"location":"code_ref/#gibbs","text":"","title":"gibbs"},{"location":"code_ref/#gibbs.hub","text":"","title":"hub"},{"location":"code_ref/#gibbs.hub.Hub","text":"Source code in gibbs/hub.py class Hub : def __init__ ( self , port = DEFAULT_PORT , resp_buffer_size = RESPONSE_BUFFER_SIZE ): super () . __init__ () self . port = port self . resp_buffer_size = resp_buffer_size self . socket = None self . ready_workers = None self . responses = {} self . req_states = {} async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff address , _ , resp = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . ready_workers . put ( address ) # Check if the response is a prediction or just a ready message if resp != b \"\" : req_id , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None ) # Store the response and set the Event if req_id in self . req_states : self . responses [ req_id ] = res self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" ) async def request ( self , * args , ** kwargs ): # Before anything, if the receiving loop was not started, start it if self . socket is None : # Create what we need here in this process/context context = zmq . asyncio . Context () self . socket = context . socket ( zmq . ROUTER ) self . socket . bind ( f \"tcp://*: { self . port } \" ) self . ready_workers = asyncio . Queue () # Fire and forget : infinite loop, taking care of receiving stuff from the socket logger . info ( \"Starting receiving loop...\" ) asyncio . create_task ( self . receive_loop ()) # Assign a unique ID to the request, so we know which one to wait for req_id = uuid . uuid4 () . hex # Create an event for this request, so we know when we receive an answer self . req_states [ req_id ] = asyncio . Event () # Send the request address = await self . ready_workers . get () logger . debug ( f \"Sending request # { req_id } to worker # { address } \" ) await self . socket . send_multipart ([ address , b \"\" , msgpack . packb ([ req_id , args , kwargs ])]) # Wait for the receiving loop to receive the response await self . req_states [ req_id ] . wait () logger . debug ( f \"Accessing result for request # { req_id } \" ) # Once we get it, access the result and return it res = self . responses . pop ( req_id ) # Don't forget to remove the event self . req_states . pop ( req_id ) return res def __del__ ( self ): if self . socket is not None : self . socket . close ()","title":"Hub"},{"location":"code_ref/#gibbs.hub.Hub.receive_loop","text":"Infinite loop for receiving responses from the workers. Source code in gibbs/hub.py async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff address , _ , resp = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . ready_workers . put ( address ) # Check if the response is a prediction or just a ready message if resp != b \"\" : req_id , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None ) # Store the response and set the Event if req_id in self . req_states : self . responses [ req_id ] = res self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" )","title":"receive_loop()"},{"location":"code_ref/#gibbs.worker","text":"","title":"worker"},{"location":"code_ref/#gibbs.worker.Worker","text":"Source code in gibbs/worker.py class Worker ( Process ): def __init__ ( self , worker_cls , * args , gibbs_host = \"localhost\" , gibbs_port = DEFAULT_PORT , ** kwargs ): super () . __init__ () self . worker_cls = worker_cls self . worker_args = args self . worker_kwargs = kwargs self . identity = uuid . uuid4 () . hex self . host = gibbs_host self . port = gibbs_port def run ( self ): # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the context for the socket context = zmq . Context () socket = context . socket ( zmq . REQ ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) # Tell the Hub we are ready socket . send ( b \"\" ) logger . info ( \"Worker ready to roll\" ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) workload = socket . recv () req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments res = worker ( * req_args , ** req_kwargs ) logger . debug ( \"Sending back the response\" ) socket . send ( msgpack . packb ([ req_id , res ]))","title":"Worker"},{"location":"code_ref/#gibbs.worker.Worker.run","text":"Method to be run in sub-process; can be overridden in sub-class Source code in gibbs/worker.py def run ( self ): # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the context for the socket context = zmq . Context () socket = context . socket ( zmq . REQ ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) # Tell the Hub we are ready socket . send ( b \"\" ) logger . info ( \"Worker ready to roll\" ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) workload = socket . recv () req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments res = worker ( * req_args , ** req_kwargs ) logger . debug ( \"Sending back the response\" ) socket . send ( msgpack . packb ([ req_id , res ]))","title":"run()"},{"location":"features/","text":"Features This page introduces the different features included in this template repository, as well as where to find them and modify them if necessary. Documentation This documentation is generated using Mkdocs , using Material for Mkdocs theme. Check out Material for Mkdocs documentation , their documentation is complete and easy to follow. Where to modify it ? If you want to modify the documentation, modify the appropriate markdown files in docs/ . If you want to modify the configuration, take a look at mkdocs.yml . If you want to modify the theme (advanced), go to mkdocs/ . The documentation is versioned and published as a Github page with mike . Check mike's documentation for more details on how to use it. For a very short summary : mike deploy --push --update-aliases X.Y to push the current documentation version as X.Y version. mike deploy --push --update-aliases X.Y name to push the current documentation version as X.Y version, and add an alias name . mike retitle --push X.Y \"title\" to set the title of X.Y as title . For example, title can be the full version X.Y.Z . mike set-default --push name to set the alias name as default. mike delete --all --push to remove everything (careful with that !). mike serve to serve the documentation locally (for debugging). Code formatting & linters To lint and check the format of the code, this template uses several libraries : isort , black , flake8 , and darglint . Where to modify it ? If you wish to not use one of these tools, you need to remove it from the pre-commit hooks and from the Github actions . isort isort is a library that sorts import statements in your python code. You can run isort manually by running : isort . Where to modify it ? You can modify the configuration of isort in pyproject.toml , under the section [tool.isort] . black black is a well-known code formatter for python. You can run black manually by running : black . Where to modify it ? You can modify the configuration of black in pyproject.toml , under the section [tool.black] . flake518 flake8 is another code formatter, with additional checks, such as code complexity. flake518 is just a small wrapper around flake8 , that allows to manage its configuration from a pyproject configuration file (so we have a single configuration file for all tools). You can run flake518 manually by running : flake518 . Where to modify it ? You can modify the configuration of flake518 in pyproject.toml , under the section [tool.flake8] . darglint darglint is a docstring linter, ensuring the docstrings written match the source code. You can run darglint manually by running : darglint . Unit-testing Unit-tests are implemented with pytest . You can run the unit-tests manually by running : python -m pytest Where to modify it ? You can add/remove tests in the python files in tests/ . If you wish to not run unit-tests, you need to remove it from the pre-commit hooks and from the Github actions . Pre-commit hooks Several pre-commit hooks are used in this template repository : Remove trailing whitespaces Ensure files have an empty line at the end Check the syntax of yaml files Ensure no large files are added Lint code with isort Lint code with black Lint code with flake518 Lint code with darglint Ensure unit-tests pass Ensure the coverage badge is up-to-date Where to modify it ? You can modify the configuration for pre-commit hooks in the file .pre-commit-config.yaml . Github actions Continuous Integration Continuous Integration ( CI ) is here to make sure that an open PR is \"safe to merge\", that is : make sure the code is well formatted, the unit-tests are passing, etc... Two Github actions are used for CI : one for the code format, and one for the unit-tests. These actions are ran whenever a PR is opened. Where to modify it ? You can modify the Github action for code format in .github/workflows/lint.yaml . You can modify the Github action for unit-tests in .github/workflows/pytest.yaml . Continuous Deployment Continuous Deployment ( CD ) is here to automatically deploying whatever needs to be deployed. It avoids manual labor. Three Github actions are used for CD : Deploying the latest documentation ( ran whenever a commit is pushed in the main branch ) Deploying the documentation of stable versions ( ran whenever a release is published ) Publishing the package to PyPi ( ran whenever a release is published ) Where to modify it ? You can modify the Github action for latest documentation deployment in .github/workflows/mike_dev.yaml . You can modify the Github action for stable documentation deployment in .github/workflows/mike_stable.yaml . You can modify the Github action for package publishing to PyPi in .github/workflows/auto_pypi.yaml . Others There is one more Github action, which takes care of labeling and closing any stale issue or PR. Where to modify it ? You can modify the Github action for stale issue/PR and its configuration in .github/workflows/stale.yaml . Issues & PR Templates This template repository uses a PR template . PR templates are useful to guide the format of new PR, making it easier to read and understand new PR. Where to modify it ? You can modify the PR template in the file .github/pull_request_template.md . The repository also defines several issue templates ( for bugs, documentation issues, and features requests ). These templates guide users in formatting their issue, and automatically label new issues. It's also useful to redirect users to the proper place to ask general questions (in the Discussion tab). Where to modify it ? You can modify each issue template in their appropriate file : .github/ISSUE_TEMPLATE/bug.yaml for bugs .github/ISSUE_TEMPLATE/doc.yaml for documentation issues .github/ISSUE_TEMPLATE/feature.yaml for feature requests You can also modify redirections in the configuration file .github/ISSUE_TEMPLATE/config.yml . Dependabot Dependabot is enabled in this template repository. It keeps your dependencies up-to-date. Where to modify it ? You can enable/disable it in the Settings tab of your Github repository ( Security & analysis section). You can modify the configuration in the file .github/dependabot.yml .","title":"Features"},{"location":"features/#features","text":"This page introduces the different features included in this template repository, as well as where to find them and modify them if necessary.","title":"Features"},{"location":"features/#documentation","text":"This documentation is generated using Mkdocs , using Material for Mkdocs theme. Check out Material for Mkdocs documentation , their documentation is complete and easy to follow. Where to modify it ? If you want to modify the documentation, modify the appropriate markdown files in docs/ . If you want to modify the configuration, take a look at mkdocs.yml . If you want to modify the theme (advanced), go to mkdocs/ . The documentation is versioned and published as a Github page with mike . Check mike's documentation for more details on how to use it. For a very short summary : mike deploy --push --update-aliases X.Y to push the current documentation version as X.Y version. mike deploy --push --update-aliases X.Y name to push the current documentation version as X.Y version, and add an alias name . mike retitle --push X.Y \"title\" to set the title of X.Y as title . For example, title can be the full version X.Y.Z . mike set-default --push name to set the alias name as default. mike delete --all --push to remove everything (careful with that !). mike serve to serve the documentation locally (for debugging).","title":"Documentation"},{"location":"features/#code-formatting-linters","text":"To lint and check the format of the code, this template uses several libraries : isort , black , flake8 , and darglint . Where to modify it ? If you wish to not use one of these tools, you need to remove it from the pre-commit hooks and from the Github actions .","title":"Code formatting &amp; linters"},{"location":"features/#isort","text":"isort is a library that sorts import statements in your python code. You can run isort manually by running : isort . Where to modify it ? You can modify the configuration of isort in pyproject.toml , under the section [tool.isort] .","title":"isort"},{"location":"features/#black","text":"black is a well-known code formatter for python. You can run black manually by running : black . Where to modify it ? You can modify the configuration of black in pyproject.toml , under the section [tool.black] .","title":"black"},{"location":"features/#flake518","text":"flake8 is another code formatter, with additional checks, such as code complexity. flake518 is just a small wrapper around flake8 , that allows to manage its configuration from a pyproject configuration file (so we have a single configuration file for all tools). You can run flake518 manually by running : flake518 . Where to modify it ? You can modify the configuration of flake518 in pyproject.toml , under the section [tool.flake8] .","title":"flake518"},{"location":"features/#darglint","text":"darglint is a docstring linter, ensuring the docstrings written match the source code. You can run darglint manually by running : darglint .","title":"darglint"},{"location":"features/#unit-testing","text":"Unit-tests are implemented with pytest . You can run the unit-tests manually by running : python -m pytest Where to modify it ? You can add/remove tests in the python files in tests/ . If you wish to not run unit-tests, you need to remove it from the pre-commit hooks and from the Github actions .","title":"Unit-testing"},{"location":"features/#pre-commit-hooks","text":"Several pre-commit hooks are used in this template repository : Remove trailing whitespaces Ensure files have an empty line at the end Check the syntax of yaml files Ensure no large files are added Lint code with isort Lint code with black Lint code with flake518 Lint code with darglint Ensure unit-tests pass Ensure the coverage badge is up-to-date Where to modify it ? You can modify the configuration for pre-commit hooks in the file .pre-commit-config.yaml .","title":"Pre-commit hooks"},{"location":"features/#github-actions","text":"","title":"Github actions"},{"location":"features/#continuous-integration","text":"Continuous Integration ( CI ) is here to make sure that an open PR is \"safe to merge\", that is : make sure the code is well formatted, the unit-tests are passing, etc... Two Github actions are used for CI : one for the code format, and one for the unit-tests. These actions are ran whenever a PR is opened. Where to modify it ? You can modify the Github action for code format in .github/workflows/lint.yaml . You can modify the Github action for unit-tests in .github/workflows/pytest.yaml .","title":"Continuous Integration"},{"location":"features/#continuous-deployment","text":"Continuous Deployment ( CD ) is here to automatically deploying whatever needs to be deployed. It avoids manual labor. Three Github actions are used for CD : Deploying the latest documentation ( ran whenever a commit is pushed in the main branch ) Deploying the documentation of stable versions ( ran whenever a release is published ) Publishing the package to PyPi ( ran whenever a release is published ) Where to modify it ? You can modify the Github action for latest documentation deployment in .github/workflows/mike_dev.yaml . You can modify the Github action for stable documentation deployment in .github/workflows/mike_stable.yaml . You can modify the Github action for package publishing to PyPi in .github/workflows/auto_pypi.yaml .","title":"Continuous Deployment"},{"location":"features/#others","text":"There is one more Github action, which takes care of labeling and closing any stale issue or PR. Where to modify it ? You can modify the Github action for stale issue/PR and its configuration in .github/workflows/stale.yaml .","title":"Others"},{"location":"features/#issues-pr-templates","text":"This template repository uses a PR template . PR templates are useful to guide the format of new PR, making it easier to read and understand new PR. Where to modify it ? You can modify the PR template in the file .github/pull_request_template.md . The repository also defines several issue templates ( for bugs, documentation issues, and features requests ). These templates guide users in formatting their issue, and automatically label new issues. It's also useful to redirect users to the proper place to ask general questions (in the Discussion tab). Where to modify it ? You can modify each issue template in their appropriate file : .github/ISSUE_TEMPLATE/bug.yaml for bugs .github/ISSUE_TEMPLATE/doc.yaml for documentation issues .github/ISSUE_TEMPLATE/feature.yaml for feature requests You can also modify redirections in the configuration file .github/ISSUE_TEMPLATE/config.yml .","title":"Issues &amp; PR Templates"},{"location":"features/#dependabot","text":"Dependabot is enabled in this template repository. It keeps your dependencies up-to-date. Where to modify it ? You can enable/disable it in the Settings tab of your Github repository ( Security & analysis section). You can modify the configuration in the file .github/dependabot.yml .","title":"Dependabot"},{"location":"usage/","text":"Usage Create your repository The very first step is to create your own repository from this template repository. To do this, just click the button \"Use this template\" : It will prompt you to create a new Github repository. Add your content Once your repository is created, you can just clone it and replace the dummy content with your content. To be sure you don't forget to replace anything, here is an exhaustive list of steps to follow : Change setup.py In setup.py , replace the name of the package, the version , the author and the author_email , the package description , and the package url . Replace README.md You can keep the same README outline, but you must update the core content. Make sure to search for any occurence of the string astariul/pytere and replace it with your own <user>/<repo> . Make sure to search for any occurence of the string astariul and replace it with your own username. Make sure to search for any occurence of the string pytere and replace it with the name of your package. Important Don't forget to carefully read your README and edit each section with a content that fit your package ! Update the documentation In the file mkdocs.yml , replace the site_name , repo_url , repo_name . Of course you also need to update the content of the documentation. You can do this by updating the md files in the docs/ folder. For the code reference (in docs/code_ref.md ), make sure to change the name from pytere to the name of your package. Info The documentation will be published in Github page after you create a Github release. Change the package name Make sure to replace the name of the folder pytere/ , which contains the source code of the package, to the name of your package. Also don't forget to remove the dummy code in pytere/__init__.py ! Update the configuration file In the configuration file pyproject.toml , you should replace the name pytere with the name of your package. Replace the tests Rename the test file tests/test_pytere.py and replace its content with actual tests ! Update names and links in .github/ folder A few links to update in .github/ folder : In .github/ISSUE_TEMPLATE/bug.yaml , replace pytere by the name of your package. In .github/ISSUE_TEMPLATE/config.yml , replace astariul/pytere by your <user>/<repo> . In .github/workflows/mike_dev.yaml , replace pytere by your package name. In .github/workflows/mike_stable.yaml , replace pytere by your package name. Optionally Optionally, if there is some features you don't want (like the Github action that automatically release your code to PyPi), you can remove it ! Head over to the Features page to see which file to remove. Enable Dependabot From the Github website, on your repository page, you can enable Dependabot by going to the Settings tab of your repository, then in the Security & analysis section you can enable Dependabot alerts and Dependabot security updates . Add your PyPi API token The Github action that automatically publish your package to PyPi (see Features ) requires your PyPi API token . You can store the API token in a Github secret . To do this, go to the Settings tab of your Github repository, then go to the Secrets section, and click the button New repository secret . Then set the name of the secret as PYPI_API_TOKEN , and put your API token in the value field.","title":"Usage"},{"location":"usage/#usage","text":"","title":"Usage"},{"location":"usage/#create-your-repository","text":"The very first step is to create your own repository from this template repository. To do this, just click the button \"Use this template\" : It will prompt you to create a new Github repository.","title":"Create your repository"},{"location":"usage/#add-your-content","text":"Once your repository is created, you can just clone it and replace the dummy content with your content. To be sure you don't forget to replace anything, here is an exhaustive list of steps to follow :","title":"Add your content"},{"location":"usage/#change-setuppy","text":"In setup.py , replace the name of the package, the version , the author and the author_email , the package description , and the package url .","title":"Change setup.py"},{"location":"usage/#replace-readmemd","text":"You can keep the same README outline, but you must update the core content. Make sure to search for any occurence of the string astariul/pytere and replace it with your own <user>/<repo> . Make sure to search for any occurence of the string astariul and replace it with your own username. Make sure to search for any occurence of the string pytere and replace it with the name of your package. Important Don't forget to carefully read your README and edit each section with a content that fit your package !","title":"Replace README.md"},{"location":"usage/#update-the-documentation","text":"In the file mkdocs.yml , replace the site_name , repo_url , repo_name . Of course you also need to update the content of the documentation. You can do this by updating the md files in the docs/ folder. For the code reference (in docs/code_ref.md ), make sure to change the name from pytere to the name of your package. Info The documentation will be published in Github page after you create a Github release.","title":"Update the documentation"},{"location":"usage/#change-the-package-name","text":"Make sure to replace the name of the folder pytere/ , which contains the source code of the package, to the name of your package. Also don't forget to remove the dummy code in pytere/__init__.py !","title":"Change the package name"},{"location":"usage/#update-the-configuration-file","text":"In the configuration file pyproject.toml , you should replace the name pytere with the name of your package.","title":"Update the configuration file"},{"location":"usage/#replace-the-tests","text":"Rename the test file tests/test_pytere.py and replace its content with actual tests !","title":"Replace the tests"},{"location":"usage/#update-names-and-links-in-github-folder","text":"A few links to update in .github/ folder : In .github/ISSUE_TEMPLATE/bug.yaml , replace pytere by the name of your package. In .github/ISSUE_TEMPLATE/config.yml , replace astariul/pytere by your <user>/<repo> . In .github/workflows/mike_dev.yaml , replace pytere by your package name. In .github/workflows/mike_stable.yaml , replace pytere by your package name.","title":"Update names and links in .github/ folder"},{"location":"usage/#optionally","text":"Optionally, if there is some features you don't want (like the Github action that automatically release your code to PyPi), you can remove it ! Head over to the Features page to see which file to remove.","title":"Optionally"},{"location":"usage/#enable-dependabot","text":"From the Github website, on your repository page, you can enable Dependabot by going to the Settings tab of your repository, then in the Security & analysis section you can enable Dependabot alerts and Dependabot security updates .","title":"Enable Dependabot"},{"location":"usage/#add-your-pypi-api-token","text":"The Github action that automatically publish your package to PyPi (see Features ) requires your PyPi API token . You can store the API token in a Github secret . To do this, go to the Settings tab of your Github repository, then go to the Secrets section, and click the button New repository secret . Then set the name of the secret as PYPI_API_TOKEN , and put your API token in the value field.","title":"Add your PyPi API token"}]}