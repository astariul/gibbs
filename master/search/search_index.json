{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Gibbs Introduction Welcome to the documentation of the gibbs package. gibbs is a package that help you scale your ML workers (and pure python code) across machines. Features : \u26a1\ufe0f Highly performant \ud83d\udd00 Asynchronous \ud83d\udc25 Easy-to-use Installation Latest version You can install the latest stable version of the package directly from PyPi with : pip install gibbs Bleeding-edge version To install the bleeding-edge version ( main , not released), you can do : pip install git+https://github.com/astariul/gibbs.git Local version For development purposes, you can clone the repository locally and install it manually : git clone https://github.com/astariul/gibbs.git cd gibbs pip install -e . Extra dependencies You can also install extras dependencies, for example : pip install gibbs [ docs ] Will install necessary dependencies for building the docs. List of extra dependencies : test : Dependencies for running unit-tests. hook : Dependencies for running pre-commit hooks. lint : Dependencies for running linters and formatters. docs : Dependencies for building the documentation. ex : Dependencies for running the examples. dev : test + hook + lint + docs . all : All extra dependencies. Contribute To contribute, install the package locally (see Installation ), create your own branch, add your code/tests/documentation, and open a PR ! Pre-commit hooks Pre-commit hooks are set to check the code added whenever you commit something. When you try to commit your code, hooks are run, and if anything fails ( linters, etc... ), your code will not be committed. You then have to fix your code and try to commit again ! Info If you never ran the hooks before, install it with : pre-commit install Documentation When you contribute, make sure to keep the documentation up-to-date. You can visualize the documentation locally by running : mkdocs serve","title":"Welcome"},{"location":"#gibbs","text":"","title":"Gibbs"},{"location":"#introduction","text":"Welcome to the documentation of the gibbs package. gibbs is a package that help you scale your ML workers (and pure python code) across machines. Features : \u26a1\ufe0f Highly performant \ud83d\udd00 Asynchronous \ud83d\udc25 Easy-to-use","title":"Introduction"},{"location":"#installation","text":"","title":"Installation"},{"location":"#latest-version","text":"You can install the latest stable version of the package directly from PyPi with : pip install gibbs","title":"Latest version"},{"location":"#bleeding-edge-version","text":"To install the bleeding-edge version ( main , not released), you can do : pip install git+https://github.com/astariul/gibbs.git","title":"Bleeding-edge version"},{"location":"#local-version","text":"For development purposes, you can clone the repository locally and install it manually : git clone https://github.com/astariul/gibbs.git cd gibbs pip install -e .","title":"Local version"},{"location":"#extra-dependencies","text":"You can also install extras dependencies, for example : pip install gibbs [ docs ] Will install necessary dependencies for building the docs. List of extra dependencies : test : Dependencies for running unit-tests. hook : Dependencies for running pre-commit hooks. lint : Dependencies for running linters and formatters. docs : Dependencies for building the documentation. ex : Dependencies for running the examples. dev : test + hook + lint + docs . all : All extra dependencies.","title":"Extra dependencies"},{"location":"#contribute","text":"To contribute, install the package locally (see Installation ), create your own branch, add your code/tests/documentation, and open a PR !","title":"Contribute"},{"location":"#pre-commit-hooks","text":"Pre-commit hooks are set to check the code added whenever you commit something. When you try to commit your code, hooks are run, and if anything fails ( linters, etc... ), your code will not be committed. You then have to fix your code and try to commit again ! Info If you never ran the hooks before, install it with : pre-commit install","title":"Pre-commit hooks"},{"location":"#documentation","text":"When you contribute, make sure to keep the documentation up-to-date. You can visualize the documentation locally by running : mkdocs serve","title":"Documentation"},{"location":"code_ref/","text":"Code reference API Hub Class acting as a hub for all the requests to send. All requests sent through this class will be automatically dispatched to connected workers, will wait for the responses and return it. Parameters: Name Type Description Default port int Port number to use for the sockets. Defaults to DEFAULT_PORT. 5019 heartbeat_interval float Heartbeat interval used by the workers, in seconds. Defaults to DEFAULT_HEARTBEAT_INTERVAL. 1 resp_buffer_size int Maximum response buffer size. Defaults to RESPONSE_BUFFER_SIZE. 4096 Source code in gibbs/hub.py class Hub : \"\"\"Class acting as a hub for all the requests to send. All requests sent through this class will be automatically dispatched to connected workers, will wait for the responses and return it. Args: port (int): Port number to use for the sockets. Defaults to DEFAULT_PORT. heartbeat_interval (float): Heartbeat interval used by the workers, in seconds. Defaults to DEFAULT_HEARTBEAT_INTERVAL. resp_buffer_size (int): Maximum response buffer size. Defaults to RESPONSE_BUFFER_SIZE. \"\"\" def __init__ ( self , port : int = DEFAULT_PORT , heartbeat_interval : float = DEFAULT_HEARTBEAT_INTERVAL , resp_buffer_size : int = RESPONSE_BUFFER_SIZE , ): super () . __init__ () self . port = port self . heartbeat_t = heartbeat_interval self . socket = None self . w_manager = None self . req_manager = RequestManager ( resp_buffer_size = resp_buffer_size ) async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff logger . debug ( \"Receiving...\" ) address , * frames = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . w_manager . reckon ( address ) if len ( frames ) == 1 : # Answer the Ping logger . debug ( \"Answering the ping\" ) await self . socket . send_multipart ([ address , b \"\" , PONG ]) continue _ , resp = frames req_id , code , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) self . req_manager . store ( req_id , code , res ) def _start_if_not_started ( self ): \"\"\"Helper method to ensure everything is properly started (socket is initialized, receiving loop is started, etc...). \"\"\" if self . socket is None : # Create what we need here in this process/context context = zmq . asyncio . Context () self . socket = context . socket ( zmq . ROUTER ) self . socket . bind ( f \"tcp://*: { self . port } \" ) self . w_manager = WorkerManager ( heartbeat_interval = self . heartbeat_t ) # Fire and forget : infinite loop, taking care of receiving stuff from the socket logger . info ( \"Starting receiving loop...\" ) asyncio . create_task ( self . receive_loop ()) async def _request ( self , * args : Any , ** kwargs : Any ) -> Any : \"\"\"Raw method to send a request. This method will do the following : * Start the receiving loop if it was not started * Get the address of the next worker ready (blocking) * Send the request to the worker * Wait for the response (blocking) * Return the result Args: *args: Positional arguments for the request. **kwargs: Keywords arguments for the request. Raises: UserCodeException: Exception raised if an exception was raised inside user-defined code on the worker side. Returns: Any: The response for the request. \"\"\" # Before anything, if the receiving loop was not started, start it self . _start_if_not_started () # Assign a unique ID to the request req_id = uuid . uuid4 () . hex # Let the manager know that we are waiting for this request logger . debug ( f \"Pinning request # { req_id } \" ) self . req_manager . pin ( req_id ) # Send the request address = await self . w_manager . get_next_worker () logger . debug ( f \"Sending request # { req_id } to worker # { address } \" ) await self . socket . send_multipart ([ address , b \"\" , msgpack . packb ([ req_id , args , kwargs ])]) # Wait until we receive the response code , res = await self . req_manager . wait_for ( req_id ) logger . debug ( f \"Received result for request # { req_id } \" ) # Depending on what is the response, deal with it properly if code == CODE_FAILURE : raise UserCodeException ( res ) else : return res async def request ( self , * args : Any , gibbs_timeout : float = None , gibbs_retries : int = 0 , ** kwargs : Any ) -> Any : \"\"\"Main method, used to send a request to workers and get the result. This method is a wrapper around `_request`, providing additional functionalities : * Timeout * Automatic retries Args: *args: Positional arguments for the request. gibbs_timeout (float): Timeout for the request, in seconds. If `None` is given, block until the request is complete. Defaults to None. gibbs_retries (int): Number of retries. This argument is used only if `gibbs_timeout` is not `None`. If `-1` is given, indefinitely retry. Defaults to 0. **kwargs: Keywords arguments for the request. Raises: asyncio.TimeoutError: Error raised if no response is received within the given timeout. Returns: Any: The response for the request. \"\"\" try : return await asyncio . wait_for ( self . _request ( * args , ** kwargs ), timeout = gibbs_timeout ) except asyncio . TimeoutError : if gibbs_retries == 0 : logger . error ( f \"Request failed : no response received within { gibbs_timeout } s\" ) raise else : retries_left = max ( gibbs_retries - 1 , - 1 ) logger . warning ( f \"Request failed : no response received within { gibbs_timeout } s. Retrying { retries_left } times\" ) return await self . request ( * args , gibbs_timeout = gibbs_timeout , gibbs_retries = retries_left , ** kwargs ) def __del__ ( self ): if self . socket is not None : self . socket . close () receive_loop ( self ) async Infinite loop for receiving responses from the workers. Source code in gibbs/hub.py async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff logger . debug ( \"Receiving...\" ) address , * frames = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . w_manager . reckon ( address ) if len ( frames ) == 1 : # Answer the Ping logger . debug ( \"Answering the ping\" ) await self . socket . send_multipart ([ address , b \"\" , PONG ]) continue _ , resp = frames req_id , code , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) self . req_manager . store ( req_id , code , res ) request ( self , * args , * , gibbs_timeout = None , gibbs_retries = 0 , ** kwargs ) async Main method, used to send a request to workers and get the result. This method is a wrapper around _request , providing additional functionalities : * Timeout * Automatic retries Parameters: Name Type Description Default *args Any Positional arguments for the request. () gibbs_timeout float Timeout for the request, in seconds. If None is given, block until the request is complete. Defaults to None. None gibbs_retries int Number of retries. This argument is used only if gibbs_timeout is not None . If -1 is given, indefinitely retry. Defaults to 0. 0 **kwargs Any Keywords arguments for the request. {} Exceptions: Type Description asyncio.TimeoutError Error raised if no response is received within the given timeout. Returns: Type Description Any The response for the request. Source code in gibbs/hub.py async def request ( self , * args : Any , gibbs_timeout : float = None , gibbs_retries : int = 0 , ** kwargs : Any ) -> Any : \"\"\"Main method, used to send a request to workers and get the result. This method is a wrapper around `_request`, providing additional functionalities : * Timeout * Automatic retries Args: *args: Positional arguments for the request. gibbs_timeout (float): Timeout for the request, in seconds. If `None` is given, block until the request is complete. Defaults to None. gibbs_retries (int): Number of retries. This argument is used only if `gibbs_timeout` is not `None`. If `-1` is given, indefinitely retry. Defaults to 0. **kwargs: Keywords arguments for the request. Raises: asyncio.TimeoutError: Error raised if no response is received within the given timeout. Returns: Any: The response for the request. \"\"\" try : return await asyncio . wait_for ( self . _request ( * args , ** kwargs ), timeout = gibbs_timeout ) except asyncio . TimeoutError : if gibbs_retries == 0 : logger . error ( f \"Request failed : no response received within { gibbs_timeout } s\" ) raise else : retries_left = max ( gibbs_retries - 1 , - 1 ) logger . warning ( f \"Request failed : no response received within { gibbs_timeout } s. Retrying { retries_left } times\" ) return await self . request ( * args , gibbs_timeout = gibbs_timeout , gibbs_retries = retries_left , ** kwargs ) Worker ( Process ) Define a worker process. This worker process indefinitely waits for requests on a socket. Upon receiving a request, it processes it with the worker class provided, and return the response. After creating the Worker object, you have 2 different ways to run it : * worker.run() : It will run in the current process directly (blocking, infinite loop). * worker.start() : It will start a different process and start the code there (non-blocking). Parameters: Name Type Description Default worker_cls Callable Worker class containing the code that will be used to process requests. required gibbs_host str Host of the Hub. Defaults to \"localhost\". 'localhost' gibbs_port int Port of the Hub. Defaults to DEFAULT_PORT. 5019 gibbs_heartbeat_interval float Heartbeat interval between the worker and the Hub. Defaults to DEFAULT_HEARTBEAT_INTERVAL. 1 gibbs_reset_after_n_miss int Number of missed heartbeats allowed before hard-resetting the socket and retrying. Defaults to DEFAULT_RESET_AFTER_N_MISS. 2 Source code in gibbs/worker.py class Worker ( Process ): \"\"\"Define a worker process. This worker process indefinitely waits for requests on a socket. Upon receiving a request, it processes it with the worker class provided, and return the response. After creating the Worker object, you have 2 different ways to run it : * `worker.run()` : It will run in the current process directly (blocking, infinite loop). * `worker.start()` : It will start a different process and start the code there (non-blocking). Args: worker_cls (Callable): Worker class containing the code that will be used to process requests. gibbs_host (str): Host of the Hub. Defaults to \"localhost\". gibbs_port (int): Port of the Hub. Defaults to DEFAULT_PORT. gibbs_heartbeat_interval (float): Heartbeat interval between the worker and the Hub. Defaults to DEFAULT_HEARTBEAT_INTERVAL. gibbs_reset_after_n_miss (int): Number of missed heartbeats allowed before hard-resetting the socket and retrying. Defaults to DEFAULT_RESET_AFTER_N_MISS. \"\"\" def __init__ ( self , worker_cls : Callable , * args : Any , gibbs_host : str = \"localhost\" , gibbs_port : int = DEFAULT_PORT , gibbs_heartbeat_interval : float = DEFAULT_HEARTBEAT_INTERVAL , gibbs_reset_after_n_miss : int = DEFAULT_RESET_AFTER_N_MISS , ** kwargs : Any , ): super () . __init__ () self . worker_cls = worker_cls self . worker_args = args self . worker_kwargs = kwargs self . identity = uuid . uuid4 () . hex self . host = gibbs_host self . port = gibbs_port self . heartbeat_t = gibbs_heartbeat_interval self . reset_n_miss = gibbs_reset_after_n_miss self . waiting_pong = 0 def create_socket ( self , context : zmq . Context ) -> zmq . Socket : \"\"\"Helper method to create a socket, setting its identity and connecting to the Hub. Args: context (zmq.Context): ZMQ context to use. Returns: zmq.Socket: Initialized and connected socket, ready to use. \"\"\" # Create the socket, set its identity socket = context . socket ( zmq . DEALER ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) return socket def ping ( self , socket : zmq . Socket ): \"\"\"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Args: socket (zmq.Socket): Socket to use to send the heartbeat. \"\"\" logger . debug ( \"Sending ping...\" ) socket . send ( PING ) self . waiting_pong += 1 def run ( self ): \"\"\"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. \"\"\" # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the socket context = zmq . Context () socket = self . create_socket ( context ) logger . info ( \"Worker ready to roll\" ) # Tell the Hub we are ready self . ping ( socket ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) if socket . poll ( self . heartbeat_t * MS , zmq . POLLIN ): _ , workload = socket . recv_multipart ( zmq . NOBLOCK ) logger . debug ( \"Received something !\" ) self . waiting_pong = 0 else : logger . debug ( f \"Didn't receive anything for { self . heartbeat_t } s ( { self . waiting_pong } )\" ) if self . waiting_pong >= self . reset_n_miss : logger . warning ( f \"The Hub is not answering, even after { self . waiting_pong } missed pings... \" f \"Resetting the socket\" ) socket . close ( linger = 0 ) socket = self . create_socket ( context ) self . waiting_pong = 0 # We didn't receive anything for some time, try to ping again self . ping ( socket ) continue if workload == PONG : # Just a Pong, ignore it logger . debug ( \"It was just a pong...\" ) continue # From here the Hub sent us an actual request req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments try : res = worker ( * req_args , ** req_kwargs ) except Exception as e : logger . warning ( f \"Exception in user-defined __call__ method : { e . __class__ . __name__ } ( { str ( e ) } )\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_FAILURE , traceback . format_exc ()])]) else : logger . debug ( \"Sending back the response\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_SUCCESS , res ])]) create_socket ( self , context ) Helper method to create a socket, setting its identity and connecting to the Hub. Parameters: Name Type Description Default context zmq.Context ZMQ context to use. required Returns: Type Description zmq.Socket Initialized and connected socket, ready to use. Source code in gibbs/worker.py def create_socket ( self , context : zmq . Context ) -> zmq . Socket : \"\"\"Helper method to create a socket, setting its identity and connecting to the Hub. Args: context (zmq.Context): ZMQ context to use. Returns: zmq.Socket: Initialized and connected socket, ready to use. \"\"\" # Create the socket, set its identity socket = context . socket ( zmq . DEALER ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) return socket ping ( self , socket ) Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Parameters: Name Type Description Default socket zmq.Socket Socket to use to send the heartbeat. required Source code in gibbs/worker.py def ping ( self , socket : zmq . Socket ): \"\"\"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Args: socket (zmq.Socket): Socket to use to send the heartbeat. \"\"\" logger . debug ( \"Sending ping...\" ) socket . send ( PING ) self . waiting_pong += 1 run ( self ) Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. Source code in gibbs/worker.py def run ( self ): \"\"\"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. \"\"\" # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the socket context = zmq . Context () socket = self . create_socket ( context ) logger . info ( \"Worker ready to roll\" ) # Tell the Hub we are ready self . ping ( socket ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) if socket . poll ( self . heartbeat_t * MS , zmq . POLLIN ): _ , workload = socket . recv_multipart ( zmq . NOBLOCK ) logger . debug ( \"Received something !\" ) self . waiting_pong = 0 else : logger . debug ( f \"Didn't receive anything for { self . heartbeat_t } s ( { self . waiting_pong } )\" ) if self . waiting_pong >= self . reset_n_miss : logger . warning ( f \"The Hub is not answering, even after { self . waiting_pong } missed pings... \" f \"Resetting the socket\" ) socket . close ( linger = 0 ) socket = self . create_socket ( context ) self . waiting_pong = 0 # We didn't receive anything for some time, try to ping again self . ping ( socket ) continue if workload == PONG : # Just a Pong, ignore it logger . debug ( \"It was just a pong...\" ) continue # From here the Hub sent us an actual request req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments try : res = worker ( * req_args , ** req_kwargs ) except Exception as e : logger . warning ( f \"Exception in user-defined __call__ method : { e . __class__ . __name__ } ( { str ( e ) } )\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_FAILURE , traceback . format_exc ()])]) else : logger . debug ( \"Sending back the response\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_SUCCESS , res ])]) Internal UserCodeException ( Exception ) Custom Exception for user-defined catched errors. Parameters: Name Type Description Default t str Traceback returned by the worker. required Source code in gibbs/hub.py class UserCodeException ( Exception ): \"\"\"Custom Exception for user-defined catched errors. Args: t (str): Traceback returned by the worker. \"\"\" def __init__ ( self , t : str ): super () . __init__ ( f \"Exception raised in user-defined code. Traceback : \\n { t } \" ) WorkerManager A helper class that takes care of managing workers. Workers' address can be registered as available, and this class will make sure to return address of workers that are available and alive. A worker is considered as dead if we didn't receive any heartbeat within a given interval. Parameters: Name Type Description Default heartbeat_interval float Interval of time (in seconds) after which we consider a worker to be dead. required Source code in gibbs/hub.py class WorkerManager : \"\"\"A helper class that takes care of managing workers. Workers' address can be registered as available, and this class will make sure to return address of workers that are available and alive. A worker is considered as dead if we didn't receive any heartbeat within a given interval. Args: heartbeat_interval (float): Interval of time (in seconds) after which we consider a worker to be dead. \"\"\" def __init__ ( self , heartbeat_interval : float ): super () . __init__ () self . heartbeat_t = heartbeat_interval self . w_ts = {} self . w_access = asyncio . Condition () async def reckon ( self , address : str ): \"\"\"Register the given address as available. Args: address (str): Address of the worker to register as available. \"\"\" async with self . w_access : self . w_ts [ address ] = time . time () self . w_access . notify () async def get_next_worker ( self ) -> str : \"\"\"Retrieve the next available and alive worker's address. Returns: str: Address of the available and alive worker. \"\"\" async with self . w_access : # Iterate workers until we find one that was alive recently w_alive = False while not w_alive : # If no workers are available, wait... if not self . w_ts : await self . w_access . wait () address , ts = self . w_ts . popitem () w_alive = time . time () - ts < self . heartbeat_t return address reckon ( self , address ) async Register the given address as available. Parameters: Name Type Description Default address str Address of the worker to register as available. required Source code in gibbs/hub.py async def reckon ( self , address : str ): \"\"\"Register the given address as available. Args: address (str): Address of the worker to register as available. \"\"\" async with self . w_access : self . w_ts [ address ] = time . time () self . w_access . notify () get_next_worker ( self ) async Retrieve the next available and alive worker's address. Returns: Type Description str Address of the available and alive worker. Source code in gibbs/hub.py async def get_next_worker ( self ) -> str : \"\"\"Retrieve the next available and alive worker's address. Returns: str: Address of the available and alive worker. \"\"\" async with self . w_access : # Iterate workers until we find one that was alive recently w_alive = False while not w_alive : # If no workers are available, wait... if not self . w_ts : await self . w_access . wait () address , ts = self . w_ts . popitem () w_alive = time . time () - ts < self . heartbeat_t return address RequestManager A helper class that takes care of storing responses and waiting for the right response. Parameters: Name Type Description Default resp_buffer_size int Maximum size of the response buffer. required Source code in gibbs/hub.py class RequestManager : \"\"\"A helper class that takes care of storing responses and waiting for the right response. Args: resp_buffer_size (int): Maximum size of the response buffer. \"\"\" def __init__ ( self , resp_buffer_size : int ): super () . __init__ () self . resp_buffer_size = resp_buffer_size self . responses = {} self . req_states = {} def pin ( self , req_id : str ): \"\"\"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each `req_id` before calling `wait_for`. Args: req_id (str): Request unique identifier. \"\"\" self . req_states [ req_id ] = asyncio . Event () # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None ) async def wait_for ( self , req_id : str ) -> Tuple [ int , Any ]: \"\"\"Async method that waits until we received the response corresponding to the given request ID. The method `pin` should be called before waiting with this method. Args: req_id (str): Request unique identifier. Raises: KeyError: Exception raised if the request wasn't registered previously. Returns: Tuple[int, Any]: Code and content of the received response. \"\"\" if req_id not in self . req_states : raise KeyError ( f \"Request # { req_id } was not pinned, or was removed because of buffer overflow\" ) # Wait for the receiving loop to receive the response await self . req_states [ req_id ] . wait () # Once we get it, access the result r = self . responses . pop ( req_id ) # Don't forget to remove the event self . req_states . pop ( req_id ) return r . code , r . content def store ( self , req_id : str , code : int , response : Any ): \"\"\"Store a response, to be consumed later. Args: req_id (str): Request unique identifier. code (int): Code of the response. response (Any): Content of the response. \"\"\" # Store the response if the req_id is recognized if req_id in self . req_states : self . responses [ req_id ] = Response ( code , response ) # Notify that we received the response self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" ) pin ( self , req_id ) Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each req_id before calling wait_for . Parameters: Name Type Description Default req_id str Request unique identifier. required Source code in gibbs/hub.py def pin ( self , req_id : str ): \"\"\"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each `req_id` before calling `wait_for`. Args: req_id (str): Request unique identifier. \"\"\" self . req_states [ req_id ] = asyncio . Event () # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None ) wait_for ( self , req_id ) async Async method that waits until we received the response corresponding to the given request ID. The method pin should be called before waiting with this method. Parameters: Name Type Description Default req_id str Request unique identifier. required Exceptions: Type Description KeyError Exception raised if the request wasn't registered previously. Returns: Type Description Tuple[int, Any] Code and content of the received response. Source code in gibbs/hub.py async def wait_for ( self , req_id : str ) -> Tuple [ int , Any ]: \"\"\"Async method that waits until we received the response corresponding to the given request ID. The method `pin` should be called before waiting with this method. Args: req_id (str): Request unique identifier. Raises: KeyError: Exception raised if the request wasn't registered previously. Returns: Tuple[int, Any]: Code and content of the received response. \"\"\" if req_id not in self . req_states : raise KeyError ( f \"Request # { req_id } was not pinned, or was removed because of buffer overflow\" ) # Wait for the receiving loop to receive the response await self . req_states [ req_id ] . wait () # Once we get it, access the result r = self . responses . pop ( req_id ) # Don't forget to remove the event self . req_states . pop ( req_id ) return r . code , r . content store ( self , req_id , code , response ) Store a response, to be consumed later. Parameters: Name Type Description Default req_id str Request unique identifier. required code int Code of the response. required response Any Content of the response. required Source code in gibbs/hub.py def store ( self , req_id : str , code : int , response : Any ): \"\"\"Store a response, to be consumed later. Args: req_id (str): Request unique identifier. code (int): Code of the response. response (Any): Content of the response. \"\"\" # Store the response if the req_id is recognized if req_id in self . req_states : self . responses [ req_id ] = Response ( code , response ) # Notify that we received the response self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" ) Constants RESPONSE_BUFFER_SIZE : int CODE_FAILURE : int CODE_SUCCESS : int DEFAULT_HEARTBEAT_INTERVAL : float DEFAULT_PORT : int DEFAULT_RESET_AFTER_N_MISS : int MS : int PING : bytes PONG : bytes","title":"Code reference"},{"location":"code_ref/#code-reference","text":"","title":"Code reference"},{"location":"code_ref/#api","text":"","title":"API"},{"location":"code_ref/#gibbs.hub.Hub","text":"Class acting as a hub for all the requests to send. All requests sent through this class will be automatically dispatched to connected workers, will wait for the responses and return it. Parameters: Name Type Description Default port int Port number to use for the sockets. Defaults to DEFAULT_PORT. 5019 heartbeat_interval float Heartbeat interval used by the workers, in seconds. Defaults to DEFAULT_HEARTBEAT_INTERVAL. 1 resp_buffer_size int Maximum response buffer size. Defaults to RESPONSE_BUFFER_SIZE. 4096 Source code in gibbs/hub.py class Hub : \"\"\"Class acting as a hub for all the requests to send. All requests sent through this class will be automatically dispatched to connected workers, will wait for the responses and return it. Args: port (int): Port number to use for the sockets. Defaults to DEFAULT_PORT. heartbeat_interval (float): Heartbeat interval used by the workers, in seconds. Defaults to DEFAULT_HEARTBEAT_INTERVAL. resp_buffer_size (int): Maximum response buffer size. Defaults to RESPONSE_BUFFER_SIZE. \"\"\" def __init__ ( self , port : int = DEFAULT_PORT , heartbeat_interval : float = DEFAULT_HEARTBEAT_INTERVAL , resp_buffer_size : int = RESPONSE_BUFFER_SIZE , ): super () . __init__ () self . port = port self . heartbeat_t = heartbeat_interval self . socket = None self . w_manager = None self . req_manager = RequestManager ( resp_buffer_size = resp_buffer_size ) async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff logger . debug ( \"Receiving...\" ) address , * frames = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . w_manager . reckon ( address ) if len ( frames ) == 1 : # Answer the Ping logger . debug ( \"Answering the ping\" ) await self . socket . send_multipart ([ address , b \"\" , PONG ]) continue _ , resp = frames req_id , code , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) self . req_manager . store ( req_id , code , res ) def _start_if_not_started ( self ): \"\"\"Helper method to ensure everything is properly started (socket is initialized, receiving loop is started, etc...). \"\"\" if self . socket is None : # Create what we need here in this process/context context = zmq . asyncio . Context () self . socket = context . socket ( zmq . ROUTER ) self . socket . bind ( f \"tcp://*: { self . port } \" ) self . w_manager = WorkerManager ( heartbeat_interval = self . heartbeat_t ) # Fire and forget : infinite loop, taking care of receiving stuff from the socket logger . info ( \"Starting receiving loop...\" ) asyncio . create_task ( self . receive_loop ()) async def _request ( self , * args : Any , ** kwargs : Any ) -> Any : \"\"\"Raw method to send a request. This method will do the following : * Start the receiving loop if it was not started * Get the address of the next worker ready (blocking) * Send the request to the worker * Wait for the response (blocking) * Return the result Args: *args: Positional arguments for the request. **kwargs: Keywords arguments for the request. Raises: UserCodeException: Exception raised if an exception was raised inside user-defined code on the worker side. Returns: Any: The response for the request. \"\"\" # Before anything, if the receiving loop was not started, start it self . _start_if_not_started () # Assign a unique ID to the request req_id = uuid . uuid4 () . hex # Let the manager know that we are waiting for this request logger . debug ( f \"Pinning request # { req_id } \" ) self . req_manager . pin ( req_id ) # Send the request address = await self . w_manager . get_next_worker () logger . debug ( f \"Sending request # { req_id } to worker # { address } \" ) await self . socket . send_multipart ([ address , b \"\" , msgpack . packb ([ req_id , args , kwargs ])]) # Wait until we receive the response code , res = await self . req_manager . wait_for ( req_id ) logger . debug ( f \"Received result for request # { req_id } \" ) # Depending on what is the response, deal with it properly if code == CODE_FAILURE : raise UserCodeException ( res ) else : return res async def request ( self , * args : Any , gibbs_timeout : float = None , gibbs_retries : int = 0 , ** kwargs : Any ) -> Any : \"\"\"Main method, used to send a request to workers and get the result. This method is a wrapper around `_request`, providing additional functionalities : * Timeout * Automatic retries Args: *args: Positional arguments for the request. gibbs_timeout (float): Timeout for the request, in seconds. If `None` is given, block until the request is complete. Defaults to None. gibbs_retries (int): Number of retries. This argument is used only if `gibbs_timeout` is not `None`. If `-1` is given, indefinitely retry. Defaults to 0. **kwargs: Keywords arguments for the request. Raises: asyncio.TimeoutError: Error raised if no response is received within the given timeout. Returns: Any: The response for the request. \"\"\" try : return await asyncio . wait_for ( self . _request ( * args , ** kwargs ), timeout = gibbs_timeout ) except asyncio . TimeoutError : if gibbs_retries == 0 : logger . error ( f \"Request failed : no response received within { gibbs_timeout } s\" ) raise else : retries_left = max ( gibbs_retries - 1 , - 1 ) logger . warning ( f \"Request failed : no response received within { gibbs_timeout } s. Retrying { retries_left } times\" ) return await self . request ( * args , gibbs_timeout = gibbs_timeout , gibbs_retries = retries_left , ** kwargs ) def __del__ ( self ): if self . socket is not None : self . socket . close ()","title":"Hub"},{"location":"code_ref/#gibbs.hub.Hub.receive_loop","text":"Infinite loop for receiving responses from the workers. Source code in gibbs/hub.py async def receive_loop ( self ): \"\"\"Infinite loop for receiving responses from the workers.\"\"\" while True : # Receive stuff logger . debug ( \"Receiving...\" ) address , * frames = await self . socket . recv_multipart () logger . debug ( f \"Received something from worker # { address } \" ) # Since we received a response from this worker, it means it's ready for more ! await self . w_manager . reckon ( address ) if len ( frames ) == 1 : # Answer the Ping logger . debug ( \"Answering the ping\" ) await self . socket . send_multipart ([ address , b \"\" , PONG ]) continue _ , resp = frames req_id , code , res = msgpack . unpackb ( resp ) logger . debug ( f \"Received response from request # { req_id } \" ) self . req_manager . store ( req_id , code , res )","title":"receive_loop()"},{"location":"code_ref/#gibbs.hub.Hub.request","text":"Main method, used to send a request to workers and get the result. This method is a wrapper around _request , providing additional functionalities : * Timeout * Automatic retries Parameters: Name Type Description Default *args Any Positional arguments for the request. () gibbs_timeout float Timeout for the request, in seconds. If None is given, block until the request is complete. Defaults to None. None gibbs_retries int Number of retries. This argument is used only if gibbs_timeout is not None . If -1 is given, indefinitely retry. Defaults to 0. 0 **kwargs Any Keywords arguments for the request. {} Exceptions: Type Description asyncio.TimeoutError Error raised if no response is received within the given timeout. Returns: Type Description Any The response for the request. Source code in gibbs/hub.py async def request ( self , * args : Any , gibbs_timeout : float = None , gibbs_retries : int = 0 , ** kwargs : Any ) -> Any : \"\"\"Main method, used to send a request to workers and get the result. This method is a wrapper around `_request`, providing additional functionalities : * Timeout * Automatic retries Args: *args: Positional arguments for the request. gibbs_timeout (float): Timeout for the request, in seconds. If `None` is given, block until the request is complete. Defaults to None. gibbs_retries (int): Number of retries. This argument is used only if `gibbs_timeout` is not `None`. If `-1` is given, indefinitely retry. Defaults to 0. **kwargs: Keywords arguments for the request. Raises: asyncio.TimeoutError: Error raised if no response is received within the given timeout. Returns: Any: The response for the request. \"\"\" try : return await asyncio . wait_for ( self . _request ( * args , ** kwargs ), timeout = gibbs_timeout ) except asyncio . TimeoutError : if gibbs_retries == 0 : logger . error ( f \"Request failed : no response received within { gibbs_timeout } s\" ) raise else : retries_left = max ( gibbs_retries - 1 , - 1 ) logger . warning ( f \"Request failed : no response received within { gibbs_timeout } s. Retrying { retries_left } times\" ) return await self . request ( * args , gibbs_timeout = gibbs_timeout , gibbs_retries = retries_left , ** kwargs )","title":"request()"},{"location":"code_ref/#gibbs.worker.Worker","text":"Define a worker process. This worker process indefinitely waits for requests on a socket. Upon receiving a request, it processes it with the worker class provided, and return the response. After creating the Worker object, you have 2 different ways to run it : * worker.run() : It will run in the current process directly (blocking, infinite loop). * worker.start() : It will start a different process and start the code there (non-blocking). Parameters: Name Type Description Default worker_cls Callable Worker class containing the code that will be used to process requests. required gibbs_host str Host of the Hub. Defaults to \"localhost\". 'localhost' gibbs_port int Port of the Hub. Defaults to DEFAULT_PORT. 5019 gibbs_heartbeat_interval float Heartbeat interval between the worker and the Hub. Defaults to DEFAULT_HEARTBEAT_INTERVAL. 1 gibbs_reset_after_n_miss int Number of missed heartbeats allowed before hard-resetting the socket and retrying. Defaults to DEFAULT_RESET_AFTER_N_MISS. 2 Source code in gibbs/worker.py class Worker ( Process ): \"\"\"Define a worker process. This worker process indefinitely waits for requests on a socket. Upon receiving a request, it processes it with the worker class provided, and return the response. After creating the Worker object, you have 2 different ways to run it : * `worker.run()` : It will run in the current process directly (blocking, infinite loop). * `worker.start()` : It will start a different process and start the code there (non-blocking). Args: worker_cls (Callable): Worker class containing the code that will be used to process requests. gibbs_host (str): Host of the Hub. Defaults to \"localhost\". gibbs_port (int): Port of the Hub. Defaults to DEFAULT_PORT. gibbs_heartbeat_interval (float): Heartbeat interval between the worker and the Hub. Defaults to DEFAULT_HEARTBEAT_INTERVAL. gibbs_reset_after_n_miss (int): Number of missed heartbeats allowed before hard-resetting the socket and retrying. Defaults to DEFAULT_RESET_AFTER_N_MISS. \"\"\" def __init__ ( self , worker_cls : Callable , * args : Any , gibbs_host : str = \"localhost\" , gibbs_port : int = DEFAULT_PORT , gibbs_heartbeat_interval : float = DEFAULT_HEARTBEAT_INTERVAL , gibbs_reset_after_n_miss : int = DEFAULT_RESET_AFTER_N_MISS , ** kwargs : Any , ): super () . __init__ () self . worker_cls = worker_cls self . worker_args = args self . worker_kwargs = kwargs self . identity = uuid . uuid4 () . hex self . host = gibbs_host self . port = gibbs_port self . heartbeat_t = gibbs_heartbeat_interval self . reset_n_miss = gibbs_reset_after_n_miss self . waiting_pong = 0 def create_socket ( self , context : zmq . Context ) -> zmq . Socket : \"\"\"Helper method to create a socket, setting its identity and connecting to the Hub. Args: context (zmq.Context): ZMQ context to use. Returns: zmq.Socket: Initialized and connected socket, ready to use. \"\"\" # Create the socket, set its identity socket = context . socket ( zmq . DEALER ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) return socket def ping ( self , socket : zmq . Socket ): \"\"\"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Args: socket (zmq.Socket): Socket to use to send the heartbeat. \"\"\" logger . debug ( \"Sending ping...\" ) socket . send ( PING ) self . waiting_pong += 1 def run ( self ): \"\"\"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. \"\"\" # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the socket context = zmq . Context () socket = self . create_socket ( context ) logger . info ( \"Worker ready to roll\" ) # Tell the Hub we are ready self . ping ( socket ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) if socket . poll ( self . heartbeat_t * MS , zmq . POLLIN ): _ , workload = socket . recv_multipart ( zmq . NOBLOCK ) logger . debug ( \"Received something !\" ) self . waiting_pong = 0 else : logger . debug ( f \"Didn't receive anything for { self . heartbeat_t } s ( { self . waiting_pong } )\" ) if self . waiting_pong >= self . reset_n_miss : logger . warning ( f \"The Hub is not answering, even after { self . waiting_pong } missed pings... \" f \"Resetting the socket\" ) socket . close ( linger = 0 ) socket = self . create_socket ( context ) self . waiting_pong = 0 # We didn't receive anything for some time, try to ping again self . ping ( socket ) continue if workload == PONG : # Just a Pong, ignore it logger . debug ( \"It was just a pong...\" ) continue # From here the Hub sent us an actual request req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments try : res = worker ( * req_args , ** req_kwargs ) except Exception as e : logger . warning ( f \"Exception in user-defined __call__ method : { e . __class__ . __name__ } ( { str ( e ) } )\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_FAILURE , traceback . format_exc ()])]) else : logger . debug ( \"Sending back the response\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_SUCCESS , res ])])","title":"Worker"},{"location":"code_ref/#gibbs.worker.Worker.create_socket","text":"Helper method to create a socket, setting its identity and connecting to the Hub. Parameters: Name Type Description Default context zmq.Context ZMQ context to use. required Returns: Type Description zmq.Socket Initialized and connected socket, ready to use. Source code in gibbs/worker.py def create_socket ( self , context : zmq . Context ) -> zmq . Socket : \"\"\"Helper method to create a socket, setting its identity and connecting to the Hub. Args: context (zmq.Context): ZMQ context to use. Returns: zmq.Socket: Initialized and connected socket, ready to use. \"\"\" # Create the socket, set its identity socket = context . socket ( zmq . DEALER ) socket . setsockopt_string ( zmq . IDENTITY , self . identity ) # Connect to the Hub socket . connect ( f \"tcp:// { self . host } : { self . port } \" ) return socket","title":"create_socket()"},{"location":"code_ref/#gibbs.worker.Worker.ping","text":"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Parameters: Name Type Description Default socket zmq.Socket Socket to use to send the heartbeat. required Source code in gibbs/worker.py def ping ( self , socket : zmq . Socket ): \"\"\"Helper method used for the heartbeat. Also takes care of keeping the counter of heartbeats up-to-date. Args: socket (zmq.Socket): Socket to use to send the heartbeat. \"\"\" logger . debug ( \"Sending ping...\" ) socket . send ( PING ) self . waiting_pong += 1","title":"ping()"},{"location":"code_ref/#gibbs.worker.Worker.run","text":"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. Source code in gibbs/worker.py def run ( self ): \"\"\"Main method. It will initialize the worker class, and enter an infinite loop, waiting for requests. Whenever a request is received, it processes it with the code provided in the constructor. \"\"\" # Instanciate the worker worker = self . worker_cls ( * self . worker_args , ** self . worker_kwargs ) # Create the socket context = zmq . Context () socket = self . create_socket ( context ) logger . info ( \"Worker ready to roll\" ) # Tell the Hub we are ready self . ping ( socket ) # Indefinitely wait for requests : when we are done with one request, # we wait for the next one while True : logger . debug ( \"Waiting for request...\" ) if socket . poll ( self . heartbeat_t * MS , zmq . POLLIN ): _ , workload = socket . recv_multipart ( zmq . NOBLOCK ) logger . debug ( \"Received something !\" ) self . waiting_pong = 0 else : logger . debug ( f \"Didn't receive anything for { self . heartbeat_t } s ( { self . waiting_pong } )\" ) if self . waiting_pong >= self . reset_n_miss : logger . warning ( f \"The Hub is not answering, even after { self . waiting_pong } missed pings... \" f \"Resetting the socket\" ) socket . close ( linger = 0 ) socket = self . create_socket ( context ) self . waiting_pong = 0 # We didn't receive anything for some time, try to ping again self . ping ( socket ) continue if workload == PONG : # Just a Pong, ignore it logger . debug ( \"It was just a pong...\" ) continue # From here the Hub sent us an actual request req_id , req_args , req_kwargs = msgpack . unpackb ( workload ) logger . debug ( f \"Request # { req_id } received\" ) # Call worker's code with the request arguments try : res = worker ( * req_args , ** req_kwargs ) except Exception as e : logger . warning ( f \"Exception in user-defined __call__ method : { e . __class__ . __name__ } ( { str ( e ) } )\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_FAILURE , traceback . format_exc ()])]) else : logger . debug ( \"Sending back the response\" ) socket . send_multipart ([ b \"\" , msgpack . packb ([ req_id , CODE_SUCCESS , res ])])","title":"run()"},{"location":"code_ref/#internal","text":"","title":"Internal"},{"location":"code_ref/#gibbs.hub.UserCodeException","text":"Custom Exception for user-defined catched errors. Parameters: Name Type Description Default t str Traceback returned by the worker. required Source code in gibbs/hub.py class UserCodeException ( Exception ): \"\"\"Custom Exception for user-defined catched errors. Args: t (str): Traceback returned by the worker. \"\"\" def __init__ ( self , t : str ): super () . __init__ ( f \"Exception raised in user-defined code. Traceback : \\n { t } \" )","title":"UserCodeException"},{"location":"code_ref/#gibbs.hub.WorkerManager","text":"A helper class that takes care of managing workers. Workers' address can be registered as available, and this class will make sure to return address of workers that are available and alive. A worker is considered as dead if we didn't receive any heartbeat within a given interval. Parameters: Name Type Description Default heartbeat_interval float Interval of time (in seconds) after which we consider a worker to be dead. required Source code in gibbs/hub.py class WorkerManager : \"\"\"A helper class that takes care of managing workers. Workers' address can be registered as available, and this class will make sure to return address of workers that are available and alive. A worker is considered as dead if we didn't receive any heartbeat within a given interval. Args: heartbeat_interval (float): Interval of time (in seconds) after which we consider a worker to be dead. \"\"\" def __init__ ( self , heartbeat_interval : float ): super () . __init__ () self . heartbeat_t = heartbeat_interval self . w_ts = {} self . w_access = asyncio . Condition () async def reckon ( self , address : str ): \"\"\"Register the given address as available. Args: address (str): Address of the worker to register as available. \"\"\" async with self . w_access : self . w_ts [ address ] = time . time () self . w_access . notify () async def get_next_worker ( self ) -> str : \"\"\"Retrieve the next available and alive worker's address. Returns: str: Address of the available and alive worker. \"\"\" async with self . w_access : # Iterate workers until we find one that was alive recently w_alive = False while not w_alive : # If no workers are available, wait... if not self . w_ts : await self . w_access . wait () address , ts = self . w_ts . popitem () w_alive = time . time () - ts < self . heartbeat_t return address","title":"WorkerManager"},{"location":"code_ref/#gibbs.hub.WorkerManager.reckon","text":"Register the given address as available. Parameters: Name Type Description Default address str Address of the worker to register as available. required Source code in gibbs/hub.py async def reckon ( self , address : str ): \"\"\"Register the given address as available. Args: address (str): Address of the worker to register as available. \"\"\" async with self . w_access : self . w_ts [ address ] = time . time () self . w_access . notify ()","title":"reckon()"},{"location":"code_ref/#gibbs.hub.WorkerManager.get_next_worker","text":"Retrieve the next available and alive worker's address. Returns: Type Description str Address of the available and alive worker. Source code in gibbs/hub.py async def get_next_worker ( self ) -> str : \"\"\"Retrieve the next available and alive worker's address. Returns: str: Address of the available and alive worker. \"\"\" async with self . w_access : # Iterate workers until we find one that was alive recently w_alive = False while not w_alive : # If no workers are available, wait... if not self . w_ts : await self . w_access . wait () address , ts = self . w_ts . popitem () w_alive = time . time () - ts < self . heartbeat_t return address","title":"get_next_worker()"},{"location":"code_ref/#gibbs.hub.RequestManager","text":"A helper class that takes care of storing responses and waiting for the right response. Parameters: Name Type Description Default resp_buffer_size int Maximum size of the response buffer. required Source code in gibbs/hub.py class RequestManager : \"\"\"A helper class that takes care of storing responses and waiting for the right response. Args: resp_buffer_size (int): Maximum size of the response buffer. \"\"\" def __init__ ( self , resp_buffer_size : int ): super () . __init__ () self . resp_buffer_size = resp_buffer_size self . responses = {} self . req_states = {} def pin ( self , req_id : str ): \"\"\"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each `req_id` before calling `wait_for`. Args: req_id (str): Request unique identifier. \"\"\" self . req_states [ req_id ] = asyncio . Event () # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None ) async def wait_for ( self , req_id : str ) -> Tuple [ int , Any ]: \"\"\"Async method that waits until we received the response corresponding to the given request ID. The method `pin` should be called before waiting with this method. Args: req_id (str): Request unique identifier. Raises: KeyError: Exception raised if the request wasn't registered previously. Returns: Tuple[int, Any]: Code and content of the received response. \"\"\" if req_id not in self . req_states : raise KeyError ( f \"Request # { req_id } was not pinned, or was removed because of buffer overflow\" ) # Wait for the receiving loop to receive the response await self . req_states [ req_id ] . wait () # Once we get it, access the result r = self . responses . pop ( req_id ) # Don't forget to remove the event self . req_states . pop ( req_id ) return r . code , r . content def store ( self , req_id : str , code : int , response : Any ): \"\"\"Store a response, to be consumed later. Args: req_id (str): Request unique identifier. code (int): Code of the response. response (Any): Content of the response. \"\"\" # Store the response if the req_id is recognized if req_id in self . req_states : self . responses [ req_id ] = Response ( code , response ) # Notify that we received the response self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" )","title":"RequestManager"},{"location":"code_ref/#gibbs.hub.RequestManager.pin","text":"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each req_id before calling wait_for . Parameters: Name Type Description Default req_id str Request unique identifier. required Source code in gibbs/hub.py def pin ( self , req_id : str ): \"\"\"Pin a request ID. This is a necessary step when sending a request, so that the request can be awaited until a response is received. This method should be called for each `req_id` before calling `wait_for`. Args: req_id (str): Request unique identifier. \"\"\" self . req_states [ req_id ] = asyncio . Event () # Ensure we don't store too many requests if len ( self . req_states ) > self . resp_buffer_size : # If it's the case, forget the oldest one k = list ( self . req_states . keys ())[ 0 ] logger . warning ( f \"Response buffer overflow (> { self . resp_buffer_size } ). Forgetting oldest request : { k } \" ) self . req_states . pop ( k ) self . responses . pop ( k , None )","title":"pin()"},{"location":"code_ref/#gibbs.hub.RequestManager.wait_for","text":"Async method that waits until we received the response corresponding to the given request ID. The method pin should be called before waiting with this method. Parameters: Name Type Description Default req_id str Request unique identifier. required Exceptions: Type Description KeyError Exception raised if the request wasn't registered previously. Returns: Type Description Tuple[int, Any] Code and content of the received response. Source code in gibbs/hub.py async def wait_for ( self , req_id : str ) -> Tuple [ int , Any ]: \"\"\"Async method that waits until we received the response corresponding to the given request ID. The method `pin` should be called before waiting with this method. Args: req_id (str): Request unique identifier. Raises: KeyError: Exception raised if the request wasn't registered previously. Returns: Tuple[int, Any]: Code and content of the received response. \"\"\" if req_id not in self . req_states : raise KeyError ( f \"Request # { req_id } was not pinned, or was removed because of buffer overflow\" ) # Wait for the receiving loop to receive the response await self . req_states [ req_id ] . wait () # Once we get it, access the result r = self . responses . pop ( req_id ) # Don't forget to remove the event self . req_states . pop ( req_id ) return r . code , r . content","title":"wait_for()"},{"location":"code_ref/#gibbs.hub.RequestManager.store","text":"Store a response, to be consumed later. Parameters: Name Type Description Default req_id str Request unique identifier. required code int Code of the response. required response Any Content of the response. required Source code in gibbs/hub.py def store ( self , req_id : str , code : int , response : Any ): \"\"\"Store a response, to be consumed later. Args: req_id (str): Request unique identifier. code (int): Code of the response. response (Any): Content of the response. \"\"\" # Store the response if the req_id is recognized if req_id in self . req_states : self . responses [ req_id ] = Response ( code , response ) # Notify that we received the response self . req_states [ req_id ] . set () else : logger . warning ( f \"Request # { req_id } was previously removed from response buffer. \" f \"Ignoring the response from this request...\" )","title":"store()"},{"location":"code_ref/#constants","text":"","title":"Constants"},{"location":"code_ref/#gibbs.hub.RESPONSE_BUFFER_SIZE","text":"","title":"RESPONSE_BUFFER_SIZE"},{"location":"code_ref/#gibbs.worker.CODE_FAILURE","text":"","title":"CODE_FAILURE"},{"location":"code_ref/#gibbs.worker.CODE_SUCCESS","text":"","title":"CODE_SUCCESS"},{"location":"code_ref/#gibbs.worker.DEFAULT_HEARTBEAT_INTERVAL","text":"","title":"DEFAULT_HEARTBEAT_INTERVAL"},{"location":"code_ref/#gibbs.worker.DEFAULT_PORT","text":"","title":"DEFAULT_PORT"},{"location":"code_ref/#gibbs.worker.DEFAULT_RESET_AFTER_N_MISS","text":"","title":"DEFAULT_RESET_AFTER_N_MISS"},{"location":"code_ref/#gibbs.worker.MS","text":"","title":"MS"},{"location":"code_ref/#gibbs.worker.PING","text":"","title":"PING"},{"location":"code_ref/#gibbs.worker.PONG","text":"","title":"PONG"},{"location":"design/","text":"Design","title":"Design"},{"location":"design/#design","text":"","title":"Design"},{"location":"examples/","text":"Examples All examples are located in the examples/ folder. All examples can be run directly without any arguments. You can experiment new settings by changing the constants inside the scripts. Important Some examples require additional dependencies. You can install these dependencies with pip install gibbs[ex] (see Installation ) vanilla_fastapi.py python examples/vanilla_fastapi.py This example simply creates a FastAPI application with a dummy model. The dummy model simulate some computations time. The script will measure the time needed to send and receive 10 requests. gibbs_fastapi.py python examples/gibbs_fastapi.py This example is the same as vanilla_fastapi.py , but it uses gibbs to scale up the dummy model (with 2 workers). The script will also measure the time needed to send and receive 10 requests, so you can compare the results with the vanilla approach. transformer.py python examples/transformer.py A more \"real-life\" application, where we use a BART model (from transformers library) along with gibbs for scaling up text-summarization.","title":"Examples"},{"location":"examples/#examples","text":"All examples are located in the examples/ folder. All examples can be run directly without any arguments. You can experiment new settings by changing the constants inside the scripts. Important Some examples require additional dependencies. You can install these dependencies with pip install gibbs[ex] (see Installation )","title":"Examples"},{"location":"examples/#vanilla_fastapipy","text":"python examples/vanilla_fastapi.py This example simply creates a FastAPI application with a dummy model. The dummy model simulate some computations time. The script will measure the time needed to send and receive 10 requests.","title":"vanilla_fastapi.py"},{"location":"examples/#gibbs_fastapipy","text":"python examples/gibbs_fastapi.py This example is the same as vanilla_fastapi.py , but it uses gibbs to scale up the dummy model (with 2 workers). The script will also measure the time needed to send and receive 10 requests, so you can compare the results with the vanilla approach.","title":"gibbs_fastapi.py"},{"location":"examples/#transformerpy","text":"python examples/transformer.py A more \"real-life\" application, where we use a BART model (from transformers library) along with gibbs for scaling up text-summarization.","title":"transformer.py"},{"location":"usage/","text":"Usage Let's walk-through an example of how to scale a FastAPI application together ! Note Here we use FastAPI to show how easy it is to integrate gibbs in an asynchronous framework, but gibbs can be used like any asynchronous python code ! Initial application How gibbs works Use gibbs to scale up","title":"Usage"},{"location":"usage/#usage","text":"Let's walk-through an example of how to scale a FastAPI application together ! Note Here we use FastAPI to show how easy it is to integrate gibbs in an asynchronous framework, but gibbs can be used like any asynchronous python code !","title":"Usage"},{"location":"usage/#initial-application","text":"","title":"Initial application"},{"location":"usage/#how-gibbs-works","text":"","title":"How gibbs works"},{"location":"usage/#use-gibbs-to-scale-up","text":"","title":"Use gibbs to scale up"}]}